{"index":"<h1>Documentation for OpenTSDB 2.2</h1> <p>Welcome to OpenTSDB 2.2, the scalable, distributed time series database. We recommend that you start with the <a class=\"reference internal\" href=\"user_guide/index\"><em>User Guide</em></a> then test your understanding with an <a class=\"reference internal\" href=\"installation\"><em>Installation</em></a> and read on the <a class=\"reference internal\" href=\"api_http/index\"><em>HTTP API</em></a> if you need to develope against it.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/index.html</a>\n  </p>\n</div>\n","new":"<h1>What's New</h1> <p>OpenTSDB has a thriving community who contributed and requested a number of new features.</p>  <h2>2.2</h2> <ul class=\"simple\"> <li>Appends - Support writing all data points for an hour in a single column. This saves the need for TSD compactions and reduces network traffic at query time.</li> <li>Salting - Enables greater distribution of writes for high cardinality metrics as well as asynchronous scanning for improved query speed. (Non backwards compatible)</li> <li>Random Metric UIDs - Enables better distribution of writes when creating new metrics</li> <li>Storage Exception Plugin - Enables various handling of data points when HBase is unavailable</li> <li>Secure AsyncHBase - Access HBase clusters requiring Kerberos or simple authentication along with optional encryption.</li> <li>Fill Policy - Enable emitting NaNs or Nulls via the JSON query endpoint when data points are \"missing\"</li> <li>Count and Percentiles - New aggregator functions</li> <li>More Stats - Gives greater insight into query performance via the query stats endpoint and new stats for threads, region clients and the JVM</li> <li>Annotations - Scan for multiple annotations only via the /api/annotations endpoint</li> <li>Query Filters - New filters for flexibility including case (in)sensitive literals, wildcards and regular expressions.</li> <li>Override Tag Widths - You can now override tag widths in the config instead of having to recompile the code.</li> <li>Compaction Tuning - New parameters allow for tuning the TSD compaction process.</li> <li>Delete Data And UIDs - Allow for deleting data at query time as well as removing UIDs from the system.</li> <li>Synchronous Writing - The HTTP Put API now supports synchronous writing to make sure data is flushed to HBase.</li> <li>Query Stats - Query details are now logged that include timing statistics. A new endpoint also shows running and completed queries.</li> </ul>   <h2>2.1</h2> <ul class=\"simple\"> <li>Downsampling - Timestamps are now aligned on modulus boundaries, reducing the need to interpolation across series.</li> <li>Last Data Point API - Query for the last data point for specific time series within a certain time window</li> <li>Duplicates - Handle duplicate data points at query time or during FSCK</li> <li>FSCK - An updated FSCK utility that iterates over the main data table, finding and fixing errors</li> <li>Read/Write Modes - Block assigning UIDs on individual TSDs for backup clusters</li> <li>UID Cache - Preload portions of the UID table on startup to improve writes</li> </ul>   <h2>2.0</h2> <ul class=\"simple\"> <li>Lock-less UID Assignment - Drastically improves write speed when storing new metrics, tag names, or values</li> <li>Restful API - Provides access to all of OpenTSDB's features as well as offering new options, defaulting to JSON</li> <li>Cross Origin Resource Sharing - For the API so you can make AJAX calls easily</li> <li>Store Data Via HTTP - Write data points over HTTP as an alternative to Telnet</li> <li>Configuration File - A key/value file shared by the TSD and command line tools</li> <li>Pluggable Serializers - Enable different inputs and outputs for the API</li> <li>Annotations - Record meta data about specific time series or data points</li> <li>Meta Data - Record meta data for each time series, metrics, tag names, or values</li> <li>Trees - Flatten metric and tag combinations into a single name for navigation or usage with different tools</li> <li>Search Plugins - Send meta data to search engines to delve into your data and figure out what's in your database</li> <li>Real-Time Publishing Plugin - Send data to external systems as they arrive to your TSD</li> <li>Ingest Plugins - Accept data points in different formats</li> <li>Millisecond Resolution - Optionally store data with millisecond precision</li> <li>Variable Length Encoding - Use less storage space for smaller integer values</li> <li>Non-Interpolating Aggregation Functions - For situations where you require raw data</li> <li>Rate Counter Calculations - Handle roll-over and anomaly supression</li> <li>Additional Statistics - Including the number of UIDs assigned and available</li> </ul> <p>Thank you to everyone who has contributed to 2.2. Help us out by sharing your ideas and code at <a class=\"reference external\" href=\"https://github.com/OpenTSDB\">GitHub</a></p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/new.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/new.html</a>\n  </p>\n</div>\n","user_guide/index":"<h1>User Guide</h1> <p>These pages serve as a user and administration guide. We highly recommend that you start with the <a class=\"reference internal\" href=\"writing\"><em>Writing Data</em></a> and <a class=\"reference internal\" href=\"query/index\"><em>Querying or Reading Data</em></a> sections to understand how OpenTSDB handles its core purpose of storing and serving time series information. Then follow up with the <a class=\"reference internal\" href=\"quickstart\"><em>Quick Start</em></a> section to play around with getting some data into your OpenTSDB instance. Finally follow up with the other pages for details on the other features of OpenTSDB.</p> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"configuration\">Configuration</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"writing\">Writing Data</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"query/index\">Querying or Reading Data</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"uids\">UIDs and TSUIDs</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"metadata\">Metadata</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"trees\">Trees</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"guis/index\">GUI</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"plugins\">Plugins</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"stats\">Stats</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"definitions\">Definitions</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"backends/index\">Storage</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"cli/index\">CLI Tools</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"utilities/index\">Utilities</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"logging\">Logging</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"troubleshooting\">Troubleshooting</a></li> </ul> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/index.html</a>\n  </p>\n</div>\n","user_guide/definitions":"<h1>Definitions</h1> <p>When it comes to timeseries data, there are lots of terms tossed about that can lead to some confusion. This page is a sort of glossary that helps to define words related to the use of OpenTSDB.</p>  <h2>Cardinality</h2> <p>Cardinality is a mathematical term defined as the number of elements in a set. In database lingo, it's often used to refer to the number of unique items in an index. With regards to OpenTSDB it can refer to:</p> <ul class=\"simple\"> <li>The number of unique time series for a given metric</li> <li>The number of unique tag values associated with a tag name</li> </ul> <p>Due to the nature of the OpenTSDB storage schema, metrics with higher cardinality may take longer return results during query execution than those with lower cardinality. E.g. we may have metric <code class=\"docutils literal\"><span class=\"pre\">foo</span></code> with the tag name <code class=\"docutils literal\"><span class=\"pre\">datacenter</span></code> and there are 100 possible values for datacenter. Then we have metric <code class=\"docutils literal\"><span class=\"pre\">bar</span></code> with the tag <code class=\"docutils literal\"><span class=\"pre\">host</span></code> and 50,000 possible values for host. Metric <code class=\"docutils literal\"><span class=\"pre\">bar</span></code> has a higher cardinality than <code class=\"docutils literal\"><span class=\"pre\">foo</span></code>: 50,000 possible time series for <code class=\"docutils literal\"><span class=\"pre\">bar</span></code> an only 100 for <code class=\"docutils literal\"><span class=\"pre\">foo</span></code>.</p>   <h2>Compaction</h2> <p>An OpenTSDB compaction takes multiple columns in an HBase row and merges them into a single column to reduce disk space. This is not to be confused with HBase compactions where multiple edits to a region are merged into one. OpenTSDB compactions can occur periodically for a TSD after data has been written, or during a query.</p>   <h2>Data Point</h2> <p>Each of the metrics above can be recorded as a number at a specific time. For example, we could record that Sue worked 8 hours at the end of each day. Or that \"mylogo.jpg\" was downloaded 400 times in the past hour. Thus a datapoint consists of:</p> <ul class=\"simple\"> <li>A metric</li> <li>A numeric value</li> <li>A timestamp when the value was recorded</li> <li>One or more sets of tags</li> </ul>   <h2>Metric</h2> <p>A metric is simply the name of a quantitative measurement. Metrics include things like:</p> <ul class=\"simple\"> <li>hours worked by an employee</li> <li>webserver downloads of a file</li> <li>snow accumulation in a region</li> </ul> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Notice that the <code class=\"docutils literal\"><span class=\"pre\">metric</span></code> did not include a specific number or a time. That is becaue a <code class=\"docutils literal\"><span class=\"pre\">metric</span></code> is just a label of what you are measuring. The actual measurements are called <code class=\"docutils literal\"><span class=\"pre\">datapoints</span></code>, as you'll see later.</p> </div> <p>Unfortunately OpenTSDB requires metrics to be named as a single, long word without spaces. Thus metrics are usually recorded using \"dotted notation\". For example, the metrics above would have names like:</p> <ul class=\"simple\"> <li>hours.worked</li> <li>webserver.downloads</li> <li>accumulation.snow</li> </ul>   <h2>Tags</h2> <p>A <code class=\"docutils literal\"><span class=\"pre\">metric</span></code> should be descriptive of what is being measured, but with OpenTSDB, it should not be too specific. Instead, it is better to use <code class=\"docutils literal\"><span class=\"pre\">tags</span></code> to differentiate and organize different items that may share a common metric. Tags are pairs of words that provide a means of associating a metric with a specific item. Each pair consists of a <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> that represents the group or category of the following <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> that represents a specific item, object, location or other noun.</p> <p>Expanding on the metric examples above:</p> <ul class=\"simple\"> <li>A business may have four employees, Sue, John, Kelly and Paul. Therefore we may configure a <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> of <code class=\"docutils literal\"><span class=\"pre\">employee</span></code> with their names as the <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>. These would be recorded as <code class=\"docutils literal\"><span class=\"pre\">employee=sue</span></code>, <code class=\"docutils literal\"><span class=\"pre\">employee=john</span></code> etc.</li> <li>Webservers usually have many files so we could have a <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> of <code class=\"docutils literal\"><span class=\"pre\">file</span></code> to arrive at <code class=\"docutils literal\"><span class=\"pre\">file=logo.jpg</span></code> or <code class=\"docutils literal\"><span class=\"pre\">file=index.php</span></code>\n</li> <li>Snow falls in many regions so we may record a <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> of <code class=\"docutils literal\"><span class=\"pre\">region</span></code> to get <code class=\"docutils literal\"><span class=\"pre\">region=new_england</span></code> or <code class=\"docutils literal\"><span class=\"pre\">region=north_west</span></code>\n</li> </ul>   <h2>Time Series</h2> <p>A collection of two or more data points for a single metric and group of tag name/value pairs.</p>   <h2>Timestamp</h2> <p>Timestamps are simply the absolute time when a value for a given metric was recorded.</p>   <h2>Value</h2> <p>A value represents the actual numeric measurement of the given metric. One of our employees, Sue, worked 8 hours yesterday, thus the value would be <code class=\"docutils literal\"><span class=\"pre\">8</span></code>. There were 1,024 downloads of <code class=\"docutils literal\"><span class=\"pre\">logo.jpg</span></code> from our webserver in the past hour. And 12 inches of snow fell in New England today.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/definitions.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/definitions.html</a>\n  </p>\n</div>\n","user_guide/backends/index":"<h1>Storage</h1> <p>OpenTSDB currently supports Apache HBase as its main storage backend. As of version 2.3, OpenTSDB also works with Google's Bigtable in the cloud (fitting as OpenTSDB is descended from a monitoring system at Google and HBase is descended from HBase). Select the HBase link below to learn about the storage schema or Bigtable to find the configs and setup for use in the cloud.</p> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\">\n<a class=\"reference internal\" href=\"hbase\">HBase Schema</a><ul> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"hbase#data-table-schema\">Data Table Schema</a></li> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"hbase#uid-table-schema\">UID Table Schema</a></li> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"hbase#meta-table-schema\">Meta Table Schema</a></li> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"hbase#tree-table-schema\">Tree Table Schema</a></li> </ul> </li> <li class=\"toctree-l1\">\n<a class=\"reference internal\" href=\"bigtable\">Bigtable</a><ul> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"bigtable#setup\">Setup</a></li> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"bigtable#configuration\">Configuration</a></li> </ul> </li> <li class=\"toctree-l1\">\n<a class=\"reference internal\" href=\"cassandra\">Cassandra</a><ul> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"cassandra#setup\">Setup</a></li> <li class=\"toctree-l2\"><a class=\"reference internal\" href=\"cassandra#configuration\">Configuration</a></li> </ul> </li> </ul> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/backends/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/backends/index.html</a>\n  </p>\n</div>\n","user_guide/cli/index":"<h1>CLI Tools</h1> <p>OpenTSDB consists of a single JAR file that uses a shell script to determine what actiosn the user wants to take. While the most common action is to start the TSD with the <code class=\"docutils literal\"><span class=\"pre\">tsd</span></code> command so that it can run all the time and process RPCs, other commands are available to work with OpenTSDB data. These commands include:</p> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"uid\">uid</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"mkmetric\">mkmetric</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"import\">import</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"query\">query</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"fsck\">fsck</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"scan\">scan</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"search\">search</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tsd\">tsd</a></li> </ul> </div> <p>Accessing a CLI tool is performed from the location of the <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> file, built after compiling OpenTSDB. By default the tsdb file will be located in the <code class=\"docutils literal\"><span class=\"pre\">build</span></code> directory so you may access it via <code class=\"docutils literal\"><span class=\"pre\">./build/tsdb</span></code>. Provide the name of the CLI utility as in <code class=\"docutils literal\"><span class=\"pre\">./build/tsdb</span> <span class=\"pre\">tsd</span></code>.</p>  <h2>Common Parameters</h2> <p>All command line utilities share some common command line parameters:</p> <table class=\"docutils\"> <colgroup> <col width=\"15%\"> <col width=\"5%\"> <col width=\"40%\"> <col width=\"5%\"> <col width=\"35%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>--config</td> <td>String</td> <td>The full or relative path to an OpenTSDB <a class=\"reference internal\" href=\"../configuration\"><em>Configuration</em></a> file. If this parameter is not provided, the command will attempt to load the default config file.</td> <td>See <a class=\"reference internal\" href=\"../configuration\"><em>Configuration</em></a>\n</td> <td>--config=/usr/local/tempconfig.conf</td> </tr> <tr class=\"row-odd\">\n<td>--table</td> <td>String</td> <td>Name of the HBase table where datapoints are stored</td> <td>tsdb</td> <td>--table=prod-tsdb</td> </tr> <tr class=\"row-even\">\n<td>--uidtable</td> <td>String</td> <td>Name of the HBase table where UID information is stored</td> <td>tsdb-uid</td> <td>--uidtable=prod-tsdb-uid</td> </tr> <tr class=\"row-odd\">\n<td>--verbose</td> <td>Boolean</td> <td>For some CLI tools, this command will allow for INFO and above logging per the logback.xml config. Otherwise without this flag, some tools may only log WARNing messages.</td> <td> </td> <td> </td> </tr> <tr class=\"row-even\">\n<td>--zkbasedir</td> <td>String</td> <td>Path under which is the znode for the -ROOT- region</td> <td>/hbase</td> <td>--zkbasedir=/prod/hbase</td> </tr> <tr class=\"row-odd\">\n<td>--read-only</td> <td>Boolean</td> <td>Sets the mode for OpenTSDB</td> <td>false</td> <td>--read-only</td> </tr> <tr class=\"row-even\">\n<td>--zkquorum</td> <td>String</td> <td>Specification of the ZooKeeper quorum to use, i.e. a list of servers and/or ports in the ZooKeeper cluster</td> <td>localhost</td> <td>--zkquorum=zkhost1,zkhost2,zkhost3</td> </tr> <tr class=\"row-odd\">\n<td>--statswport</td> <td>Boolean</td> <td>Directs all TSD stats to be generated with a port tag <code>port=###</code>. Demarcates TSD stats when running multiple instances on the same host.</td> <td>false</td> <td></td> </tr> </tbody> </table>   <h2>Site-specific Configuration</h2> <p>The common parameters above are required by all the CLI commands. It can be tedious to manually type them over and over again. You can instead store typically used values in a file <code class=\"docutils literal\"><span class=\"pre\">./tsdb.local</span></code>. This file is expected to be a shell script and will be sourced by <code class=\"docutils literal\"><span class=\"pre\">./tsdb</span></code> if it exists.</p> <p><em>Setting default values for common parameters</em></p> <p>If, for example, your ZooKeeper quorum is behind the DNS name \"zookeeper.example.com\" (a name with 5 A records), instead of always passing <code class=\"docutils literal\"><span class=\"pre\">--zkquorum=zookeeper.example.com</span></code> to the CLI tool each time you use it, you can create <code class=\"docutils literal\"><span class=\"pre\">./tsdb.local</span></code> with the following contents:</p> <pre data-language=\"bash\">#!/bin/bash\nMY_ARGS='--zkquorum=zookeeper'\nset x $MY_ARGS \"$@\"\nshift\n</pre>\n <p><em>Overriding the timezone of the TSD</em></p> <p>Servers are frequently using UTC as their timezone. By default, the TSD renders graphs using the local timezone of the server. You can override this to have graphs in your local time by specifying a timezone in <code class=\"docutils literal\"><span class=\"pre\">./tsdb.local</span></code>. For example, if you're in California, this will force the TSD to use your timezone:</p> <pre data-language=\"bash\">echo export TZ=PST8PDT &gt;&gt;tsdb.local\n</pre>\n <p>On most Linux and BSD systems, you can look under <code class=\"docutils literal\"><span class=\"pre\">/usr/share/zoneinfo</span></code> for names of timezones supported on your system.</p> <p><em>Changing JVM parameters</em></p> <p>You might want to adjust JVM parameters, for instance to turn on GC activity logging or to set the size of various memory regions. In order to do so, simply set the variable JVMARGS in <code class=\"docutils literal\"><span class=\"pre\">./tsdb.local</span></code>.</p> <p>Here is an example that is recommended for production use:</p> <pre data-language=\"bash\">GCARGS=\"-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\\\n -XX:+PrintTenuringDistribution -Xloggc:/tmp/tsd-gc-`date +%s`.log\"\nif test -t 0; then # if stdin is a tty, don't turn on GC logging.\n  GCARGS=\nfi\n# The Sun JDK caches all name resolution results forever, which is stupid.\n# This forces you to restart your application if any of the backends change\n# IP. Instead tell it to cache names for only 10 minutes at most.\nFIX_DNS='-Dsun.net.inetaddr.ttl=600'\nJVMARGS=\"$JVMARGS $GCARGS $FIX_DNS\"\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/index.html</a>\n  </p>\n</div>\n","user_guide/utilities/index":"<h1>Utilities</h1> <p>This page lists some of the utilities or projects included with OpenTSDB or maintained by the OpenTSDB group. Additional utilities, such as front-ends, clients and publishers can be found on the <a class=\"reference internal\" href=\"../../resources\"><em>Additional Resources</em></a> page or via a simple Google search.</p> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tcollector\">TCollector</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tcollector#collectors-bundled-with-tcollector\">Collectors bundled with <code class=\"docutils literal\"><span class=\"pre\">tcollector</span></code></a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"clean_cache\">clean_cache.sh</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tsddrain\">tsddrain.py</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"varnish\">Load Balancing with Varnish</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"nagios\">Alerting with Nagios</a></li> </ul> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/utilities/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/utilities/index.html</a>\n  </p>\n</div>\n","user_guide/logging":"<h1>Logging</h1> <p>OpenTSDB uses the <a class=\"reference external\" href=\"http://www.slf4j.org/\">SLF4J</a> abstraction layer along with <a class=\"reference external\" href=\"http://logback.qos.ch/\">Logback</a> for logging flexibility. Configuration is performed via an XML file and there are many different formatting, level and destination options.</p>  <h2>Levels</h2> <p>Every log message is accompanied by a descriptive severity level. Levels employed by OpenTSDB include:</p> <ul class=\"simple\"> <li>\n<strong>ERROR</strong> - Something failed, be it invalid data, a failed connection or a bug in the code. You should pay attention to these and figure out what caused the error. Check with the user group for assistance.</li> <li>\n<strong>WARN</strong> - These are often caused by bad user data or something else that was wrong but not a critical error. Look for warnings if you are not receiving the results you expect when using OpenTSDB.</li> <li>\n<strong>INFO</strong> - Informational messages are notifications of expected or normal behavior. They can be useful during troubleshooting. Most logging appenders should be set to <code class=\"docutils literal\"><span class=\"pre\">INFO</span></code>.</li> <li>\n<strong>DEBUG</strong> - If you require further troubleshooting you can enable <code class=\"docutils literal\"><span class=\"pre\">DEBUG</span></code> logging that will give much greater detail about what OpenTSDB is doing under the hood. Be careful enabling this level as it can return a vast amount of data.</li> <li>\n<strong>OFF</strong> - To drop any logging messages from a class, simply set the level to <code class=\"docutils literal\"><span class=\"pre\">OFF</span></code>.</li> </ul>   <h2>Configuration</h2> <p>A file called <code class=\"docutils literal\"><span class=\"pre\">logback.xml</span></code> is included in the <code class=\"docutils literal\"><span class=\"pre\">/src</span></code> directory and copied for distributions. On startup, OpenTSDB will search the class path for this file and if found, load the configuration. The default config from GIT will log INFO level events to console and store the 1,024 latest messages in a round-robin buffer to be accessed from the GUI. However by default, it won't log to disk. Packages built from GIT have file logging enabled by default. As of 2.2, all queries can be logged to a separate file for parsing and automating. This log is disabled by default but can be enabled by setting the proper log level.</p> <div class=\"section\" id=\"appenders\"> <h3>Appenders</h3> <p>Appenders are destinations where logging information is sent. Typically logging configs send results to the console and a file. Optionally you can send logs to Syslog, email, sockets, databases and more. Each appender section defines a destination, a format and an optional trigger. Read about appenders in the <a class=\"reference external\" href=\"http://logback.qos.ch/manual/appenders.html\">Logback Manual</a>.</p> </div> <div class=\"section\" id=\"loggers\"> <h3>Loggers</h3> <p>Loggers determine what data and what level of data is routed to the appenders. Loggers can match a particular Java class namespace and affect all messages emitted from that space. The default OpenTSDB config explicitly lists some loggers for Zookeeper, AsyncHBase and the Async libraries to set their levels to <code class=\"docutils literal\"><span class=\"pre\">INFO</span></code> so as to avoid chatty outputs that are not relevant most of the time. If you enable a plugin and start seeing a lot of messages that you don't care about, add a logger entry to suppress the messages.</p> <p><strong>Query Log</strong> To enable the Query log, find the following section:</p> <pre data-language=\"xml\">&lt;logger name=\"QueryLog\" level=\"OFF\" additivity=\"false\"&gt;\n  &lt;appender-ref ref=\"QUERY_LOG\"/&gt;\n&lt;/logger&gt;\n</pre>\n <p>and set the <code class=\"docutils literal\"><span class=\"pre\">level</span></code> to <code class=\"docutils literal\"><span class=\"pre\">INFO</span></code>.</p> <p><strong>Log File</strong> To enable the main log file, find the following section:</p> <pre data-language=\"xml\">&lt;!--&lt;appender-ref ref=\"FILE\"/&gt;--&gt;\n</pre>\n <p>and remove the comments so it appears as <code class=\"docutils literal\"><span class=\"pre\">&lt;appender-ref</span> <span class=\"pre\">ref=\"FILE\"/&gt;</span></code>.</p> </div> <div class=\"section\" id=\"root\"> <h3>Root</h3> <p>The root section is the catch-all logger that determines that default logging level for all messages that don't match an explicit logger. It also handles routing to the different appenders.</p> </div> <div class=\"section\" id=\"log-to-rotating-file\"> <h3>Log to Rotating File</h3> <pre data-language=\"xml\">&lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;\n  &lt;file&gt;/var/log/opentsdb/opentsdb.log&lt;/file&gt;\n  &lt;append&gt;true&lt;/append&gt;\n\n  &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\"&gt;\n  &lt;fileNamePattern&gt;/var/log/opentsdb/opentsdb.log.%i&lt;/fileNamePattern&gt;\n  &lt;minIndex&gt;1&lt;/minIndex&gt;\n  &lt;maxIndex&gt;3&lt;/maxIndex&gt;\n  &lt;/rollingPolicy&gt;\n\n  &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt;\n  &lt;maxFileSize&gt;128MB&lt;/maxFileSize&gt;\n  &lt;/triggeringPolicy&gt;\n\n  &lt;!-- encoders are assigned the type\n     ch.qos.logback.classic.encoder.PatternLayoutEncoder by default --&gt;\n  &lt;encoder&gt;\n  &lt;pattern&gt;%d{HH:mm:ss.SSS} %-5level [%logger{0}.%M] - %msg%n&lt;/pattern&gt;\n  &lt;/encoder&gt;\n&lt;/appender&gt;\n</pre>\n <p>This appender will write to a log file called <code class=\"docutils literal\"><span class=\"pre\">/var/log/opentsdb/opentsdb.log</span></code>. When the file reaches 128MB in size, it will rotate the log to <code class=\"docutils literal\"><span class=\"pre\">opentsdb.log.1</span></code> and start a new <code class=\"docutils literal\"><span class=\"pre\">opentsdb.log</span></code> file. Once the new log fills up, it bumps <code class=\"docutils literal\"><span class=\"pre\">.1</span></code> to <code class=\"docutils literal\"><span class=\"pre\">.2</span></code>, <code class=\"docutils literal\"><span class=\"pre\">.log</span></code> to <code class=\"docutils literal\"><span class=\"pre\">.1</span></code> and creates a new one. It repeats this until there are four log files in total. The next time the log fills up, the last log is deleted. This way you are gauranteed to only use up to 512MB of disk space. Many other appenders are available so see what fits your needs the best.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/logging.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/logging.html</a>\n  </p>\n</div>\n","user_guide/troubleshooting":"<h1>Troubleshooting</h1> <p>This page lists common issues encountered by users of OpenTSDB along with various troubleshooting steps. If you run into an issue, please check the <a class=\"reference external\" href=\"https://groups.google.com/forum/#!forum/opentsdb\">OpenTSDB Google Group</a> or the <a class=\"reference external\" href=\"https://github.com/OpenTSDB/opentsdb/issues\">Github Issues</a>. If you can't find an answer, please include your operating system, TSD version and HBase version in your question.</p>  <h2>OpenTSDB compactions trigger large .tmp files and region server crashes in HBase</h2> <p>This can be caused if you use millisecond timestamps and write thousands of data points for a single metric in a single hour. In this case, the column qualifier and row key can grow larger than the configured <code class=\"docutils literal\"><span class=\"pre\">hfile.index.block.max.size</span></code>. In this situation we recommend that you disable TSD compaction code. In the future we will support appends which will allow for compacted columns with small qualifiers.</p>   <h2>TSDs are slow to respond after region splits or over long run times</h2> <p>During region splits or region migrations, OpenTSDB's AsyncHBase client will buffer RPCs in memory and attempt to flush them once the regions are back online. Each region has a 10,000 RPC buffer by default and if many regions are down then the RPCs can eventually fill up the TSD heap and cause long garbage collection pauses. If this happens, you can either increase your heap to accommodate more region splits or decrease the NSRE queue size by modifying the <code class=\"docutils literal\"><span class=\"pre\">hbase.nsre.high_watermark</span></code> config parameter in AsyncHBase 1.7 and OpenTSDB 2.2.</p>   <h2>TSDs are stuck in GC or crashing due to Out of Memory Exceptions</h2> <p>There are a number of potential causes for this problem including:</p> <ul class=\"simple\"> <li>Multiple NSREs from HBase - See the section above about TSDs being slow to respond.</li> <li>Too many writes - If the rate of writes to TSD is high, queues can build up in AsyncHBase (see above) or in the compaction queue. If this is the case, check HBase performance and try disabling compactions.</li> <li>Large queries - A very large query with many time series or for a long range can cause the TSD to OOM. Try reducing query size or break large queries up into smaller chunks.</li> </ul><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/troubleshooting.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/troubleshooting.html</a>\n  </p>\n</div>\n","development/index":"<h1>Development</h1> <p>OpenTSDB has a strong and growing base of users running TSDs in production. There are also a number of talented developers creating tools for OpenTSDB or contributing code directly to the project. If you are interested in helping, by adding new features, fixing bugs, adding tools or simply updating documentation, please read the guidelines below. Then sign the contributors agreement and send us a pull request!</p> <p>If you are looking to integrate OpenTSDB with your application, the compiled JAVA library has a consistent and well documented API. Please see <a class=\"reference external\" href=\"http://opentsdb.net/docs/javadoc/index.html\">JAVA API Documentation</a>.</p>  <h2>Guidelines</h2> <ul class=\"simple\"> <li>Please file <a class=\"reference external\" href=\"https://github.com/OpenTSDB/opentsdb/issues\">issues on GitHub</a> after checking to see if anyone has posted a bug already. Make sure your bug reports contain enough details so they can be easily understood by others and quickly fixed.</li> <li>Read the Development page for tips</li> <li>The best way to contribute code is to fork the main repo and <a class=\"reference external\" href=\"https://help.github.com/articles/using-pull-requests\">send a pull request</a> on GitHub.<ul> <li>Bug fixes should be done in the <code class=\"docutils literal\"><span class=\"pre\">master</span></code> branch</li> <li>New features or major changes should be done in the <code class=\"docutils literal\"><span class=\"pre\">next</span></code> branch</li> </ul> </li> <li>Alternatively, you can send a plain-text patch to the <a class=\"reference external\" href=\"https://groups.google.com/forum/#!forum/opentsdb\">mailing list</a>.</li> <li>Before your code changes can be included, please file the <a class=\"reference external\" href=\"https://docs.google.com/spreadsheet/embeddedform?formkey=dFNiOFROLXJBbFBmMkQtb1hNMWhUUnc6MQ\">Contribution License Agreement</a>.</li> <li>Unlike, say, the Apache Software Foundation, we do not require every single code change to be attached to an issue. Feel free to send as many small fixes as you want.</li> <li>Please break down your changes into as many small commits as possible.</li> <li>Please <em>respect the coding style of the code</em> you're changing.<ul> <li>Indent code with 2 spaces, no tabs</li> <li>Keep code to 80 columns</li> <li>Curly brace on the same line as <code class=\"docutils literal\"><span class=\"pre\">if</span></code>, <code class=\"docutils literal\"><span class=\"pre\">for</span></code>, <code class=\"docutils literal\"><span class=\"pre\">while</span></code>, etc</li> <li>Variables need descriptive names <code class=\"docutils literal\"><span class=\"pre\">like_this</span></code> (instead of the typical Java style of <code class=\"docutils literal\"><span class=\"pre\">likeThis</span></code>)</li> <li>Methods named <code class=\"docutils literal\"><span class=\"pre\">likeThis()</span></code> starting with lower case letters</li> <li>Classes named <code class=\"docutils literal\"><span class=\"pre\">LikeThis</span></code>, starting with upper case letters</li> <li>Use the <code class=\"docutils literal\"><span class=\"pre\">final</span></code> keyword as much as you can, particularly in method parameters and returns statements.</li> <li>Avoid checked exceptions as much as possible</li> <li>Always provide the most restrictive visibility to classes and members</li> <li>Javadoc all of your classes and methods. Some folks make use the Java API directly and we'll build docs for the site, so the more the merrier</li> <li>Don't add dependencies to the core OpenTSDB library unless absolutely necessary</li> <li>Add unit tests for any classes/methods you create and verify that your change doesn't break existing unit tests. We know UTs aren't fun, but they are useful</li> </ul> </li> </ul>   <h2>Details</h2> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"development\">General Development</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"plugins\">Plugins</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"http_api\">HTTP API</a></li> </ul> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/development/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/development/index.html</a>\n  </p>\n</div>\n","installation":"<h1>Installation</h1> <p>OpenTSDB may be compiled from source or installed from a package. Releases can be found on <a class=\"reference external\" href=\"https://github.com/OpenTSDB/opentsdb/releases\">Github</a>.</p>  <h2>Runtime Requirements</h2> <p>To actually run OpenTSDB, you'll need to meet the following:</p> <ul class=\"simple\"> <li>A Linux system</li> <li>Java Runtime Environment 1.6 or later</li> <li>HBase 0.92 or later</li> <li>GnuPlot 4.2 or later</li> </ul>   <h2>Installation</h2> <p>First, you need to setup HBase. If you are brand new to HBase and/or OpenTSDB we recommend you test with a stand-alone instance as this is the easiest to get up and running. The best place to start is to follow the <a class=\"reference external\" href=\"https://hbase.apache.org/book/quickstart.html\">Apache Quick Start</a> guide. Alternatively you could try a packaged distribution such as <a class=\"reference external\" href=\"http://www.cloudera.com/content/cloudera/en/products-and-services/cloudera-express.html\">Cloudera's CDH</a> or <a class=\"reference external\" href=\"http://hortonworks.com/products/hdp-2/\">Hortonworks HDP</a></p> <p>Before proceeding with OpenTSDB, make certain that Zookeeper is accessible. One method is to simply telnet to the proper port and execute the <code class=\"docutils literal\"><span class=\"pre\">stats</span></code> command.</p> <pre data-language=\"python\">root@host:~# telnet localhost 2181\nTrying 127.0.0.1...\nConnected to myhost.\nEscape character is '^]'.\nstats\nZookeeper version: 3.4.3-cdh4.0.1--1, built on 06/28/2012 23:59 GMT\nClients:\n\nLatency min/avg/max: 0/0/677\nReceived: 4684478\nSent: 4687034\nOutstanding: 0\nZxid: 0xb00187dd0\nMode: leader\nNode count: 127182\nConnection closed by foreign host.\n</pre>\n <p>If you can't connect to Zookeeper, check IPs and name resolution. HBase can be finicky.</p> <p>If HBase is running, you can choose to install OpenTSDB from a package (available under <a class=\"reference external\" href=\"https://github.com/OpenTSDB/opentsdb/releases\">Releases</a> in Github) or from source using GIT or a source tarball.</p> <div class=\"section\" id=\"compiling-from-source\"> <h3>Compiling From Source</h3> <p>Compilation requirements include:</p> <ul class=\"simple\"> <li>A Linux system</li> <li>Java Development Kit 1.6 or later</li> <li>GnuPlot 4.2 or later</li> <li>Autotools</li> <li>Make</li> <li>Python</li> <li>Git</li> <li>An Internet connection</li> </ul> <p>Download the latest version using <code class=\"docutils literal\"><span class=\"pre\">git</span> <span class=\"pre\">clone</span></code> command or download a release from the site or Github. Then just run the <code class=\"docutils literal\"><span class=\"pre\">build.sh</span></code> script. This script helps run all the processes needed to compile OpenTSDB: it runs <code class=\"docutils literal\"><span class=\"pre\">./bootstrap</span></code> (only once, when you first check out the code), followed by <code class=\"docutils literal\"><span class=\"pre\">./configure</span></code> and <code class=\"docutils literal\"><span class=\"pre\">make</span></code>. The output of the build process is put into a <code class=\"docutils literal\"><span class=\"pre\">build</span></code> folder and JARs required by OpenTSDB will be downloaded.</p> <pre data-language=\"python\">git clone git://github.com/OpenTSDB/opentsdb.git\ncd opentsdb\n./build.sh\n</pre>\n <p>If compilation was successfuly, you should have a tsdb jar file in <code class=\"docutils literal\"><span class=\"pre\">./build</span></code> along with a <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> script. You can now execute command-line tool by invoking <code class=\"docutils literal\"><span class=\"pre\">./build/tsdb</span></code> or you can run <code class=\"docutils literal\"><span class=\"pre\">make</span> <span class=\"pre\">install</span></code> to install OpenTSDB on your system. Should you ever change your mind, there is also <code class=\"docutils literal\"><span class=\"pre\">make</span> <span class=\"pre\">uninstall</span></code>, so there are no strings attached.</p> <p>If you need to distribute OpenTSDB to machines without an Internet connection, call <code class=\"docutils literal\"><span class=\"pre\">./build.sh</span> <span class=\"pre\">dist</span></code> to wrap the build directory into a tarball that you can then copy to additional machines.</p> </div> <div class=\"section\" id=\"source-layout\"> <h3>Source Layout</h3> <p>There are two main branches in the GIT repo. The <code class=\"docutils literal\"><span class=\"pre\">master</span></code> branch is the latest stable release along with any bug fixes that have been committed between releases. Currently, the <code class=\"docutils literal\"><span class=\"pre\">master</span></code> branch is OpenTSDB 2.0.1. The <code class=\"docutils literal\"><span class=\"pre\">next</span></code> branch is the next major or minor version of OpenTSDB with new features and development. When <code class=\"docutils literal\"><span class=\"pre\">next</span></code> is stable, it will be merged into <code class=\"docutils literal\"><span class=\"pre\">master</span></code>. Currently the <code class=\"docutils literal\"><span class=\"pre\">next</span></code> branch is 2.1.0 RC 1. Additional branches may be present and are used for testing or developing specific features.</p> </div> <div class=\"section\" id=\"debian-package\"> <h3>Debian Package</h3> <p>You can generate a Debian package by calling <code class=\"docutils literal\"><span class=\"pre\">sh</span> <span class=\"pre\">build.sh</span> <span class=\"pre\">debian</span></code>. The package will be located at <code class=\"docutils literal\"><span class=\"pre\">./build/opentsdb-2.x.x/opentsdb-2.x.x_all.deb</span></code>. Then simply distribute the package and install it as you regularly would. For example <code class=\"docutils literal\"><span class=\"pre\">dpkg</span> <span class=\"pre\">-i</span> <span class=\"pre\">opentsdb-2.0.0_all.deb</span></code>.</p> <p>The Debian package will create the following directories:</p> <ul class=\"simple\"> <li>/etc/opentsdb - Configuration files</li> <li>/tmp/opentsdb - Temporary cache files</li> <li>/usr/share/opentsdb - Application files</li> <li>/usr/share/opentsdb/bin - The \"tsdb\" startup script that launches a TSD or commandline tools</li> <li>/usr/share/opentsdb/lib - Java JAR library files</li> <li>/usr/share/opentsdb/plugins - Location for plugin files and dependencies</li> <li>/usr/share/opentsdb/static - Static files for the GUI</li> <li>/usr/share/opentsdb/tools - Scripts and other tools</li> <li>/var/log/opentsdb - Logs</li> </ul> <p>Installation includes an init script at <code class=\"docutils literal\"><span class=\"pre\">/etc/init.d/opentsdb</span></code> that can start, stop and restart OpenTSDB. Simply call <code class=\"docutils literal\"><span class=\"pre\">service</span> <span class=\"pre\">opentsdb</span> <span class=\"pre\">start</span></code> to start the tsd and <code class=\"docutils literal\"><span class=\"pre\">service</span> <span class=\"pre\">opentsdb</span> <span class=\"pre\">stop</span></code> to gracefully shutdown. Note after install, the tsd will not be running so that you can edit the configuration file. Edit the config file, then start the TSD.</p> <p>The Debian package also creates an <code class=\"docutils literal\"><span class=\"pre\">opentsdb</span></code> user and group for the TSD to run under for increased security. TSD only requires write permission to the temporary and logging directories. If you can't use the default locations, please change them in <code class=\"docutils literal\"><span class=\"pre\">/etc/opentsdb/opentsdb.conf</span></code> and <code class=\"docutils literal\"><span class=\"pre\">/etc/opentsdb/logback.xml</span></code> respectively and apply the proper permissions for the <code class=\"docutils literal\"><span class=\"pre\">opentsdb</span></code> user.</p> <p>If you install OpenTSDB for the first time, you'll need to create the HBase tables using the script located at <code class=\"docutils literal\"><span class=\"pre\">/usr/share/opentsdb/tools/create_table.sh</span></code>. Follow the steps below.</p> </div> <div class=\"section\" id=\"create-tables\"> <h3>Create Tables</h3> <p>If this is the first time that you are running OpenTSDB with your HBase instance, you first need to create the necessary HBase tables. A simple script is provided to create the proper tables with the ability to enable or disable compression. Execute:</p> <pre data-language=\"python\">env COMPRESSION=NONE HBASE_HOME=path/to/hbase-0.94.X ./src/create_table.sh\n</pre>\n <p>where the <code class=\"docutils literal\"><span class=\"pre\">COMPRESSION</span></code> value is either <code class=\"docutils literal\"><span class=\"pre\">NONE</span></code>, <code class=\"docutils literal\"><span class=\"pre\">LZO</span></code>, <code class=\"docutils literal\"><span class=\"pre\">GZIP</span></code> or <code class=\"docutils literal\"><span class=\"pre\">SNAPPY</span></code>. This will create four tables: <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tsdb-tree</span></code> and <code class=\"docutils literal\"><span class=\"pre\">tsdb-meta</span></code>. If you're just evaluating OpenTSDB, don't worry about compression for now. In production and at scale, make sure you use a valid compression library as it will save on storage tremendously.</p> </div> <div class=\"section\" id=\"start-a-tsd\"> <h3>Start a TSD</h3> <p>OpenTSDB 2.2 works off a configuration file that is shared between the daemon and command line tools. If you compiled from source, copy the <code class=\"docutils literal\"><span class=\"pre\">./src/opentsdb.conf</span></code> file to a proper directory as documented in <a class=\"reference internal\" href=\"user_guide/configuration\"><em>Configuration</em></a> and edit the following, required settings:</p> <ul class=\"simple\"> <li>\n<strong>tsd.http.cachedir</strong> - Path to write temporary files to</li> <li>\n<strong>tsd.http.staticroot</strong> - Path to the static GUI files found in <code class=\"docutils literal\"><span class=\"pre\">./build/staticroot</span></code>\n</li> <li>\n<strong>tsd.storage.hbase.zk_quorum</strong> - If HBase and Zookeeper are not running on the same machine, specify the host and port here.</li> </ul> <p>With the config file written, you can start a tsd with the command:</p> <pre data-language=\"python\">./build/tsdb tsd\n</pre>\n <p>Alternatively, you can also use the following commands to create a temporary directory and pass in only command line flags:</p> <pre data-language=\"python\">tsdtmp=${TMPDIR-'/tmp'}/tsd  # For best performance, make sure\nmkdir -p \"$tsdtmp\"       # your temporary directory uses tmpfs\n./build/tsdb tsd --port=4242 --staticroot=build/staticroot --cachedir=\"$tsdtmp\" --zkquorum=myhost:2181\n</pre>\n <p>At this point you can access the TSD's web interface through <a class=\"reference external\" href=\"http://127.0.0.1:4242\">http://127.0.0.1:4242</a> (if it's running on your local machine).</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The <strong>Cache Directory</strong> stores temporary files generated when a graph is requested via the built-in GUI. These files should be purged periodically to free up space. OpenTSDB doesn't clean up after itself at this time but there is a script that should be run as a cron at least once a day located at <code class=\"docutils literal\"><span class=\"pre\">tools/clean_cache.sh</span></code>.</p> </div> </div>   <h2>Upgrading from 1.x</h2> <p>OpenTSDB 2.2 is fully backwards compatible with 1.x data. We've taken great pains to make sure you can download 2.2, compile, stop your old TSD and start the new one. Your existing tools will read and write to the TSD without a problem. 2.2 introduces two new tables to HBase schema for storing meta-data. From the directory where you downloaded the source (or the tools directory if installed with the Debian package), execute:</p> <pre data-language=\"python\">env COMPRESSION=NONE HBASE_HOME=path/to/hbase-0.94.X ./src/upgrade_1to2.sh\n</pre>\n <p>where <code class=\"docutils literal\"><span class=\"pre\">COMPRESSION</span></code> is the same as your existing production table compression format.</p> <p>While you can start a 2.2 TSD with the same command line options as a 1.0 TSD, we highly recommend that you create a configuration file based on the config included at <code class=\"docutils literal\"><span class=\"pre\">./src/opentsdb.conf</span></code>. Or if you install from a package, you'll want to edit the included default config. The config file includes many more options than are accesible via command line and the file is shared with CLI tools. See <a class=\"reference internal\" href=\"user_guide/configuration\"><em>Configuration</em></a> for details.</p> <p>You do not have to upgrade all of your TSDs to 2.2 at the same time. Some users upgrade their read-only TSDs first to gain access to the full HTTP API and test the new features. Later on you can upgrade the write-only TSDs at leisure. You can also perform a rolling upgrade without issues. Simply stop traffic to one TSD, upgrade it, restore traffic, and continue on until you have upgraded all of your TSDs.</p> <p>If you do perform a rolling upgrade where you have multiple TSDs, heed the following warning:</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Do not write <strong>Annotations</strong> or <strong>Data point with Millisecond Timestamps</strong> while you run a mixture of 1.x and 2.x. Because these data are stored in the same rows as regular data points, they can affect compactions and queries.</p> </div> <p>Before upgrading to 2.x, you may want to upgrade all of your TSDs to OpenTSDB 1.2. This release is fully forwards compatible in that it will ignore annotations and millisecond timestamps and operate as expected. With 1.2 running, if you accidentally record an annotation or millisecond data point, your 1.2 TSDs will operate normally.</p>   <h2>Downgrading</h2> <p>Because we've worked hard to maintain backwards compatability, you can turn off a 2.x TSD and restart your old 1.x TSD. The only exceptions are if you have written annotations or milliseconds as you saw in the warning above. In these cases you must downgrade to 1.2 or later. You may also delete the <code class=\"docutils literal\"><span class=\"pre\">tsdb-tree</span></code> and <code class=\"docutils literal\"><span class=\"pre\">tsdb-meta</span></code> tables if you so desire.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/installation.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/installation.html</a>\n  </p>\n</div>\n","user_guide/configuration":"<h1>Configuration</h1> <p>OpenTSDB can be configured via a file on the local system, via command line arguments or a combination or both.</p>  <h2>Configuration File</h2> <p>The configuration file conforms to the Java properties specification. Configuration names are lower-case, dotted strings without spaces. Each name is followed by an equals sign, then the value for the property. All OpenTSDB properties start with <code class=\"docutils literal\"><span class=\"pre\">tsd.</span></code> Comments or inactive configuration lines are blocked by a hash symbol <code class=\"docutils literal\"><span class=\"pre\">#</span></code>. For example:</p> <pre data-language=\"python\"># List of Zookeeper hosts that manage the HBase cluster\ntsd.storage.hbase.zk_quorum = 192.168.1.100\n</pre>\n <p>will configure the TSD to connect to Zookeeper on <code class=\"docutils literal\"><span class=\"pre\">192.168.1.100</span></code>.</p> <p>When combining configuration files and command line arguments, the order of processing is as follows:</p> <ol class=\"arabic simple\"> <li>Default values are loaded</li> <li>Configuration file values are loaded, overriding default values</li> <li>Command line parameters are loaded, overriding config file and default values</li> </ol>   <h2>File Locations</h2> <p>You can use the <code class=\"docutils literal\"><span class=\"pre\">--config</span></code> command line argument to specify the full path to a configuration file. Otherwise if not specified, OpenTSDB and some of the command-line tools will attempt to search for a valid configuration file in the following locations:</p> <ul class=\"simple\"> <li>./opentsdb.conf</li> <li>/etc/opentsdb.conf</li> <li>/etc/opentsdb/opentsdb.conf</li> <li>/opt/opentsdb/opentsdb.conf</li> </ul> <p>In the event that a valid configuration file cannot be found and the required properties are not set, the TSD will not start. Please see the properties table below for a list of required configuration settings.</p>   <h2>Properties</h2> <p>The following is a table of configuration options for all tools. When applicable, the corresponding command line override is provided. Please note that individual command line tools may have their own values so see their documentation for details.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">For additional parameters used for tuning the AsyncHBase client, see <a class=\"reference external\" href=\"http://opentsdb.github.io/asynchbase/docs/build/html/configuration.html\">AsyncHBase Configuration</a></p> </div> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"55%\"> <col width=\"5%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Property</th> <th class=\"head\">Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">CLI</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>tsd.core.auto_create_metrics</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not a data point with a new metric will assign a UID to the metric. When false, a data point with a metric that is not in the database will be rejected and an exception will be thrown.</td> <td>False</td> <td>--auto-metric</td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.auto_create_tagks <em>(2.1)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not a data point with a new tag name will assign a UID to the tagk. When false, a data point with a tag name that is not in the database will be rejected and an exception will be thrown.</td> <td>True</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.core.auto_create_tagvs <em>(2.1)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not a data point with a new tag value will assign a UID to the tagv. When false, a data point with a tag value that is not in the database will be rejected and an exception will be thrown.</td> <td>True</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.connections.limit <em>(2.3)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>Sets the maximum number of connections a TSD will handle, additional connections are immediately closed.</td> <td>0</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.core.meta.enable_realtime_ts</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable real-time TSMeta object creation. See <a class=\"reference internal\" href=\"metadata\"><em>Metadata</em></a>\n</td> <td>False</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.meta.enable_realtime_uid</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable real-time UIDMeta object creation. See <a class=\"reference internal\" href=\"metadata\"><em>Metadata</em></a>\n</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.core.meta.enable_tsuid_incrementing</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable tracking of TSUIDs by incrementing a counter every time a data point is recorded. See <a class=\"reference internal\" href=\"metadata\"><em>Metadata</em></a> (Overrides \"tsd.core.meta.enable_tsuid_tracking\")</td> <td>False</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.meta.enable_tsuid_tracking</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable tracking of TSUIDs by storing a <code class=\"docutils literal\"><span class=\"pre\">1</span></code> with the current timestamp every time a data point is recorded. See <a class=\"reference internal\" href=\"metadata\"><em>Metadata</em></a>\n</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.core.plugin_path</td> <td>String</td> <td>Optional</td> <td>A path to search for plugins when the TSD starts. If the path is invalid, the TSD will fail to start. Plugins can still be enabled if they are in the class path.</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.preload_uid_cache <em>(2.1)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Enables pre-population of the UID caches when starting a TSD.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.core.preload_uid_cache.max_entries <em>(2.1)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The number of rows to scan for UID pre-loading.</td> <td>300,000</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.stats_with_port <em>(2.3)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Directs all TSD stats to be generated with a port tag <code>port=###</code>. Demarcates TSD stats when running multiple instances on the same host.</td> <td>False</td> <td>--statswport</td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.storage_exception_handler.enable <em>(2.2)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable the configured storage exception handler plugin.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.core.storage_exception_handler.plugin <em>(2.2)</em>\n</td> <td>String</td> <td>Optional</td> <td>The full class name of the storage exception handler plugin you wish to use.</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.timezone</td> <td>String</td> <td>Optional</td> <td>A localized timezone identification string used to override the local system timezone used when converting absolute times to UTC when executing a query. This does not affect incoming data timestamps. E.g. America/Los_Angeles</td> <td>System Configured</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.core.tree.enable_processing</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable processing new/edited TSMeta through tree rule sets</td> <td>false</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.core.uid.random_metrics <em>(2.2)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to randomly assign UIDs to new metrics as they are created</td> <td>false</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.http.cachedir</td> <td>String</td> <td>Required</td> <td>The full path to a location where temporary files can be written. E.g. /tmp/opentsdb</td> <td> </td> <td>--cachedir</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.query.allow_delete</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to allow deleting data points from storage during query time.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.query.enable_fuzzy_filter</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable the FuzzyRowFilter for HBase when making queries using the <code class=\"docutils literal\"><span class=\"pre\">explicitTags</span></code> flag.</td> <td>True</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.request.cors_domains</td> <td>String</td> <td>Optional</td> <td>A comma separated list of domain names to allow access to OpenTSDB when the <code class=\"docutils literal\"><span class=\"pre\">Origin</span></code> header is specified by the client. If empty, CORS requests are passed through without validation. The list may not contain the public wildcard <code class=\"docutils literal\"><span class=\"pre\">*</span></code> and specific domains at the same time.</td> <td> </td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.http.request.cors_headers <em>(2.1)</em>\n</td> <td>String</td> <td>Optional</td> <td>A comma separated list of headers sent to clients when executing a CORs request. The literal value of this option will be passed to clients.</td> <td>Authorization, Content-Type, Accept, Origin, User-Agent, DNT, Cache-Control, X-Mx-ReqToken, Keep-Alive, X-Requested-With, If-Modified-Since</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.request.enable_chunked</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable incoming chunk support for the HTTP RPC</td> <td>false</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.http.request.max_chunk</td> <td>Integer</td> <td>Optional</td> <td>The maximum request body size to support for incoming HTTP requests when chunking is enabled.</td> <td>4096</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.rpc.plugins <em>(2.2)</em>\n</td> <td>String</td> <td>Optional</td> <td>A comma delimited list of RPC plugins to load when starting a TSD. Must contain the entire class name.</td> <td> </td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.http.show_stack_trace</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to return the stack trace with an API query response when an exception occurs.</td> <td>false</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.staticroot</td> <td>String</td> <td>Required</td> <td>Location of a directory where static files, such as JavaScript files for the web interface, are located. E.g. /opt/opentsdb/staticroot</td> <td> </td> <td>--staticroot</td> </tr> <tr class=\"row-even\">\n<td>tsd.mode <em>(2.1)</em>\n</td> <td>String</td> <td>Optional</td> <td>Whether or not the TSD will allow writing data points. Must be either <code class=\"docutils literal\"><span class=\"pre\">rw</span></code> to allow writing data or <code class=\"docutils literal\"><span class=\"pre\">ro</span></code> to block data point writes. Note that meta data such as UIDs can still be written/modified.</td> <td>rw</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.network.async_io</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to use NIO or traditional blocking IO</td> <td>True</td> <td>--async-io</td> </tr> <tr class=\"row-even\">\n<td>tsd.network.backlog</td> <td>Integer</td> <td>Optional</td> <td>The connection queue depth for completed or incomplete connection requests depending on OS. The default may be limited by the 'somaxconn' kernel setting or set by Netty to 3072.</td> <td>See Description</td> <td>--backlog</td> </tr> <tr class=\"row-odd\">\n<td>tsd.network.bind</td> <td>String</td> <td>Optional</td> <td>An IPv4 address to bind to for incoming requests. The default is to listen on all interfaces. E.g. 127.0.0.1</td> <td>0.0.0.0</td> <td>--bind</td> </tr> <tr class=\"row-even\">\n<td>tsd.network.keep_alive</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to allow keep-alive connections</td> <td>True</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.network.port</td> <td>Integer</td> <td>Required</td> <td>The TCP port to use for accepting connections</td> <td> </td> <td>--port</td> </tr> <tr class=\"row-even\">\n<td>tsd.network.reuse_address</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to allow reuse of the bound port within Netty</td> <td>True</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.network.tcp_no_delay</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to disable TCP buffering before sending data</td> <td>True</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.network.worker_threads</td> <td>Integer</td> <td>Optional</td> <td>The number of asynchronous IO worker threads for Netty</td> <td><em>#CPU cores * 2</em></td> <td>--worker-threads</td> </tr> <tr class=\"row-odd\">\n<td>tsd.no_diediedie <em>(2.1)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Enable or disable the <code class=\"docutils literal\"><span class=\"pre\">diediedie</span></code> HTML and ASCII commands to shutdown a TSD.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.query.allow_simultaneous_duplicates <em>(2.2)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to allow simultaneous duplicate queries from the same host. If disabled, a second query that comes in matching one already running will receive an exception.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.query.filter.expansion_limit <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The maximum number of tag values to include in the regular expression sent to storage during scanning for data. A larger value means more computation on the HBase region servers.</td> <td>4096</td> <td>1024</td> </tr> <tr class=\"row-even\">\n<td>tsd.query.skip_unresolved_tagvs <em>(2.2)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to continue querying when the query includes a tag value that hasn't been assigned a UID yet and may not exist.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.query.timeout <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>How long, in milliseconds, before canceling a running query. A value of 0 means queries will not timeout.</td> <td>0</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.rpc.plugins</td> <td>String</td> <td>Optional</td> <td>A comma delimited list of RPC plugins to load when starting a TSD. Must contain the entire class name.</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.rtpublisher.enable</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable a real time publishing plugin. If true, you must supply a valid <code class=\"docutils literal\"><span class=\"pre\">tsd.rtpublisher.plugin</span></code> class name</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.rtpublisher.plugin</td> <td>String</td> <td>Optional</td> <td>The class name of a real time publishing plugin to instantiate. If <code class=\"docutils literal\"><span class=\"pre\">tsd.rtpublisher.enable</span></code> is set to false, this value is ignored. E.g. net.opentsdb.tsd.RabbitMQPublisher</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.search.enable</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable search functionality. If true, you must supply a valid <code class=\"docutils literal\"><span class=\"pre\">tsd.search.plugin</span></code> class name</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.search.plugin</td> <td>String</td> <td>Optional</td> <td>The class name of a search plugin to instantiate. If <code class=\"docutils literal\"><span class=\"pre\">tsd.search.enable</span></code> is set to false, this value is ignored. E.g. net.opentsdb.search.ElasticSearch</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.stats.canonical</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not the FQDN should be returned with statistics requests. The default stats are returned with <code class=\"docutils literal\"><span class=\"pre\">host=&lt;hostname&gt;</span></code> which is not guaranteed to perform a lookup and return the FQDN. Setting this to true will perform a name lookup and return the FQDN if found, otherwise it may return the IP. The stats output should be <code class=\"docutils literal\"><span class=\"pre\">fqdn=&lt;hostname&gt;</span></code>\n</td> <td>false</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.compaction.flush_interval <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>How long, in seconds, to wait in between compaction queue flush calls</td> <td>10</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.compaction.flush_speed <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>A multiplier used to determine how quickly to attempt flushing the compaction queue. E.g. a value of 2 means it will try to flush the entire queue within 30 minutes. A value of 1 would take an hour.</td> <td>2</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.compaction.max_concurrent_flushes <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The maximum number of compaction calls inflight to HBase at any given time</td> <td>10000</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.compaction.min_flush_threshold <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>Size of the compaction queue that must be exceeded before flushing is triggered</td> <td>100</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.enable_appends <em>(2.2)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to append data to columns when writing data points instead of creating new columns for each value. Avoids the need for compactions after each hour but can use more resources on HBase.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.enable_compaction</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to enable compactions</td> <td>True</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.fix_duplicates <em>(2.1)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to accept the last written value when parsing data points with duplicate timestamps. When enabled in conjunction with compactions, a compacted column will be written with the latest data points.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.flush_interval</td> <td>Integer</td> <td>Optional</td> <td>How often, in milliseconds, to flush the data point storage write buffer</td> <td>1000</td> <td>--flush-interval</td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.hbase.data_table</td> <td>String</td> <td>Optional</td> <td>Name of the HBase table where data points are stored</td> <td>tsdb</td> <td>--table</td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.hbase.meta_table</td> <td>String</td> <td>Optional</td> <td>Name of the HBase table where meta data are stored</td> <td>tsdb-meta</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.hbase.prefetch_meta <em>(2.2)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to prefetch the regions for the TSDB tables before starting the network interface. This can improve performance.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.hbase.tree_table</td> <td>String</td> <td>Optional</td> <td>Name of the HBase table where tree data are stored</td> <td>tsdb-tree</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.hbase.uid_table</td> <td>String</td> <td>Optional</td> <td>Name of the HBase table where UID information is stored</td> <td>tsdb-uid</td> <td>--uidtable</td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.hbase.zk_basedir</td> <td>String</td> <td>Optional</td> <td>Path under which the znode for the -ROOT- region is located</td> <td>/hbase</td> <td>--zkbasedir</td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.hbase.zk_quorum</td> <td>String</td> <td>Optional</td> <td>A comma-separated list of ZooKeeper hosts to connect to, with or without port specifiers. E.g. <code class=\"docutils literal\"><span class=\"pre\">192.168.1.1:2181,192.168.1.2:2181</span></code>\n</td> <td>localhost</td> <td>--zkquorum</td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.repair_appends <em>(2.2)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to re-write appended data point columns at query time when the columns contain duplicate or out of order data.</td> <td>False</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.max_tags <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The maximum number of tags allowed per data point. <strong>NOTE</strong> Please be aware of the performance tradeoffs of overusing tags <a class=\"reference internal\" href=\"writing\"><em>Writing Data</em></a>\n</td> <td>8</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.salt.buckets <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The number of salt buckets used to distribute load across regions. <strong>NOTE</strong> Changing this value after writing data may cause TSUID based queries to fail.</td> <td>20</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.salt.width <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The width, in bytes, of the salt prefix used to indicate which bucket a time series belongs in. A value of 0 means salting is disabled. <strong>WARNING</strong> Do not change after writing data to HBase or you will corrupt your tables and not be able to query any more.</td> <td>0</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.uid.width.metric <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The width, in bytes, of metric UIDs. <strong>WARNING</strong> Do not change after writing data to HBase or you will corrupt your tables and not be able to query any more.</td> <td>3</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>tsd.storage.uid.width.tagk <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The width, in bytes, of tag name UIDs. <strong>WARNING</strong> Do not change after writing data to HBase or you will corrupt your tables and not be able to query any more.</td> <td>3</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>tsd.storage.uid.width.tagv <em>(2.2)</em>\n</td> <td>Integer</td> <td>Optional</td> <td>The width, in bytes, of tag value UIDs. <strong>WARNING</strong> Do not change after writing data to HBase or you will corrupt your tables and not be able to query any more.</td> <td>3</td> <td> </td> </tr> </tbody> </table>   <h2>Data Types</h2> <p>Some configuration values require special consideration:</p> <ul> <li>\n<p class=\"first\">Booleans - The following literals will parse to <code class=\"docutils literal\"><span class=\"pre\">True</span></code>:</p> <ul class=\"simple\"> <li><code class=\"docutils literal\"><span class=\"pre\">1</span></code></li> <li><code class=\"docutils literal\"><span class=\"pre\">true</span></code></li> <li><code class=\"docutils literal\"><span class=\"pre\">yes</span></code></li> </ul> <p>Any other values will result in a <code class=\"docutils literal\"><span class=\"pre\">False</span></code>. Parsing is case insensitive</p> </li> <li>\n<p class=\"first\">Strings - Strings, even those with spaces, do not require quotation marks, but some considerations apply:</p> <ul> <li>\n<p class=\"first\">Special characters must be escaped with a backslash include: <code class=\"docutils literal\"><span class=\"pre\">#</span></code>, <code class=\"docutils literal\"><span class=\"pre\">!</span></code>, <code class=\"docutils literal\"><span class=\"pre\">=</span></code>, and <code class=\"docutils literal\"><span class=\"pre\">:</span></code> E.g.:</p> <pre data-language=\"python\">my.property = Hello World\\!\n</pre>\n </li> <li>\n<p class=\"first\">Unicode characters must be escaped with their hexadecimal representation, e.g.:</p> <pre data-language=\"python\">my.property = \\u0009\n</pre>\n </li> </ul> </li> </ul><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/configuration.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/configuration.html</a>\n  </p>\n</div>\n","user_guide/uids":"<h1>UIDs and TSUIDs</h1> <p>In OpenTSDB, when you write a timeseries data point, it is always associated with a metric and at least one tag name/value pair. Each metric, tag name and tag value is assigned a unique identifier (UID) the first time it is encountered or when explicitly assigned via the API or a CLI tool. The combination of metric and tag name/value pairs create a timeseries UID or TSUID.</p>  <h2>UID</h2> <p>Types of UID objects include:</p> <ul class=\"simple\"> <li>\n<strong>metric</strong> - A metric such as <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.0</span></code> or <code class=\"docutils literal\"><span class=\"pre\">trades.per.second</span></code>\n</li> <li>\n<strong>tagk</strong> - A tag name such as <code class=\"docutils literal\"><span class=\"pre\">host</span></code> or <code class=\"docutils literal\"><span class=\"pre\">symbol</span></code>. This is always the \"key\" (the first value) in a tag key/value pair.</li> <li>\n<strong>tagv</strong> - A tag value such as <code class=\"docutils literal\"><span class=\"pre\">web01</span></code> or <code class=\"docutils literal\"><span class=\"pre\">goog</span></code>. This is always the \"value\" (the second value) in a tag key/value pair.</li> </ul> <div class=\"section\" id=\"assignment\"> <h3>Assignment</h3> <p>The UID is a positive integer that is unique to the name of the UID object and it's type. Within the storage system there is a counter that is incremented for each <code class=\"docutils literal\"><span class=\"pre\">metric</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> and <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>. When you create a new <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table, this counter is set to 0 for each type. So if you put a new data point with a metric of <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.0</span></code> and a tag pair of <code class=\"docutils literal\"><span class=\"pre\">host=web01</span></code> you will have 3 new UID objects, each with a UID of 1.</p> <p>UIDs are assigned automatically for new <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> and <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> objects when data points are written to a TSD. <code class=\"docutils literal\"><span class=\"pre\">metric</span></code> objects also receive new UIDs but only if the <em>auto metric</em> setting has been configured to <code class=\"docutils literal\"><span class=\"pre\">true</span></code>. Otherwise data points with new metrics are rejected. The UIDs are looked up in a cached map for every incoming data point. If the lookup fails, then the TSD will attempt to assign a new UID.</p> </div> <div class=\"section\" id=\"storage\"> <h3>Storage</h3> <p>By default, UIDs are encoded on 3 bytes in storage, giving a maximum unique ID of 16,777,215 for each UID type. This is done to reduce the amount of space taken up in storage and to reduce the memory footprint of a TSD. For the vast majority of users, 16 million unique metrics, 16 million unique tag names and 16 million unique tag values should be enough. But if you do need more of a particular type, you can modify the OpenTSDB source code and recompile with 4 bytes or more. As of version 2.2 you can override the UID size via the config file.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">If you do adjust the byte encoding number, you must start with a fresh <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> and fresh <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table, otherwise the results will be unexpected. If you have data in an existing setup, you must export it, drop all tables, create them from scratch and re-import the data.</p> </div> </div> <div class=\"section\" id=\"display\"> <h3>Display</h3> <p>UIDs can be displayed in a few ways. The most common method is via the HTTP API where the 3 bytes of UID data are encoded as a hexadecimal string. For example, the UID of <code class=\"docutils literal\"><span class=\"pre\">1</span></code> would be written in binary as <code class=\"docutils literal\"><span class=\"pre\">000000000000000000000001</span></code>. As an array of unsigned byte values, you could imagine it as <code class=\"docutils literal\"><span class=\"pre\">[0,</span> <span class=\"pre\">0,</span> <span class=\"pre\">1]</span></code>. Encoded as a hex string, the value would be <code class=\"docutils literal\"><span class=\"pre\">000001</span></code> where the string is padded with 0s for each byte. The UID of 255 would result in a hex value of <code class=\"docutils literal\"><span class=\"pre\">0000FF</span></code> (or as a byte array, <code class=\"docutils literal\"><span class=\"pre\">[0,</span> <span class=\"pre\">0,</span> <span class=\"pre\">255]</span></code>. To convert between a decimal UID to a hex, use any kind of hex conversion tool you prefer and put 0s in front of the resulting value until you have a total of 6 characters. To convert from a hex UID to decimal, simply drop any 0s from the front, then use a tool to convert the hex string to a decimal.</p> <p>In some CLI tools and log files, a UID may be displayed as an array of signed bytes (thanks to Java) such as the above example of <code class=\"docutils literal\"><span class=\"pre\">[0,</span> <span class=\"pre\">0,</span> <span class=\"pre\">1]</span></code> or <code class=\"docutils literal\"><span class=\"pre\">[0,</span> <span class=\"pre\">0,</span> <span class=\"pre\">-28]</span></code>. To convert from this signed array to an an array of unsigned bytes, then to hex. For example, <code class=\"docutils literal\"><span class=\"pre\">-28</span></code> would be binary <code class=\"docutils literal\"><span class=\"pre\">10011100</span></code> which results in a decimal value of <code class=\"docutils literal\"><span class=\"pre\">156</span></code> and a hex value of <code class=\"docutils literal\"><span class=\"pre\">9C</span></code>.</p> </div> <div class=\"section\" id=\"modification\"> <h3>Modification</h3> <p>UIDs can be renamed or deleted. Renaming can be accomplished via the CLI and is generally safe but will affect EVERY time series that includes the renamed ID. E.g. if we have a series <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=web01</span></code> and another <code class=\"docutils literal\"><span class=\"pre\">apache.requests</span> <span class=\"pre\">host=web01</span></code> and rename the <code class=\"docutils literal\"><span class=\"pre\">web01</span></code> tag value to <code class=\"docutils literal\"><span class=\"pre\">web01.mysite.org</span></code>, then both series will now reflect the new host name and all queries referring to the old name must be updated.. If a data point comes in that has the previous string, a new UID will be assigned.</p> <p>Deleting UIDs can be tricky as of version 2.2. Deleting a metric is safe in that users may no longer query for the data and it won't show up in calls to the suggest API. However deleting a tag name or value can cause queries to fail. E.g. if you have time series for the metric <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span></code> with hosts <code class=\"docutils literal\"><span class=\"pre\">web01</span></code>, <code class=\"docutils literal\"><span class=\"pre\">web02</span></code>, <code class=\"docutils literal\"><span class=\"pre\">web03</span></code>, etc. and you delete the UID for <code class=\"docutils literal\"><span class=\"pre\">web02</span></code>, any query that would scan over data that includes the series <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=web02</span></code> will throw an exception to the user because the data remains in storage. We highly recommend you run an FSCK with a query to repair such issues.</p> </div> <div class=\"section\" id=\"why-uids\"> <h3>Why UIDs?</h3> <p>This question is asked often enough it's worth laying out the reasons here. Looking up or assigning a UID takes up precious cycles in the TSD so folks wonder if it wouldn't be faster to use the raw name of the metric or computer a hash. Indeed, from a write perspective it would be slightly faster, but there are a number of drawbacks that become apparent.</p> </div>   <h2>Raw Names</h2> <p>Since OpenTSDB uses HBase as the storage layer, you could use strings as the row key. Following the current schema, you may have a row key that looked like <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.0.user</span> <span class=\"pre\">1292148000</span> <span class=\"pre\">host=websv01.lga.mysite.com</span> <span class=\"pre\">owner=operations</span></code>. Ordering would be similar to the existing schema, but now you're using up 70 bytes of storage each hour instead of 19. Additionally, the row key must be written and returned with every query to HBase, so you're increasing your network usage as well. So resorting to UIDs can help save space.</p>   <h2>Hashes</h2> <p>Another idea is to simply bump up the UIDs to 4 bytes then calculate a hash on the strings and store the hash with forward and reverse maps as we currently do. This would certainly reduce the amount of time it takes to assign a UID, but there are a few problems. First, you will encounter collisions where different names return the same hash. You could try different algorithms and even try increasing the hash to 8 bytes, but you'll always have the issue of colliding hashes. Second, you are now adding a hash calculation to every data put since it would have to determine the hash, then lookup the hash in the UID table to see if it's been mapped yet. Right now, each data point only performs the lookup. Third, you can't pre-split your HBase regions as easily. If you know you will have roughly 800 metrics in your system (the tags are irrelevant for this purpose), you can pre-split your HBase table to evenly distribute those 800 metrics and increase your initial write performance.</p>   <h2>TSUIDs</h2> <p>When a data point is written to OpenTSDB, the row key is formatted as <code class=\"docutils literal\"><span class=\"pre\">&lt;metric_UID&gt;&lt;timestamp&gt;&lt;tagk1_UID&gt;&lt;tagv1_UID&gt;[...&lt;tagkN_UID&gt;&lt;tagvN_UID&gt;]</span></code>. By simply dropping the timestamp from the row key, we have a long array of UIDs that combined, form a unique timeseries ID. Encoding the bytes as a hex string will give us a useful TSUID that can be passed around various API calls. Thus from our UID example above where each metric, tag name and value has a UID of 1, our TSUID, encoded as a hexadecimal string, would be <code class=\"docutils literal\"><span class=\"pre\">000001000001000001</span></code>.</p> <p>While this TSUID format may be long and ugly, particularly with all of the 0s for early UIDs, there are a few reasons why this is useful:</p> <ul class=\"simple\"> <li>If you know the width of each UID (by default 3 bytes as stated above), then you can easily parse the UID for each metric, tag name and value from the UID string.</li> <li>Assigning a unique numeric ID for each timeseries creates issues with lock contention and/or synchronization issues where a timeseries may be missed if the UID could not be incremented.</li> </ul><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/uids.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/uids.html</a>\n  </p>\n</div>\n","user_guide/guis/index":"<h1>GUI</h1> <p>Currently OpenTSDB offers a simple built-in GUI accessible by opening your browser and navigating to the host and port where the TSD is running. For example, if you are running a TSD on your local computer on port 4242, simply navigate to <code class=\"docutils literal\"><span class=\"pre\">http://localhost:4242</span></code>. While the GUI won't win awards for beauty, it provides a quick means of building a useful graph with the data in your system.</p>  <h2>Interface</h2> <img alt=\"../../_images/gui_sections.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_sections.png\"> <p>There are three main areas of the GUI:</p> <ol class=\"arabic simple\"> <li>The notification area and tab area that serves as a menu</li> <li>The query builder that lets you select what will be displayed and how</li> <li>The graph area that displays query results</li> </ol> <div class=\"section\" id=\"menu\"> <h3>Menu</h3> <p>The menu is a group of tabs that can be clicked for different options.</p> <ul class=\"simple\"> <li>Graph - This is the default that lets you issue a query and generate a graph</li> <li>Stats - This tab will display a list of statistics about the running TSD. The same stats can be retrieved via the <code class=\"docutils literal\"><span class=\"pre\">/stats</span></code> or <code class=\"docutils literal\"><span class=\"pre\">/api/stats</span></code> endpoints.</li> <li>Logs - If Logback is configured, this tab will show you a list of the latest 1,024 log entries for the TSD.</li> <li>Version - Displays version information about the TSD</li> </ul> </div> <div class=\"section\" id=\"errors\"> <h3>Errors</h3> <p>When building a graph, if an error occurs, a message will appear above the menu. Click on the arrow to expand the message and determine what the error was.</p> <img alt=\"../../_images/gui_error.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_error.png\"> </div>   <h2>Query Builder</h2> <p>You'll likely spend a lot of time in this area since there are a number of options to play with. You'll likely want to start by choosing one or more metrics and tags to graph.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If you start by picking a start and end time then as soon as you enter a metric, the TSD will start to graph <em>every time series for that metric</em>. This will show the <code class=\"docutils literal\"><span class=\"pre\">Loading</span> <span class=\"pre\">Graph...</span></code> status and may take a long time before you can do anything else. So skip the times and choose your metrics first.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Also note that changes to any field in this section will cause a graph reload, so be aware if you're graph takes a long time to load.</p> </div> <div class=\"section\" id=\"metrics-section\"> <h3>Metrics Section</h3> <img alt=\"../../_images/gui_metric_section.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_metric_section.png\"> <p>This area is where you choose the metrics, optional tags, aggregation function and a possible down sampler for your graph. Along the top are a pair of blue tabs. Each graph can display multiple metrics and the tabs organize the different sub queries. Each graph requires at least one metric so you'll choose that metric in the first tab. To add another metric to your graph, click the <code class=\"docutils literal\"><span class=\"pre\">+</span></code> tab and you'll be able to setup another sub query. If you have configured multiple metrics, simply click on the tab that corresponds to the metric you want to modify. The tab will display a subset of the metric name it is associated with.</p> <p>The <strong>Metric</strong> box is where you'll choose a metric. This field auto-completes as you type just like a modern web browser. Auto-complete is generally case sensitive so only metrics matching the case provided will be displayed. By default, only the 25 top matching entries will be returned so you may not see all of the possible choices as you type. Either click on the entry you want when it appears or keep typing until you have entire metric in the box.</p> <img alt=\"../../_images/gui_autocomplete.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_autocomplete.png\"> <p>Recall from the <a class=\"reference internal\" href=\"../query/index\"><em>Querying or Reading Data</em></a> documentation that if you only provide a metric without any tags, <em>every time series with that metric</em> will be aggregated in the results. If you want to drill down, supply one or more <strong>Tags</strong> to filter or group the results. A new metric section will have two boxes next to <strong>Tags</strong>. The left box is for the tag name or <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> value, e.g. <code class=\"docutils literal\"><span class=\"pre\">host</span></code> or <code class=\"docutils literal\"><span class=\"pre\">symbol</span></code>. The right hand box is for the tag value or <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>, e.g. <code class=\"docutils literal\"><span class=\"pre\">webserver01</span></code> or <code class=\"docutils literal\"><span class=\"pre\">google</span></code>. When you add a tag, another pair of boxes will appear so that you can keep adding tags to filter as much as necessary.</p> <p>Both tag name and value boxes also auto-complete in the same way as the <strong>Metric</strong> box. However each auto-complete will show <em>all</em> of the results for the name or value, not just the values that would apply to a specific metric or tag name. In future versions we may be able to implement such a mapping feature but currently you'll have to sort through all of the values.</p> <p>With version 2.2, a checkbox to the right of each pair of check boxes is used to determine if the results should be grouped by the tag filter (checked) or aggregated (unchecked). The boxes are checked by default to exhibit the behavior of TSD prior to 2.2.</p> <p>The tag value box can use grouping operators such as the <code class=\"docutils literal\"><span class=\"pre\">*</span></code> and the <code class=\"docutils literal\"><span class=\"pre\">|</span></code>. See <a class=\"reference internal\" href=\"../query/index\"><em>Querying or Reading Data</em></a> for details. Tag value boxes can also use filters as of version 2.2. E.g. you can enter \"wildcard(webserver*)\" as a tag value and it will match all hosts starting with \"webserver\".</p> <p>The <strong>Rate</strong> box allows you to convert all of the time series for the metric to a rate of change value. By default this option is turned off.</p> <p><strong>Rate ctr</strong> Enables the rate options boxes below and indicate that the metric graphed is a monotonically increasing counter. If so, you can choose to supply a maximum value (<strong>Rate Ctr Max</strong>) for the counter so that when it rolls over, the graph will show the proper value instead of a negative number. Likewise you can choose to set a reset value (<strong>Rate Ctr Reset</strong>) to replace values with a zero if the rate is greater than the value. To avoid negative spikes it's generally save to set the rate counter with a reset value of 1.</p> <p>For metrics or time series with different scales, you can select the <strong>Right Axis</strong> check box to add another axis to the right of the graph for the metric's time series. This can make graphs much more readable if the scales differ greatly.</p> <p>The <strong>Aggregator</strong> box is a drop-down list of aggregation functions used to manipulate the data for multiple time series associated with the sub query. The default aggregator is <em>sum</em> but you can choose from a number of other options.</p> <p>The <strong>Downsample</strong> section is used to reduce the number of data points displayed on the graph. By default, GnuPlot will place a character, such as the <code class=\"docutils literal\"><span class=\"pre\">+</span></code> or <code class=\"docutils literal\"><span class=\"pre\">x</span></code> at each data point of a graph. When the time span is wide and there are many data points, the graph can grow pretty thick and ugly. Use down sampling to reduce the number of points. Simply choose an aggregation function from the drop down list, then enter a time interval in the second box. The interval must follow the relative date format (without the <code class=\"docutils literal\"><span class=\"pre\">-ago</span></code> component). For example, to downsample on an hour, enter <code class=\"docutils literal\"><span class=\"pre\">1h</span></code>. The last selection box chooses a \"fill policy\" for the downsampled values when aggregated with other series. For graphing in the GUI, only the \"zero\" value makes a difference as it will substitute a zero for missing series. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details.</p> <div class=\"figure\" id=\"id1\"> <img alt=\"../../_images/gui_downsampling_off.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_downsampling_off.png\"> <p class=\"caption\"><span class=\"caption-text\">Downsampling Disabled</span></p> </div> <div class=\"figure\" id=\"id2\"> <img alt=\"../../_images/gui_downsampling_on.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_downsampling_on.png\"> <p class=\"caption\"><span class=\"caption-text\">Downsampling Enabled</span></p> </div> </div> <div class=\"section\" id=\"time-section\"> <h3>Time Section</h3> <img alt=\"../../_images/gui_time.jpg\" src=\"http://opentsdb.net/docs/build/html/_images/gui_time.jpg\"> <p>The time secion determines the timespan for all metrics and time series in your graph. The <strong>Frome</strong> time determines when your graph will start and the <strong>End</strong> time determines when it will stop. Both fields must be filled out for a query to execute. Times may be in human readable, absolute format or a relative format. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details.</p> <p>Clicking a time box will pop-up a utility to help you choose a time. Use the arrows at the top left of the box to navigate through the months, then click on a date. The relative links in the upper right are helpers to jump forward or backward 1 minute, 10 minutes, 1 hour, 1 day, 1 week or 30 days. The <em>now</em> link will update the time to the current time on your local system. The <strong>HH</strong> buttons let you choose an hour along with <em>AM</em> or <em>PM</em>. The MM buttons let you choose a normalized minute. You can also cut and paste a time into the any of the boxes or edit the times directly.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Unix timestamps are not supported directly in the boxes. You can click in a box to display the calendar, then paste a Unix timestamp (in seconds) in the <em>UNIX Timestamp</em> box, then press the <em>TAB</em> key to convert to a human readable time stamp.</p> </div> <p>If the time stamp in a time box is invalid, the background will turn red. This may happen if your start time is greater than or equal to your end time.</p> <p>The <strong>To (now)</strong> link will update the <strong>End</strong> box to the current time on your system.</p> <p>Click the <strong>Autoreload</strong> check box to automatically refresh your graph periodically. This can be very useful for monitoring displays where you want to have the graph displayed for a number of people. When checked, the <strong>End</strong> box will disappear and be replaced by an <strong>Every:</strong> box that lets you choose the refresh rate in seconds. The default is to refresh every 15 seconds.</p> </div>   <h2>Graphing</h2> <p>We'll make a quick detour here to talk about the actual graph section. Below the query building area is a spot where details about query results are displayed as well as the actual graph.</p> <img alt=\"../../_images/gui_cached.jpg\" src=\"http://opentsdb.net/docs/build/html/_images/gui_cached.jpg\"> <p>A status line prints information about the results of a query including whether or not the results were cached in the TSD, how many raw data points were analyzed, how many data points were actually plotted (as per the results of aggregations and down sampling) and how long the query took to execute. When the browser is waiting for the results of a query, this message will show <code class=\"docutils literal\"><span class=\"pre\">Loading</span> <span class=\"pre\">Graph...</span></code>.</p> <p>Below the status line will be the actual graph. The graph is simply a PNG image generated by GnuPlot so you can copy the image and save it to your local machine or send it in an email.</p> <p>You can also zoom in on a time range by clicking and dragging a red box across a section of the graph. Release and the query will be updated with the new time span. Note that the browser cursor doesn't change when you're over the graph, it will still remain the default arrow your browser or OS provides.</p> <img alt=\"../../_images/gui_zoom.jpg\" src=\"http://opentsdb.net/docs/build/html/_images/gui_zoom.jpg\"> <div class=\"section\" id=\"graph-style\"> <h3>Graph Style</h3> <p>Back in the query builder section you have the graphing style box to the right.</p> <img alt=\"user_guide/guis/../../images/gui_graphing_style.jpg\" src=\"http://opentsdb.net/docs/build/html/user_guide/guis/images/gui_graphing_style.jpg\"> <p>The <strong>WxH</strong> box alters the dimensions of the graph. Simply enter the <code class=\"docutils literal\"><span class=\"pre\">&lt;width&gt;x&lt;height&gt;</span></code> in pixels such as <code class=\"docutils literal\"><span class=\"pre\">1024x768</span></code> then tab or click in another box to update the graph.</p> <p>Below that are a few tabs for altering different parts of the graph.</p> </div> <div class=\"section\" id=\"axes-tab\"> <h3>Axes Tab</h3> <p>This area deals with altering the Y axes of the graph. <strong>Y</strong> settings affect the axis on the left and <strong>Y2</strong> settings affect the axis on the right. Y2 settings are only enabled if at least one of the metrics has had the <strong>Right Axis</strong> check box checked.</p> <p>The <strong>Label</strong> box will add the specified text to the graph alon the left or right Y axis. By default, no label is provided since OpenTSDB doesn't know what you're graphing.</p> <p>The <strong>Format</strong> box can alter the numbers on the Y axis according to a custom algorithm or formatting. This can be useful to convert numbers to or from scientific notation and adjusting the scale for gigabytes if the data comes in as bytes. For example, you can supply a value of <code class=\"docutils literal\"><span class=\"pre\">%0.0f</span> <span class=\"pre\">Reqs</span></code> and it will change the axis to show an integer value at each step with the string <em>Reqs</em> after it as in the following example.</p> <img alt=\"../../_images/gui_format.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_format.png\"> <p>Read the <a class=\"reference external\" href=\"http://www.gnuplot.info/\">GnuPlot Manual</a> for <em>Format Specifiers</em> to find out what is permissible.</p> <p>The <strong>Range</strong> box allows you to effectively zoom horizontally, showing only the data points between a range of Y axis values. The format for this box is <code class=\"docutils literal\"><span class=\"pre\">[&lt;starting</span> <span class=\"pre\">value&gt;:&lt;optional</span> <span class=\"pre\">end</span> <span class=\"pre\">value&gt;]</span></code>. For example, if I want to show only the data points with values between 700 and 800 I can enter <code class=\"docutils literal\"><span class=\"pre\">[700:800]</span></code>. This will produce a graph as below:</p> <img alt=\"../../_images/gui_range.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_range.png\"> <p>The <strong>Log Scale</strong> check box will set a base ten log scale on the Y axis. An example appears below.</p> <img alt=\"../../_images/gui_log.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_log.png\"> </div> <div class=\"section\" id=\"key-tab\"> <h3>Key Tab</h3> <p>The top half of the key tab's section deals with the location of the graph key. This is a series of buttons layed out to show you where the key will appear. A box surrounds some of the buttons indicating that the key will appear inside of the graph's box, overlaying the data. The default location is the top right inside of the graph box. Simply select a button to move the key box.</p> <img alt=\"../../_images/gui_key_above.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_key_above.png\"> <p>By default, the key lists all of the different labels vertically. The <strong>Horizontal Layout</strong> check box will lay out the key horizontally first, then vertically if the dimensions of the graph wouldn't support it.</p> <p>The <strong>Box</strong> check box will toggle a box outline around the key. This is on by default.</p> <p>The <strong>No Key</strong> check box will hide the key altogether.</p> </div> <div class=\"section\" id=\"style-tab\"> <h3>Style Tab</h3> <p>The style tab currently has a single box, the <strong>Smooth</strong> check box. With this checked, the data point characters will be removed from the graph (showing the lines only) and the data will be smoothed with splines (at least three points need to be plotted). Some users prefer this over the default.</p> <img alt=\"../../_images/gui_smooth.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_smooth.png\"> </div>   <h2>Saving Your Work</h2> <p>As you make changes via the GUI you'll see that the URL reflects your edits. You can copy the URL, save it or email it around and pull it back up to pick up where you were. Unfortunately OpenTSDB doesn't include a built in dashboard so you'll have to save the URL somewhere manually.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/guis/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/guis/index.html</a>\n  </p>\n</div>\n","user_guide/plugins":"<h1>Plugins</h1> <p>OpenTSDB 2.0 introduced a plugin framework, allowing varous contributors to quickly and easily customize their TSDs. This document gives you an overview of the plugin system and will link to some available implementations.</p>  <h2>General</h2> <p>Plugins are loaded at run time by a TSD or command line utility. Once the program or daemon is running, plugin configurations cannot be changed. You must restart the program for changes to take effect.</p> <p>Plugins are JAR files that must be downloaded to a directory accessible by OpenTSDB. Once a directory is created, it must be specified in the <code class=\"docutils literal\"><span class=\"pre\">opentsdb.conf</span></code> config file via the <code class=\"docutils literal\"><span class=\"pre\">tsd.core.plugin_path</span></code> property. If the plugin has dependency JARs that were not compiled into the plugin and are not located in the standard class path, they must be copied to this plugin directory as well.</p> <p>Once the JARs are in place, they must be selected in the configuration file for the type of plugin specified. Usually this will be the fully qualified Java class name such as \"net.opentsdb.search.ElasticSearch\". Each plugin should have an \"enabled\" property as well that must be set to <code class=\"docutils literal\"><span class=\"pre\">true</span></code> for the plugin to be loaded. Plugins may also have configuration settings that must be added to the <code class=\"docutils literal\"><span class=\"pre\">opentsdb.conf</span></code> file before they can operate properly. See your plugin's documentation. See <a class=\"reference internal\" href=\"configuration\"><em>Configuration</em></a> for details.</p> <p>When starting a TSD or CLI tool, a number of errors may prevent a successful launch due to plugin issues. If something happens you should see an exception in the logs related to a plugin. Some things to troubleshoot include:</p> <ul class=\"simple\"> <li>Make sure the <code class=\"docutils literal\"><span class=\"pre\">tsd.core.plugin_path</span></code> is configured</li> <li>Check that the path is readable for the user OpenTSDB is running under, i.e. check permissions</li> <li>Check for typos in the config file. Case matters for plugin names.</li> <li>The plugin may not have access to the dependencies it needs. If it has dependencies that are not included with OpenTSDB or packaged into it's own JAR you need to drop the dependencies in the plugin path.</li> <li>The plugin may be missing configuration settings required for it to be initialized. Read the docs and see if anything is missing.</li> </ul> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">You should always test a new plugin in a development or QA environment before enabling them in production. Plugins may adversely affect write or read performance so be sure to do some load testing to avoid taking down your TSDs and losing data.</p> </div> <div class=\"section\" id=\"logging\"> <h3>Logging</h3> <p>Plugins and their dependencies can be pretty chatty so you may want to tweak your Logback settings to reduce the number of messages.</p> </div>   <h2>Serializers</h2> <p>The HTTP API provides a plugin interface for serializing and deserializing data in formats other than the default JSON formats. These plugins do not require a plugin name or enable flag in the configuration file. Instead simply drop the plugin in the plugin directory and it will be loaded when the TSD is launched. More than one serializer plugin can be loaded on startup. Serializer plugins may require configuration properties, so check the documentation before using them.</p> <div class=\"section\" id=\"id1\"> <h3>Plugins</h3> <p>No implementations, aside from the default, at this time.</p> </div>   <h2>Startup and Service Discovery</h2> <p>OpenTSDB is sometimes used within environments where additional initialization or registration is desired beyond what OpenTSDB typically can do out of the box. Startup plugins can be enabled which will be called when OpenTSDB is initializing, when it is ready to serve traffic, and when it is being shutdown. The <code class=\"docutils literal\"><span class=\"pre\">tsd.startup.plugin</span></code> property can be used to specify the plugin class and <code class=\"docutils literal\"><span class=\"pre\">tsd.startup.enable</span></code> will instruct OpenTSDB to attempt to load the startup plugin.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Added in 2.3.0</p> </div> <div class=\"section\" id=\"id2\"> <h3>Plugins</h3> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://github.com/inst-tech/opentsdb-discoveryplugins/blob/master/src/main/java/io/tsdb/opentsdb/discoveryplugins/IdentityPlugin.java\">Identity Plugin</a> - An example plugin which does nothing but can be used as a starting point for future Startup Plugins and can be used to test the registration mechanism.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/inst-tech/opentsdb-discoveryplugins/blob/master/src/main/java/io/tsdb/opentsdb/discoveryplugins/CuratorPlugin.java\">Apache Curator</a> - A beta plugin which can be used to register OpenTSDB in Zookeeper using Apache Curator's Service Discovery mechanism</li> </ul> </div>   <h2>Search</h2> <p>OpenTSDB can emit meta data and annotations to a search engine for complex querying. A single search plugin can be enabled for a TSD to push data or execute queries. The <code class=\"docutils literal\"><span class=\"pre\">tsd.search.plugin</span></code> property lets you select a search plugin and <code class=\"docutils literal\"><span class=\"pre\">tsd.search.enable</span></code> will start sending data and queries. Search plugins will be loaded by TSDs and select command line tools such as the UID Manager tool.</p> <div class=\"section\" id=\"id3\"> <h3>Plugins</h3> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://github.com/manolama/opentsdb-elasticsearch\">Elastic Search</a> - A beta plugin that connects to an Elastic Search cluster</li> </ul> </div>   <h2>Real Time Publishing</h2> <p>Every data point received by a TSD can be sent to another destination for real time processing. One plugin for this type may be enabled at a time. The <code class=\"docutils literal\"><span class=\"pre\">tsd.rtpublisher.plugin</span></code> property lets you select a plugin and <code class=\"docutils literal\"><span class=\"pre\">tsd.rtpublisher.enable</span></code> will start sending data.</p> <div class=\"section\" id=\"id4\"> <h3>Plugins</h3> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://github.com/manolama/opentsdb-rtpub-rabbitmq\">RabbitMQ</a> - A proof-of-concept plugin to publish to a RabbitMQ cluster by metric name</li> <li>\n<a class=\"reference external\" href=\"https://github.com/gutefrage/OpenTsdbSkylinePublisher\">Skyline</a> - A proof-of-concept plugin to publish to an Etsy Skyline processor</li> </ul> </div>   <h2>RPC</h2> <p>Natively, OpenTSDB supports ingesting data points via Telnet or HTTP. The RPC plugin interface allows users to implement and choose alternative protocols such as Protobufs, Thrift, Memcache or any other means of storing information. More than one plugin can be loaded at a time via the <code class=\"docutils literal\"><span class=\"pre\">tsd.rpc.plugins</span></code> or <cite>tsd.http.rpc.plugins`</cite> configuration property. Simply list the class name of any RPC plugins you wish to load, separated by a comma if you have more than one. RPC plugins are only initialized when running a TSD.</p> <div class=\"section\" id=\"id5\"> <h3>Plugins</h3> <p>No implementations at this time.</p> </div>   <h2>Storage Exception Handler</h2> <p>If a write to the underlying storage layer fails for any reason, an exception is raised. When this happens, if a a storage exception handler plugin is enabled, the data points that couldn't be written can be retried at a later date by spooling to disk or passing to a messaging system. (v2.2)</p> <div class=\"section\" id=\"id6\"> <h3>Plugins</h3> <p>No implementations at this time.</p> </div>   <h2>HTTP RPC Plugin</h2> <p>This is an interface used to implement additional HTTP API endpoints for OpenTSDB. (v2.2)</p> <div class=\"section\" id=\"id7\"> <h3>Plugins</h3> <p>No implementations at this time.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/plugins.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/plugins.html</a>\n  </p>\n</div>\n","user_guide/stats":"<h1>Stats</h1> <p>OpenTSDB offers a number of metrics about its performance, accessible via various API endpoints. The main stats are accessible from the GUI via the \"Stats\" tab, from the Http API at <code class=\"docutils literal\"><span class=\"pre\">/api/stats</span></code> or the legacy API at <code class=\"docutils literal\"><span class=\"pre\">/stats</span></code>. The Telnet style API also supports the \"stats\" command for fetching over CLI. These can easily be published right back into OpenTSDB at any interval you like.</p> <p>Additional stats available include JVM information, storage details (e.g. per-region-client HBase stats) and executed query details. See <a class=\"reference internal\" href=\"../api_http/stats/index\"><em>/api/stats</em></a> for more details about the other endpoints.</p> <p>All metrics from the main stats endpoint include a <code class=\"docutils literal\"><span class=\"pre\">host</span></code> tag that includes the name of the host where the TSD is running. If the <code class=\"docutils literal\"><span class=\"pre\">tsd.stats.canonical</span></code> configuration flag is set, this will change to <code class=\"docutils literal\"><span class=\"pre\">fqdn</span></code> and the TSD will try to resolve its host name to return the fully qualified domain name. Currently all stats are integer values. Each request for stats will fetch statistics in real time so the timestamp will reflect the current time on the TSD host.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The <code class=\"docutils literal\"><span class=\"pre\">/api/stats</span></code> endpoint is a good place to execute a health check for your TSD as it will execute a query to storage for fetching UID stats. If the TSD is unable to reach the backing store, the API will return an exception.</p> </div> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"20%\"> <col width=\"10%\"> <col width=\"50%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Metric</th> <th class=\"head\">Tags</th> <th class=\"head\">Type</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>tsd.connectionmgr.connections</td> <td>type=open</td> <td>Gauge</td> <td>The number of currently open Telnet and HTTP connections.</td> </tr> <tr class=\"row-odd\">\n<td>tsd.connectionmgr.connections</td> <td>type=total</td> <td>Counter</td> <td>The total number of connections made to OpenTSDB. This includes all Telnet and HTTP connections.</td> </tr> <tr class=\"row-even\">\n<td>tsd.connectionmgr.exceptions</td> <td>type=closed</td> <td>Counter</td> <td>The total number of exceptions caused by writes to a channel that was already closed. This can occur if a query takes too long, the client closes their connection gracefully, and the TSD attempts to write to the socket. This includes all Telnet and HTTP connections.</td> </tr> <tr class=\"row-odd\">\n<td>tsd.connectionmgr.exceptions</td> <td>type=reset</td> <td>Counter</td> <td>The total number of exceptions caused by a client disconnecting without closing the socket. This includes all Telnet and HTTP connections.</td> </tr> <tr class=\"row-even\">\n<td>tsd.connectionmgr.exceptions</td> <td>type=timeout</td> <td>Counter</td> <td>The total exceptions caused by a socket inactivity timeout, i.e. the TSD neither wrote nor received data from a socket within the timeout period. This includes all Telnet and HTTP connections.</td> </tr> <tr class=\"row-odd\">\n<td>tsd.connectionmgr.exceptions</td> <td>type=unknown</td> <td>Counter</td> <td>The total exceptions with an unknown cause. Check the logs for details. This includes all Telnet and HTTP connections.</td> </tr> <tr class=\"row-even\">\n<td>tsd.rpc.received</td> <td>type=telnet</td> <td>Counter</td> <td>The total number of telnet RPC requests received</td> </tr> <tr class=\"row-odd\">\n<td>tsd.rpc.received</td> <td>type=http</td> <td>Counter</td> <td>The total number of Http RPC requests received</td> </tr> <tr class=\"row-even\">\n<td>tsd.rpc.received</td> <td>type=http_plugin</td> <td>Counter</td> <td>The total number of Http RPC requests received and handled by a plugin instead of the built-in APIs. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.rpc.exceptions</td> <td> </td> <td>Counter</td> <td>The total number exceptions caught during RPC calls. These may be user error or bugs.</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.latency_50pct</td> <td>type=all</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer HTTP requests for the 50th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.latency_75pct</td> <td>type=all</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer HTTP requests for the 75th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.latency_90pct</td> <td>type=all</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer HTTP requests for the 90th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.latency_95pct</td> <td>type=all</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer HTTP requests for the 95th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.latency_50pct</td> <td>type=graph</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer graphing requests for the 50th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.latency_75pct</td> <td>type=graph</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer graphing requests for the 75th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.latency_90pct</td> <td>type=graph</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer graphing requests for the 90th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.latency_95pct</td> <td>type=graph</td> <td>Gauge</td> <td>The time it took, in milliseconds, to answer graphing requests for the 95th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.latency_50pct</td> <td>type=gnuplot</td> <td>Gauge</td> <td>The time it took, in milliseconds, to generate the GnuPlot graphs for the 50th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.latency_75pct</td> <td>type=gnuplot</td> <td>Gauge</td> <td>The time it took, in milliseconds, to generate the GnuPlot graphs for the 75th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.latency_90pct</td> <td>type=gnuplot</td> <td>Gauge</td> <td>The time it took, in milliseconds, to generate the GnuPlot graphs for the 90th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.latency_95pct</td> <td>type=gnuplot</td> <td>Gauge</td> <td>The time it took, in milliseconds, to generate the GnuPlot graphs for the 95th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.graph.requests</td> <td>cache=disk</td> <td>Counter</td> <td>The total number of graph requests satisfied from the disk cache</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.graph.requests</td> <td>cache=miss</td> <td>Counter</td> <td>The total number of graph requests that were not cached and required a fetch from storage</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.query.invalid_requests</td> <td> </td> <td>Counter</td> <td>The total number data queries sent to the /api/query endpoint that were invalid due to user errors such as using the wrong HTTP method, missing parameters or using metrics and tags without UIDs. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.http.query.exceptions</td> <td> </td> <td>Counter</td> <td>The total number data queries sent to the /api/query endpoint that threw an exception due to bad user input or an underlying error. See logs for details. (v2.2)</td> </tr> <tr class=\"row-even\">\n<td>tsd.http.query.success</td> <td> </td> <td>Counter</td> <td>The total number data queries sent to the /api/query endpoint that completed successfully. Note that these may have returned an empty result. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.rpc.received</td> <td>type=put</td> <td>Counter</td> <td>The total number of <code class=\"docutils literal\"><span class=\"pre\">put</span></code> requests for writing data points</td> </tr> <tr class=\"row-even\">\n<td>tsd.rpc.errors</td> <td>type=hbase_errors</td> <td>Counter</td> <td>The total number of RPC errors caused by HBase exceptions</td> </tr> <tr class=\"row-odd\">\n<td>tsd.rpc.errors</td> <td>type=invalid_values</td> <td>Counter</td> <td>The total number of RPC errors caused invalid <code class=\"docutils literal\"><span class=\"pre\">put</span></code> values from user requests, such as a string instead of a number</td> </tr> <tr class=\"row-even\">\n<td>tsd.rpc.errors</td> <td>type=illegal_arguments</td> <td>Counter</td> <td>The total number of RPC errors caused by bad data from the user</td> </tr> <tr class=\"row-odd\">\n<td>tsd.rpc.errors</td> <td>type=socket_writes_blocked</td> <td>Counter</td> <td>The total number of times the TSD was unable to write back to the telnet socket due to a full buffer. If this happens it likely means a number of exceptions were happening. (v2.2)</td> </tr> <tr class=\"row-even\">\n<td>tsd.rpc.errors</td> <td>type=unknown_metrics</td> <td>Counter</td> <td>The total number of RPC errors caused by attempts to <code class=\"docutils literal\"><span class=\"pre\">put</span></code> a metric without an assigned UID. This only increments if <em>auto metrics</em> is disabled.</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.cache-hit</td> <td>kind=metrics</td> <td>Counter</td> <td>The total number of successful cache lookups for metric UIDs</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.cache-miss</td> <td>kind=metrics</td> <td>Counter</td> <td>The total number of failed cache lookups for metric UIDs that required a call to storage</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.cache-size</td> <td>kind=metrics</td> <td>Gauge</td> <td>The current number of cached metric UIDs</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.ids-used</td> <td>kind=metrics</td> <td>Counter</td> <td>The current number of assigned metric UIDs. (NOTE: if random metric UID generation is enabled ids-used will always be 0)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.ids-available</td> <td>kind=metrics</td> <td>Counter</td> <td>The current number of available metric UIDs, decrements as UIDs are assigned. (NOTE: if random metric UID generation is enabled ids-used will always be 0)</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.random-collisions</td> <td>kind=metrics</td> <td>Counter</td> <td>How many times metric UIDs attempted a reassignment due to a collision with an existing UID. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.cache-hit</td> <td>kind=tagk</td> <td>Counter</td> <td>The total number of successful cache lookups for tagk UIDs</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.cache-miss</td> <td>kind=tagk</td> <td>Counter</td> <td>The total number of failed cache lookups for tagk UIDs that required a call to storage</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.cache-size</td> <td>kind=tagk</td> <td>Gauge</td> <td>The current number of cached tagk UIDs</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.ids-used</td> <td>kind=tagk</td> <td>Counter</td> <td>The current number of assigned tagk UIDs</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.ids-available</td> <td>kind=tagk</td> <td>Counter</td> <td>The current number of available tagk UIDs, decrements as UIDs are assigned.</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.cache-hit</td> <td>kind=tagv</td> <td>Counter</td> <td>The total number of successful cache lookups for tagv UIDs</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.cache-miss</td> <td>kind=tagv</td> <td>Counter</td> <td>The total number of failed cache lookups for tagv UIDs that required a call to storage</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.cache-size</td> <td>kind=tagv</td> <td>Gauge</td> <td>The current number of cached tagv UIDs</td> </tr> <tr class=\"row-odd\">\n<td>tsd.uid.ids-used</td> <td>kind=tagv</td> <td>Counter</td> <td>The current number of assigned tagv UIDs</td> </tr> <tr class=\"row-even\">\n<td>tsd.uid.ids-available</td> <td>kind=tagv</td> <td>Counter</td> <td>The current number of available tagv UIDs, decrements as UIDs are assigned.</td> </tr> <tr class=\"row-odd\">\n<td>tsd.jvm.ramfree</td> <td> </td> <td>Gauge</td> <td>The number of bytes reported as free by the JVM's Runtime.freeMemory()</td> </tr> <tr class=\"row-even\">\n<td>tsd.jvm.ramused</td> <td> </td> <td>Gauge</td> <td>The number of bytes reported as used by the JVM's Runtime.totalMemory()</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.latency_50pct</td> <td>method=put</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Put call for the 50th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.latency_75pct</td> <td>method=put</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Put call for the 75th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.latency_90pct</td> <td>method=put</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Put call for the 90th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.latency_95pct</td> <td>method=put</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Put call for the 95th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.latency_50pct</td> <td>method=scan</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Scan call for the 50th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.latency_75pct</td> <td>method=scan</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Scan call for the 75th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.latency_90pct</td> <td>method=scan</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Scan call for the 90th percentile cases</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.latency_95pct</td> <td>method=scan</td> <td>Gauge</td> <td>The time it took, in milliseconds, to execute a Scan call for the 95th percentile cases</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.root_lookups</td> <td> </td> <td>Counter</td> <td>The total number of root lookups performed by the client</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.meta_lookups</td> <td>type=uncontended</td> <td>Counter</td> <td>The total number of uncontended meta table lookups performed by the client</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.meta_lookups</td> <td>type=contended</td> <td>Counter</td> <td>The total number of contended meta table lookups performed by the client</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.rpcs</td> <td>type=increment</td> <td>Counter</td> <td>The total number of Increment requests performed by the client</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.rpcs</td> <td>type=delete</td> <td>Counter</td> <td>The total number of Delete requests performed by the client</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.rpcs</td> <td>type=get</td> <td>Counter</td> <td>The total number of Get requests performed by the client</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.rpcs</td> <td>type=put</td> <td>Counter</td> <td>The total number of Put requests performed by the client</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.rpcs</td> <td>type=rowLock</td> <td>Counter</td> <td>The total number of Row Lock requests performed by the client</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.rpcs</td> <td>type=openScanner</td> <td>Counter</td> <td>\n<dl class=\"first last docutils\"> <dt>The total number of Open Scanner requests performed by the</dt> <dd>client</dd> </dl> </td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.rpcs</td> <td>type=scan</td> <td>Counter</td> <td>The total number of Scan requests performed by the client. These indicate a scan-&gt;next() call.</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.rpcs.batched</td> <td> </td> <td>Counter</td> <td>The total number of batched requests sent by the client</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.flushes</td> <td> </td> <td>Counter</td> <td>The total number of flushes performed by the client</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.connections.created</td> <td> </td> <td>Counter</td> <td>The total number of connections made by the client to region servers</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.nsre</td> <td> </td> <td>Counter</td> <td>The total number of No Such Region Exceptions caught. These can happen when a region server crashes, is taken offline or when a region splits (?)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.rpcs.rpcs_delayed</td> <td> </td> <td>Counter</td> <td>The total number of calls delayed due to an NSRE that were later successfully executed</td> </tr> <tr class=\"row-even\">\n<td>tsd.hbase.rpcs.region_clients.open</td> <td> </td> <td>Counter</td> <td>The total number of connections opened to region servers since the TSD started. If this number is climbing the region servers may be crashing and restarting. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.hbase.rpcs.region_clients.idle_closed</td> <td> </td> <td>Counter</td> <td>The total number of connections to region servers that were closed due to idle connections. This indicates nothing was read from or written to a server in some time and the TSD will reconnect when it needs to. (v2.2)</td> </tr> <tr class=\"row-even\">\n<td>tsd.compaction.count</td> <td>type=trivial</td> <td>Counter</td> <td>The total number of trivial compactions performed by the TSD</td> </tr> <tr class=\"row-odd\">\n<td>tsd.compaction.count</td> <td>type=complex</td> <td>Counter</td> <td>The total number of complex compactions performed by the TSD</td> </tr> <tr class=\"row-even\">\n<td>tsd.compaction.duplicates</td> <td>type=identical</td> <td>Counter</td> <td>The total number of data points found during compaction that were duplicates at the same time and with the same value. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.compaction.duplicates</td> <td>type=variant</td> <td>Counter</td> <td>The total number of data points found during compaction that were duplicates at the same time but with a different value. (v2.2)</td> </tr> <tr class=\"row-even\">\n<td>tsd.compaction.queue.size</td> <td> </td> <td>Gauge</td> <td>How many rows of data are currently in the queue to be compacted. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.compaction.errors</td> <td>type=read</td> <td>Counter</td> <td>The total number of rows that couldn't be read from storage due to an error of some sort. (v2.2)</td> </tr> <tr class=\"row-even\">\n<td>tsd.compaction.errors</td> <td>type=put</td> <td>Counter</td> <td>The total number of rows that couldn't be re-written to storage due to an error of some sort. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.compaction.errors</td> <td>type=delete</td> <td>Counter</td> <td>The total number of rows that couldn't have the old non-compacted data deleted from storage due to an error of some sort. (v2.2)</td> </tr> <tr class=\"row-even\">\n<td>tsd.compaction.writes</td> <td>type=read</td> <td>Counter</td> <td>The total number of writes back to storage of compacted values. (v2.2)</td> </tr> <tr class=\"row-odd\">\n<td>tsd.compaction.deletes</td> <td>type=read</td> <td>Counter</td> <td>The total number of delete calls made to storage to remove old data that has been compacted. (v2.2)</td> </tr> </tbody> </table><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/stats.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/stats.html</a>\n  </p>\n</div>\n","resources":"<h1>Additional Resources</h1> <p>These are just some of the awesome front-ends, utilities, libraries and resources created by the OpenTSDB community. Please let us know if you have a project you'd like to see listed and if you don't see something you need, search for it on Github (new projects are popping up all the time) or your favorite search engine.</p>  <h2>Monitoring</h2> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://bosun.org/\">Bosun</a> - A monitoring and alerting system built on OpenTSDB from the folks at <a class=\"reference external\" href=\"http://stackexchange.com/\">Stack Exchange</a>.</li> </ul>   <h2>Docker Images</h2> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://registry.hub.docker.com/u/petergrace/opentsdb-docker/\">petergrace/opentsdb-docker</a> - A prebuilt Docker image with HBase and OpenTSDB already configured and ready to run! If you have Docker installed, execute <code class=\"docutils literal\"><span class=\"pre\">docker</span> <span class=\"pre\">run</span> <span class=\"pre\">-d</span> <span class=\"pre\">-p</span> <span class=\"pre\">4242:4242</span> <span class=\"pre\">petergrace/opentsdb-docker</span></code> to create an opentsdb instance running on port 4242.</li> <li>\n<a class=\"reference external\" href=\"https://registry.hub.docker.com/u/opower/opentsdb/\">opower/opentsdb</a> - A Docker image containing OpenTSDB, HBase, and tcollector. Comes in both 2.0.1 and 2.1 versions (latest defaults to 2.1). Execute <code class=\"docutils literal\"><span class=\"pre\">docker</span> <span class=\"pre\">run</span> <span class=\"pre\">-d</span> <span class=\"pre\">-p</span> <span class=\"pre\">4242:4242</span> <span class=\"pre\">opower/opentsdb</span></code> to create an OpenTSDB instance running on port 4242.</li> </ul>   <h2>Front Ends</h2> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://github.com/box/StatusWolf\">Status Wolf</a> - A PHP and MySQL based dashboard for creating and storing dynamic custom graphs with OpenTSDB data including anonmaly detection.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/Ticketmaster/metrilyx-2.0\">Metrilyx</a> - A Python and Django based dashboard system with dynamic graphs from Ticketmaster.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/clover/opentsdb-dashboard\">Opentsdb-Dashboard</a> - An HBase based dashboard system for OpenTSDB 1.x from Clover.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/facebook/tsdash\">TSDash</a> - A Java based UI and dashboard from Facebook.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/turn/opentsdb-dashboard\">OpenTSDB Dashboard</a> - A JQuery based dashboard from Turn.</li> <li>\n<a class=\"reference external\" href=\"http://grafana.org\">Grafana</a> - A dashboard and graph editor with OpenTSDB support.</li> </ul>   <h2>Utilities</h2> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://github.com/noca/opentsdbjsonproxy\">opentsdbjsonproxy</a> - An HTTP proxy to convert 1.x ASCII output from the <code class=\"docutils literal\"><span class=\"pre\">/q</span></code> endpoint to JSON for use with High Charts or other libraries.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/auxesis/collectd-opentsdb\">Collectd-opentsdb</a> - A Collectd plugin to emmit stats to a TSD.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/dotcloud/collectd-opentsdb\">Collectd-opentsdb Java</a> - A Collectd plugin to that uses the OpenTSDB Java API to push data to a TSD.</li> <li>\n<cite>TSD_proxy</cite> &lt;<a class=\"reference external\" href=\"https://github.com/aravind/tsd_proxy\">https://github.com/aravind/tsd_proxy</a>&gt;`_ - A buffering write proxy for OpenTSDB and alternate DBs.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/99designs/vacuumetrix\">Vacuumetrix</a> - Utility to pull data from various cloud services or APIs and store the results in backends such as Graphite, Ganglia and OpenTSDB.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/charms/opentsdb\">JuJu Deployment Charm</a> - Utility to compile OpenTSDB from GIT and deploy on a cluster.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/danslimmon/statsd-opentsdb-backend\">Statsd Publisher</a> - A statsd backend to publish data to a TSD.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/nimbusproject/opentsdbproxy\">OpenTSDB Proxy</a> - A Django based proxy with authentication and SSL support to run in front of the TSDs.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/mburger/puppet-opentsdb\">Puppet Module</a> - A puppet deployment module.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/yandex/opentsdb-flume\">Flume Module</a> - Write data from Flume to a TSD.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/looztra/opentsdb-cookbook\">Chef Cookbook</a> - Deploy from source via Chef.</li> <li>\n<ul class=\"first\"> <li>\n<a class=\"reference external\" href=\"https://github.com/acaiafa/opentsdb-cookbook\">OpenTSDB Cookbook</a> - A Chef cookbook for CentOS or Ubuntu.</li> </ul> </li> <li>\n<a class=\"reference external\" href=\"https://github.com/sps/metrics-opentsdb\">Coda Hale Metrics Reporter</a> - Writes data to OpenTSDB from the Java Metrics library.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/stuart-warren/metrics-opentsdb\">Alternative Coda Hale Metrics Reporter</a> - Writes data to OpenTSDB from the Java Metrics library.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/frogmaster/opentsdb-snmp\">opentsdb-snmp</a> - Fetches data from SNMP enabled devices and writes to OpenTSDB.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/worldline/proxyTSDB\">proxTSDB</a> - A metric data gateway capable of buffering data to RAM or disk if the TSD is down.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/santosh-d3vpl3x/opentsdb-udfs\">OpenTSDB Pig UDFs</a> - Integrate OpenTSDB with Apache Pig for large data set processing.</li> </ul>   <h2>Clients</h2> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"https://github.com/holstius/opentsdbr\">R Client</a> - A client to pull data from OpenTSDB into R.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/bradfordw/gen_opentsdb\">Erlang Client</a> - A simple client to publish data to a TSD from Erlang.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/opower/time-series\">time-series</a> - A Ruby client that supports both reading and writing to OpenTSDB 2.x - contains support for synthetic time series calculations.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/j05h/continuum\">Ruby</a> - A read-only client for querying data from the 1.x API.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/johnewart/ruby-opentsdb\">Ruby</a> A write-only client for pushing data to a TSD.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/bzub/go-opentsdb\">Go</a> - Work with OpenTSDB data in Go.</li> <li>\n<a class=\"reference external\" href=\"https://pypi.python.org/pypi/potsdb\">Potsdb</a> - A Python client for writing data.</li> <li>\n<a class=\"reference external\" href=\"https://github.com/cyngn/vertx-opentsdb\">vert.x OpenTsDb</a> - A library to write data to OpenTSDB from Vert.x.</li> </ul>   <h2>References to OpenTSDB</h2> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"http://www.manning.com/dimidukkhurana/\">HBase in Action</a> (Manning Publications) - Chapter 7: HBase by Example: OpenTSDB</li> <li>\n<a class=\"reference external\" href=\"http://www.wrox.com/WileyCDA/WroxTitle/Professional-NoSQL.productCd-047094224X.html\">Professional NoSQL</a> (Wrox Publishing) - Mentioned in Chapter 17: Tools and Utilities</li> <li>\n<a class=\"reference external\" href=\"http://www.youtube.com/watch?v=WlsyqhrhRZA\">OSCon Data 2011</a> - Presentation from Benoit Sigoure</li> <li>\n<a class=\"reference external\" href=\"http://www.slideshare.net/geoffanderson/monitoring-mysql-with-opentsdb-19982758\">Percona Live 2013</a> Presentation from Geoffrey Anderson</li> <li>\n<a class=\"reference external\" href=\"http://www.hbasecon.com/sessions/opentsdb-at-scale/\">HBaseCon 2013</a> - Presentation from Jonathan Creasy and Geoffrey Anderson</li> <li>\n<a class=\"reference external\" href=\"http://strataconf.com/strata2011/public/schedule/detail/16996\">Strata 2011</a> - Presentation by Benoit Sigoure</li> </ul>   <h2>Statistical Analysis Tools</h2> <ul class=\"simple\"> <li>\n<a class=\"reference external\" href=\"http://www.gnuplot.info/\">GnuPlot</a> - Graphing library used by OpenTSDB</li> <li>\n<a class=\"reference external\" href=\"http://www.r-project.org/\">R</a> - Statistical computing framework</li> <li>\n<a class=\"reference external\" href=\"http://www.scipy.org/\">SciPy</a> - Python libraries for dealing with numbers (Pandas library has time series support)</li> </ul><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/resources.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/resources.html</a>\n  </p>\n</div>\n","api_http/index":"<h1>HTTP API</h1> <p>OpenTSDB provides an HTTP based application programming interface to enable integration with external systems. Almost all OpenTSDB features are accessiable via the API such as querying timeseries data, managing metadata and storing data points. Please read this entire page for important information about standard API behavior before investigating individual endpoints.</p>  <h2>Overview</h2> <p>The HTTP API is RESTful in nature but provides alternative access through various overrides since not all clients can adhere to a strict REST protocol. The default data exchange is via JSON though pluggable <code class=\"docutils literal\"><span class=\"pre\">formatters</span></code> may be accessed, via the request, to send or receive data in different formats. Standard HTTP response codes are used for all returned results and errors will be returned as content using the proper format.</p>   <h2>Version 1.X to 2.x</h2> <p>OpenTSDB 1.x had a simple HTTP API that provided access to common behaviors such as querying for data, auto-complete queries and static file requests. OpenTSDB 2.0 introduces a new, formalized API as documented here. The 1.0 API is still accessible though most calls are deprecated and may be removed in version 3. All 2.0 API calls start with <code class=\"docutils literal\"><span class=\"pre\">/api/</span></code>.</p>   <h2>Serializers</h2> <p>2.0 introduces pluggable serializers that allow for parsing user input and returning results in different formats such as XML or JSON. Serializers only apply to the 2.0 API calls, all 1.0 behave as before. For details on Serializers and options supported, please read <a class=\"reference internal\" href=\"serializers/index\"><em>HTTP Serializers</em></a></p> <p>All API calls use the default JSON serializer unless overridden by query string or <code class=\"docutils literal\"><span class=\"pre\">Content-Type</span></code> header. To override:</p> <ul> <li>\n<p class=\"first\"><strong>Query String</strong> - Supply a parameter such as <code class=\"docutils literal\"><span class=\"pre\">serializer=&lt;serializer_name&gt;</span></code> where <code class=\"docutils literal\"><span class=\"pre\">&lt;serializer_name&gt;</span></code> is the hard-coded name of the serializer as shown in the <code class=\"docutils literal\"><span class=\"pre\">/api/serializers</span></code> <code class=\"docutils literal\"><span class=\"pre\">serializer</span></code> output field.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">If a serializer isn't found that matches the <code class=\"docutils literal\"><span class=\"pre\">&lt;serializer_name&gt;</span></code> value, the query will return an error instead of processing further.</p> </div> </li> <li>\n<p class=\"first\"><strong>Content-Type</strong> - If a query string is not given, the TSD will parse the <code class=\"docutils literal\"><span class=\"pre\">Content-Type</span></code> header from the HTTP request. Each serializer may supply a content type and if matched to the incoming request, the proper serializer will be used. If a serializer isn't located that maps to the content type, the default serializer will be used.</p> </li> <li>\n<p class=\"first\"><strong>Default</strong> - If no query string parameter is given or the content-type is missing or not matched, the default JSON serializer will be used.</p> </li> </ul> <p>The API documentation will display requests and responses using the JSON serializer. See plugin documentation for the ways in which serializers alter behavior.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The JSON specification states that fields can appear in any order, so do not assume the ordering in given examples will be preserved. Arrays may be sorted and if so, this will be documented.</p> </div>   <h2>Authentication/Permissions</h2> <p>As of yet, OpenTSDB lacks an authentication and access control system. Therefore no authentication is required when accessing the API. If you wish to limit access to OpenTSDB, use network ACLs or firewalls to block access. We do not recommend running OpenTSDB on a machine with a public IP Address.</p>   <h2>Response Codes</h2> <p>Every request will be returned with a standard HTTP response code. Most responses will include content, particularly error codes that will include details in the body about what went wrong. Successful codes returned from the API include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"90%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Code</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>200</td> <td>The request completed successfully</td> </tr> <tr class=\"row-odd\">\n<td>204</td> <td>The server has completed the request successfully but is not returning content in the body. This is primarily used for storing data points as it is not necessary to return data to caller</td> </tr> <tr class=\"row-even\">\n<td>301</td> <td>This may be used in the event that an API call has migrated or should be forwarded to another server</td> </tr> </tbody> </table> <p>Common error response codes include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"90%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Code</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>400</td> <td>Information provided by the API user, via a query string or content data, was in error or missing. This will usually include information in the error body about what parameter caused the issue. Correct the data and try again.</td> </tr> <tr class=\"row-odd\">\n<td>404</td> <td>The requested endpoint or file was not found. This is usually related to the static file endpoint.</td> </tr> <tr class=\"row-even\">\n<td>405</td> <td>The requested verb or method was not allowed. Please see the documentation for the endpoint you are attempting to access</td> </tr> <tr class=\"row-odd\">\n<td>406</td> <td>The request could not generate a response in the format specified. For example, if you ask for a PNG file of the <code class=\"docutils literal\"><span class=\"pre\">logs</span></code> endpoing, you will get a 406 response since log entries cannot be converted to a PNG image (easily)</td> </tr> <tr class=\"row-even\">\n<td>408</td> <td>The request has timed out. This may be due to a timeout fetching data from the underlying storage system or other issues</td> </tr> <tr class=\"row-odd\">\n<td>413</td> <td>The results returned from a query may be too large for the server's buffers to handle. This can happen if you request a lot of raw data from OpenTSDB. In such cases break your query up into smaller queries and run each individually</td> </tr> <tr class=\"row-even\">\n<td>500</td> <td>An internal error occured within OpenTSDB. Make sure all of the systems OpenTSDB depends on are accessible and check the bug list for issues</td> </tr> <tr class=\"row-odd\">\n<td>501</td> <td>The requested feature has not been implemented yet. This may appear with formatters or when calling methods that depend on plugins</td> </tr> <tr class=\"row-even\">\n<td>503</td> <td>A temporary overload has occurred. Check with other users/applications that are interacting with OpenTSDB and determine if you need to reduce requests or scale your system.</td> </tr> </tbody> </table>   <h2>Errors</h2> <p>If an error occurs, the API will return a response with an error object formatted per the requested response type. Error object fields include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"50%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Field Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Always Present</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>code</td> <td>Integer</td> <td>Yes</td> <td>The HTTP status code</td> <td>400</td> </tr> <tr class=\"row-odd\">\n<td>message</td> <td>String</td> <td>Yes</td> <td>A descriptive error message about what went wrong</td> <td>Missing required parameter</td> </tr> <tr class=\"row-even\">\n<td>details</td> <td>String</td> <td>Optional</td> <td>Details about the error, often a stack trace</td> <td>Missing value: type</td> </tr> <tr class=\"row-odd\">\n<td>trace</td> <td>String</td> <td>Optional</td> <td>A JAVA stack trace describing the location where the error was generated. This can be disabled via the <code class=\"docutils literal\"><span class=\"pre\">tsd.http.show_stack_trace</span></code> configuration option. The default for TSD is to show the stack trace.</td> <td><cite>See below</cite></td> </tr> </tbody> </table> <p>All errors will return with a valid HTTP status error code and a content body with error details. The default formatter returns error messages as JSON with the <code class=\"docutils literal\"><span class=\"pre\">application/json</span></code> content-type. If a different formatter was requested, the output may be different. See the formatter documentation for details.</p> <div class=\"section\" id=\"example-error-result\"> <h3>Example Error Result</h3> <pre data-language=\"javascript\">{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Missing parameter &lt;code&gt;type&lt;/code&gt;\",\n    \"trace\": \"net.opentsdb.tsd.BadRequestException: Missing parameter &lt;code&gt;type&lt;/code&gt;\\r\\n\\tat net.opentsdb.tsd.BadRequestException.missingParameter(BadRequestException.java:78) ~[bin/:na]\\r\\n\\tat net.opentsdb.tsd.HttpQuery.getRequiredQueryStringParam(HttpQuery.java:250) ~[bin/:na]\\r\\n\\tat net.opentsdb.tsd.SuggestRpc.execute(SuggestRpc.java:63) ~[bin/:na]\\r\\n\\tat net.opentsdb.tsd.RpcHandler.handleHttpQuery(RpcHandler.java:172) [bin/:na]\\r\\n\\tat net.opentsdb.tsd.RpcHandler.messageReceived(RpcHandler.java:120) [bin/:na]\\r\\n\\tat org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:75) [netty-3.5.9.Final.jar:na]\\r\\n\\tat org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:565) [netty-3.5.9.Final.jar:na]\n    ....\\r\\n\\tat java.lang.Thread.run(Unknown Source) [na:1.6.0_26]\\r\\n\"\n  }\n}\n</pre>\n <p>Note that the stack trace is truncated. Also, the trace will include system specific line endings (in this case <code class=\"docutils literal\"><span class=\"pre\">\\r\\n</span></code> for Windows). If displaying for a user or writing to a log, be sure to replace the <code class=\"docutils literal\"><span class=\"pre\">\\n</span></code> or <code class=\"docutils literal\"><span class=\"pre\">\\r\\n</span></code> and <code class=\"docutils literal\"><span class=\"pre\">\\r</span></code> characters with new lines and tabs.</p> </div>   <h2>Verbs</h2> <p>The HTTP API is RESTful in nature, meaning it does it's best to adhere to the REST protocol by using HTTP verbs to determine a course of action. For example, a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> request should only return data, a <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> or <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> should modify data and <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> should remove it. Documentation will reflect what verbs can be used on an endpoint and what they do.</p> <p>However in some situations, verbs such as <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> and <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> are blocked by firewalls, proxies or not implemented in clients. Furthermore, most developers are used to using <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> and <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> exclusively. Therefore, while the OpenTSDB API supports extended verbs, most requests can be performed with just <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> by adding the query string parameter <code class=\"docutils literal\"><span class=\"pre\">method_override</span></code>. This parameter allows clients to pass data for most API calls as query string values instead of body content. For example, you can delete an annotation by issuing a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> with a query string <code class=\"docutils literal\"><span class=\"pre\">/api/annotation?start_time=1369141261&amp;tsuid=010101&amp;method_override=delete</span></code>. The following table describes verb behavior and overrides.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"70%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Verb</th> <th class=\"head\">Description</th> <th class=\"head\">Override</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>GET</td> <td>Used to retrieve data from OpenTSDB. Overrides can be provided to modify content. <strong>Note</strong>: Requests via GET can only use query string parameters; see the note below.</td> <td>N/A</td> </tr> <tr class=\"row-odd\">\n<td>POST</td> <td>Used to update or create an object in OpenTSDB using the content body from the request. Will use a formatter to parse the content body</td> <td>method_override=post</td> </tr> <tr class=\"row-even\">\n<td>PUT</td> <td>Replace an entire object in the system with the provided content</td> <td>method_override=put</td> </tr> <tr class=\"row-odd\">\n<td>DELETE</td> <td>Used to delete data from the system</td> <td>method_override=delete</td> </tr> </tbody> </table> <p>If a method is not supported for a given API call, the TSD will return a 405 error.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The HTTP specification states that there shouldn't be an association between data passed in a request body and the URI in a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> request. Thus OpenTSDB's API does not parse body content in <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> requests. You can, however, provide a query string with data and an override for updating data in certain endpoints. But we recommend that you use <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> for anything that writes data.</p> </div>   <h2>API Versioning</h2> <p>OpenTSDB 2.0's API call calls are versioned so that users can upgrade with gauranteed backwards compatability. To access a specific API version, you craft a URL such as <code class=\"docutils literal\"><span class=\"pre\">/api/v&lt;version&gt;/&lt;endpoint&gt;</span></code> such as <code class=\"docutils literal\"><span class=\"pre\">/api/v2/suggest</span></code>. This will access version 2 of the <code class=\"docutils literal\"><span class=\"pre\">suggest</span></code> endpoint. Versioning starts at 1 for OpenTSDB 2.0.0. Requests for a version that does not exist will result in calls to the latest version. Also, if you do not supply an explicit version, such as <code class=\"docutils literal\"><span class=\"pre\">/api/suggest</span></code>, the latest version will be used.</p>   <h2>Query String Vs. Body Content</h2> <p>Most of the API endpoints support query string parameters, particularly those that fetch data from the system. However due to the complexities of encoding some characters, and particularly Unicode, all endpoints also support access via POST content using formatters. The default format is JSON so clients can use their favorite means of generating a JSON object and send it to the OpenTSDB API via a <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> request. <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> requests will generally provided greater flexibility in the fields offered and fully Unicode support than query strings.</p>   <h2>Compressed Requests</h2> <p>The API can accept body content that has been compressed. Make sure to set the <code class=\"docutils literal\"><span class=\"pre\">Content-Encoding</span></code> header to <code class=\"docutils literal\"><span class=\"pre\">gzip</span></code> and pass the binary encoded data over the wire. This is particularly useful for posting data points to the <code class=\"docutils literal\"><span class=\"pre\">/api/put</span></code> endpoint. An example using curl:</p> <pre data-language=\"javascript\">$ gzip -9c clear-32k.json &gt; gzip-32k.json\n\n$ file gzip-32k.json\ngzip-32k.json: gzip compressed data, was \"clear-32k.json\", from Unix, last modified: Thu Jan 16 15:31:55 2014\n\n$ ls -l gzip-32k.json\n-rw-r--r-- 1 root root 1666 févr.  4 09:57 gzip-32k.json\n\n$ curl -X POST --data-binary \"@gzip-32k.json\" --header \"Content-Type: application/json\" --header \"Content-Encoding: gzip\" http://mytsdb1:4242/api/put?details\n{\"errors\":[],\"failed\":0,\"success\":280}\n</pre>\n   <h2>CORS</h2> <p>OpenTSDB provides simple and preflight support for Cross-Origin Resource Sharing (CORS) requests. To enable CORS, you must supply either a wild card <code class=\"docutils literal\"><span class=\"pre\">*</span></code> or a comma separated list of specific domains in the <code class=\"docutils literal\"><span class=\"pre\">tsd.http.request.cors_domains</span></code> configuration setting and restart OpenTSDB. For example, you can supply a value of <code class=\"docutils literal\"><span class=\"pre\">*</span></code> or you could provide a list of domains such as <code class=\"docutils literal\"><span class=\"pre\">beeblebrox.com,www.beeblebrox.com,aurtherdent.com</span></code>. The domain list is case insensitive but must fully match any value sent by clients.</p> <p>When a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code>, <code class=\"docutils literal\"><span class=\"pre\">POST</span></code>, <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> or <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> request arrives with the <code class=\"docutils literal\"><span class=\"pre\">Origin</span></code> header set to a valid domain name, the server will compare the domain against the configured list. If the domain appears in the list or the wild card was set, the server will add the <code class=\"docutils literal\"><span class=\"pre\">Access-Control-Allow-Origin</span></code> and <code class=\"docutils literal\"><span class=\"pre\">Access-Control-Allow-Methods</span></code> headers to the response after processing is complete. The allowed methods will always be <code class=\"docutils literal\"><span class=\"pre\">GET,</span> <span class=\"pre\">POST,</span> <span class=\"pre\">PUT,</span> <span class=\"pre\">DELETE</span></code>. It does not change per end point. If the request is a CORS preflight, i.e. the <code class=\"docutils literal\"><span class=\"pre\">OPTION</span></code> method is used, the response will be the same but with an empty content body and a 200 status code.</p> <p>If the <code class=\"docutils literal\"><span class=\"pre\">Origin</span></code> domain did not match a domain in the configured list, the response will be a 200 status code and an Error (see above) for the content body stating that access was denied, regardless of whether the request was a preflight or a regular request. The request will not be processed any further.</p> <p>By default, the <code class=\"docutils literal\"><span class=\"pre\">tsd.http.request.cors_domains</span></code> list is empty and CORS is diabled. Requests are passed through without appending CORS specific headers. If an <code class=\"docutils literal\"><span class=\"pre\">Options</span></code> request arrives, it will receive a 405 error message.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Do not rely on CORS for security. It is exceedingly easy to spoof a domain in an HTTP request and OpenTSDB does not perform reverse lookups or domain validation. CORS is only implemented as a means to make it easier JavaScript developers to work with the API.</p> </div>   <h2>Documentation</h2> <p>The documentation for each endpoint listed below will contain details about how to use that endpoint. Eahc page will contain a description of the endpoint, what verbs are supported, the fields in a request, fields in a respone and examples.</p> <p>Request Parameters are a list of field names that you can pass in with your request. Each table has the following information:</p> <ul class=\"simple\"> <li>Name - The name of the field</li> <li>Data Type - The type of data you need to supply. E.g. <code class=\"docutils literal\"><span class=\"pre\">String</span></code> should be text, <code class=\"docutils literal\"><span class=\"pre\">Integer</span></code> must be a whole number (positive or negative), <code class=\"docutils literal\"><span class=\"pre\">Float</span></code> should be a decimal number. The data type may also be a complex object such as an array or map of values or objects. If you see <code class=\"docutils literal\"><span class=\"pre\">Present</span></code> in this column then simply adding the parameter to the query string sets the value to <code class=\"docutils literal\"><span class=\"pre\">true</span></code>, the actual value of the parameter is ignored. For example <code class=\"docutils literal\"><span class=\"pre\">/api/put?summary</span></code> will effectively set <code class=\"docutils literal\"><span class=\"pre\">summary=true</span></code>. If you request <code class=\"docutils literal\"><span class=\"pre\">/api/put?summary=false</span></code>, the API will still consider the request as <code class=\"docutils literal\"><span class=\"pre\">summary=true</span></code>.</li> <li>Required - Whether or not the parameter is required for a successful query. If the parameter is required, you'll see <code class=\"docutils literal\"><span class=\"pre\">Required</span></code> otherwise it will be <code class=\"docutils literal\"><span class=\"pre\">Optional</span></code>.</li> <li>Description - A detailed description of the parameter including what values are allowed if applicable.</li> <li>Default - The default value of the <code class=\"docutils literal\"><span class=\"pre\">Optional</span></code> parameter. If the data is required, this field will be blank.</li> <li>QS - If the parameter can be supplied via query string, this field will have a <code class=\"docutils literal\"><span class=\"pre\">Yes</span></code> in it, otherwise it will have a <code class=\"docutils literal\"><span class=\"pre\">No</span></code> meaning the parameter can only be supplied as part of the request body content.</li> <li>RW - Describes whether or not this parameter can result in an update to data stored in OpenTSDB. Possible values in this column are:<ul> <li>\n<em>empty</em> - This means that the field is for queries only and does not, necessarily, represent a field in the response.</li> <li>\n<strong>RO</strong> - A field that appears in the response but is read only. The value passed along with a request will not alter the output field.</li> <li>\n<strong>RW</strong> or <strong>W</strong> - A field that <strong>will</strong> result in an update to the data stored in the system</li> </ul> </li> <li>Example - An example of the parameter value</li> </ul>   <h2>Deprecated API</h2> <p>Read <a class=\"reference internal\" href=\"deprecated\"><em>Deprecated HTTP API</em></a></p>   <h2>API Endpoints</h2> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"s\">/s</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"aggregators\">/api/aggregators</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"annotation/index\">/api/annotation</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"config/index\">/api/config</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"dropcaches\">/api/dropcaches</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"put\">/api/put</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"query/index\">/api/query</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"search/index\">/api/search</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"serializers\">/api/serializers</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"stats/index\">/api/stats</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"suggest\">/api/suggest</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tree/index\">/api/tree</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"uid/index\">/api/uid</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"version\">/api/version</a></li> </ul> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/index.html</a>\n  </p>\n</div>\n","user_guide/query/index":"<h1>Querying or Reading Data</h1> <p>OpenTSDB offers a number of means to extract data such as CLI tools, an HTTP API and as a GnuPlot graph. Querying with OpenTSDB's tag based system can be a bit tricky so read through this document and checkout the following pages for deeper information. Example queries on this page follow the HTTP API format.</p> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"dates\">Dates and Times</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"filters\">Filters</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"timeseries\">Understanding Metrics and Time Series</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"aggregators\">Aggregators</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"examples\">Query Examples</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"stats\">Query Details and Stats</a></li> </ul> </div>  <h2>Query Components</h2> <p>OpenTSDB's query language is fairly simple but flexible. Each query has the following components:</p> <table class=\"docutils\"> <colgroup> <col width=\"15%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"50%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Parameter</th> <th class=\"head\">Date Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>Start Time</td> <td>String or Integer</td> <td>Yes</td> <td>Starting time for the query. This may be an absolute or relative time. See <a class=\"reference internal\" href=\"dates\"><em>Dates and Times</em></a> for details</td> <td>24h-ago</td> </tr> <tr class=\"row-odd\">\n<td>End Time</td> <td>String or Integer</td> <td>No</td> <td>An end time for the query. If the end time is not supplied, the current time on the TSD will be used. See <a class=\"reference internal\" href=\"dates\"><em>Dates and Times</em></a> for details.</td> <td>1h-ago</td> </tr> <tr class=\"row-even\">\n<td>Metric</td> <td>String</td> <td>Yes</td> <td>The full name of a metric in the system. Must be the complete name. Case sensitive</td> <td>sys.cpu.user</td> </tr> <tr class=\"row-odd\">\n<td>Aggregation Function</td> <td>String</td> <td>Yes</td> <td>A mathematical function to use in combining multiple time series</td> <td>sum</td> </tr> <tr class=\"row-even\">\n<td>Tags</td> <td>String</td> <td>No</td> <td>An optional set of tags for filtering or grouping</td> <td>host=*,dc=lax</td> </tr> <tr class=\"row-odd\">\n<td>Downsampler</td> <td>String</td> <td>No</td> <td>An optional interval and function to reduce the number of data points returned</td> <td>1h-avg</td> </tr> <tr class=\"row-even\">\n<td>Rate</td> <td>String</td> <td>No</td> <td>An optional flag to calculate the rate of change for the result</td> <td>rate</td> </tr> </tbody> </table>   <h2>Times</h2> <p>Absolute time stamps are supported in human readable format or Unix style integers. Relative times may be used for refreshing dashboards. Currently, all queries are able to cover a single time span. In the future we hope to provide an offset query parameter that would allow for aggregations or graphing of a metric over different time periods, such as comparing last week to 1 year ago. See <a class=\"reference internal\" href=\"dates\"><em>Dates and Times</em></a> for details on what is permissible.</p> <p>While OpenTSDB can store data with millisecond resolution, most queries will return the data with second resolution to provide backwards compatibility for existing tools. Unless a down sampling algorithm has been specified with a query, the data will automatically be down sampled to 1 second using the same aggregation function specified in a query. This way, if multiple data points are stored for a given second, they will be aggregated and returned in a normal query correctly.</p> <p>To extract data with millisecond resolution, use the <code class=\"docutils literal\"><span class=\"pre\">/api/query</span></code> endpoint and specify the <code class=\"docutils literal\"><span class=\"pre\">msResolution</span></code> JSON parameter or <code class=\"docutils literal\"><span class=\"pre\">ms</span></code> query string flag and it will bypass down sampling (unless specified) and return all timestamps in Unix epoch millisecond resolution. Also, the <code class=\"docutils literal\"><span class=\"pre\">scan</span></code> commandline utility will return the timestamp as written in storage.</p>   <h2>Tags</h2> <p>Every time series is comprised of a metric and one or more tag name/value pairs. Since tags are optional in queries, if you request only the metric name, then every metric with any number or value of tags will be returned in the aggregated results. For example, if we have a stored data set:</p> <pre data-language=\"python\">sys.cpu.user host=webserver01,cpu=0  1356998400  1\nsys.cpu.user host=webserver01,cpu=1  1356998400  4\nsys.cpu.user host=webserver02,cpu=0  1356998400  2\nsys.cpu.user host=webserver02,cpu=1  1356998400  1\n</pre>\n <p>and simply craft a query <code class=\"docutils literal\"><span class=\"pre\">start=1356998400&amp;m=sum:sys.cpu.user</span></code>, we will get a value of <code class=\"docutils literal\"><span class=\"pre\">8</span></code> at <code class=\"docutils literal\"><span class=\"pre\">1356998400</span></code> that incorporates all 4 time series.</p> <p>If we want to aggregate the results for a specific group, we can filter on the <code class=\"docutils literal\"><span class=\"pre\">host</span></code> tag. The query <code class=\"docutils literal\"><span class=\"pre\">start=1356998400&amp;m=sum:sys.cpu.user{host=webserver01}</span></code> will return a value of <code class=\"docutils literal\"><span class=\"pre\">5</span></code>, incorporating only the time series where <code class=\"docutils literal\"><span class=\"pre\">host=webserver01</span></code>. To drill down to a specific time series, you must include all of the tags for the series, e.g. <code class=\"docutils literal\"><span class=\"pre\">start=1356998400&amp;m=sum:sys.cpu.user{host=webserver01,cpu=0}</span></code> will return <code class=\"docutils literal\"><span class=\"pre\">1</span></code>.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Inconsistent tags can cause unexpected results when querying. See <a class=\"reference internal\" href=\"../writing\"><em>Writing Data</em></a> for details.</p> </div>   <h2>Grouping</h2> <p>A query can also aggregate time series with multiple tags into groups based on a tag value. Two special characters can be passed to the right of the equals symbol in a query:</p> <ul class=\"simple\"> <li>\n<strong>*</strong> - The asterisk will return a separate result for each unique tag value</li> <li>\n<strong>|</strong> - The pipe will return a separate result <em>only</em> for the exact tag values specified</li> </ul> <p>Let's take the following data set as an example:</p> <pre data-language=\"python\">sys.cpu.user host=webserver01,cpu=0  1356998400  1\nsys.cpu.user host=webserver01,cpu=1  1356998400  4\nsys.cpu.user host=webserver02,cpu=0  1356998400  2\nsys.cpu.user host=webserver02,cpu=1  1356998400  1\nsys.cpu.user host=webserver03,cpu=0  1356998400  5\nsys.cpu.user host=webserver03,cpu=1  1356998400  3\n</pre>\n <p>If we want to query for the average CPU time across each server we can craft a query like <code class=\"docutils literal\"><span class=\"pre\">start=1356998400&amp;m=avg:sys.cpu.user{host=*}</span></code>. This will give us three results:</p> <ol class=\"arabic simple\"> <li>The aggregated average for <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,cpu=0</span></code> and <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,cpu=1</span></code>\n</li> <li>The aggregated average for <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver02,cpu=0</span></code> and <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver02,cpu=1</span></code>\n</li> <li>The aggregated average for <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver03,cpu=0</span></code> and <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver03,cpu=1</span></code>\n</li> </ol> <p>However if we have many web servers in the system, this could create a ton of results. To filter on only the hosts we want you can use the pipe operator to select a subset of time series. For example <code class=\"docutils literal\"><span class=\"pre\">start=1356998400&amp;m=avg:sys.cpu.user{host=webserver01|webserver03}</span></code> will return results only for <code class=\"docutils literal\"><span class=\"pre\">webserver01</span></code> and <code class=\"docutils literal\"><span class=\"pre\">webserver03</span></code>.</p> <p>With version 2.2 you can enable or disable grouping per tag filter. Additional filters are also available including wildcards and regular expressions.</p>   <h2>Explicit Tags</h2> <p>As of 2.3 and later, if you know all of the tag keys for a given metric query latency can be improved greatly by using the <code class=\"docutils literal\"><span class=\"pre\">explicitTags</span></code> feature and making sure <code class=\"docutils literal\"><span class=\"pre\">tsd.query.enable_fuzzy_filter</span></code> is enabled in the config. A special filter is given to HBase that enables skipping ahead to rows that we need for the query instead of iterating over every row key and comparing a regular expression.</p> <p>For example, using the data set above, if we only care about metrics where <code class=\"docutils literal\"><span class=\"pre\">host=webserver02</span></code> and there are hundreds of hosts, you can craft a query such as <code class=\"docutils literal\"><span class=\"pre\">start=1356998400&amp;m=avg:explicit_tags:sys.cpu.user{host=webserver02,cpu=*}</span></code>. Note that you must specify every tag included in the time series for this to work and you can decide whether or not to group by the additional tags.</p>   <h2>Aggregation</h2> <p>A powerful feature of OpenTSDB is the ability to perform on-the-fly aggregations of multiple time series into a single set of data points. The original data is always available in storage but we can quickly extract the data in meaningful ways. Aggregation functions are means of merging two or more data points for a single time stamp into a single value. See <a class=\"reference internal\" href=\"aggregators\"><em>Aggregators</em></a> for details.</p>   <h2>Interpolation</h2> <p>When performing an aggregation, what happens if the time stamps of the data points for each time series fail to line up? Say we record the temperature every 5 minutes in different regions around the world. A sensor in Paris may send a temperature of <code class=\"docutils literal\"><span class=\"pre\">27c</span></code> at <code class=\"docutils literal\"><span class=\"pre\">1356998400</span></code>. Then a sensor in San Francisco may send a value of <code class=\"docutils literal\"><span class=\"pre\">18c</span></code> at <code class=\"docutils literal\"><span class=\"pre\">1356998430</span></code>, 30 seconds later. Antarctica may report <code class=\"docutils literal\"><span class=\"pre\">-29c</span></code> at <code class=\"docutils literal\"><span class=\"pre\">1356998529</span></code>. If we run a query requesting the average temperature, we want all of the data points averaged together into a single point. This is where <strong>interpolation</strong> comes into play. See <a class=\"reference internal\" href=\"aggregators\"><em>Aggregators</em></a> for details.</p>   <h2>Downsampling</h2> <p>OpenTSDB can ingest a large amount of data, even a data point every second for a given time series. Thus queries may return a large number of data points. Accessing the results of a query with a large number of points from the API can eat up bandwidth. High frequencies of data can easily overwhelm Javascript graphing libraries, hence the choice to use GnuPlot. Graphs created by the GUI can be difficult to read, resulting in thick lines such as the graph below:</p> <img alt=\"../../_images/gui_downsampling_off1.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_downsampling_off1.png\"> <p>Down sampling can be used at query time to reduce the number of data points returned so that you can extract better information from a graph or pass less data over a connection. Down sampling requires an <strong>aggregation</strong> function and a <strong>time interval</strong>. The aggregation function is used to compute a new data point across all of the data points in the specified interval with the proper mathematical function. For example, if the aggregation <code class=\"docutils literal\"><span class=\"pre\">sum</span></code> is used, then all of the data points within the interval will be summed together into a single value. If <code class=\"docutils literal\"><span class=\"pre\">avg</span></code> is chosen, then the average of all data points within the interval will be returned.</p> <p>Intervals are specified by a number and a unit of time. For example, <code class=\"docutils literal\"><span class=\"pre\">30m</span></code> will aggregate data points every 30 minutes. <code class=\"docutils literal\"><span class=\"pre\">1h</span></code> will aggregate across an hour. See <a class=\"reference internal\" href=\"dates\"><em>Dates and Times</em></a> for valid relative time units. Do not add the <code class=\"docutils literal\"><span class=\"pre\">-ago</span></code> to a down sampling query.</p> <p>Using down sampling we can cleanup the previous graph to arrive at something much more useful:</p> <img alt=\"../../_images/gui_downsampling_on1.png\" src=\"http://opentsdb.net/docs/build/html/_images/gui_downsampling_on1.png\"> <p>As of 2.1, downsampled timestamps are normalized based on the remainder of the original data point timestamp divided by the downsampling interval in milliseconds, i.e. the modulus. In Java the code is <code class=\"docutils literal\"><span class=\"pre\">timestamp</span> <span class=\"pre\">-</span> <span class=\"pre\">(timestamp</span> <span class=\"pre\">%</span> <span class=\"pre\">interval_ms)</span></code>. For example, given a timestamp of <code class=\"docutils literal\"><span class=\"pre\">1388550980000</span></code>, or <code class=\"docutils literal\"><span class=\"pre\">1/1/2014</span> <span class=\"pre\">04:36:20</span> <span class=\"pre\">UTC</span></code> and an hourly interval that equates to 3600000 milliseconds, the resulting timestamp will be rounded to <code class=\"docutils literal\"><span class=\"pre\">1388548800000</span></code>. All data points between 4 and 5 UTC will wind up in the 4 AM bucket. If you query for a day's worth of data downsampling on 1 hour, you will receive 24 data points (assuming there is data for all 24 hours).</p> <p>Normalization works very well for common queries such as a day's worth of data downsampled to 1 minute or 1 hour. However if you try to downsample on an odd interval, such as 36 minutes, then the timestamps may look a little strange due to the nature of the modulus calculation. Given an interval of 36 minutes and our example above, the interval would be <code class=\"docutils literal\"><span class=\"pre\">2160000</span></code> milliseconds and the resulting timestamp <code class=\"docutils literal\"><span class=\"pre\">1388549520</span></code> or <code class=\"docutils literal\"><span class=\"pre\">04:12:00</span> <span class=\"pre\">UTC</span></code>. All data points between <code class=\"docutils literal\"><span class=\"pre\">04:12</span></code> and <code class=\"docutils literal\"><span class=\"pre\">04:48</span></code> would wind up in a single bucket. Also note that OpenTSDB cannot currently normalize on non-UTC times and it cannot normalize on weekly or monthly boundaries.</p> <p>With version 2.2 a downsampling query can emit a <code class=\"docutils literal\"><span class=\"pre\">NaN</span></code> or <code class=\"docutils literal\"><span class=\"pre\">null</span></code> when a downsample bucket is missing a value for all of the series involved. Because OpenTSDB does not allow for storing literal NaNs at this time, nor does it impose specific intervals on storage, this can be used to mimic systems that do such as RRDs.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Previous to 2.1, timestamps were not normalized. The buckets were calculated based on the starting time of the first data point retreived for each series, then the series went through interpolation. This means a graph may show varying gaps between values and return more values than expected.</p> </div>   <h2>Rate</h2> <p>A number of data sources return values as constantly incrementing counters. One example is a web site hit counter. When you start a web server, it may have a hit counter of 0. After five minutes the value may be 1,024. After another five minutes it may be 2,048. The graph for a counter will be a somewhat straight line angling up to the right and isn't always very useful. OpenTSDB provides the <strong>rate</strong> key word that calculates the rate of change in values over time. This will transform counters into lines with spikes to show you when activity occurred and can be much more useful.</p> <p>The rate is the first derivative of the values. It's defined as (v2 - v1) / (t2 - t1). Therefore you will get the rate of change per second. Currently the rate of change between millisecond values defaults to a per second calculation.</p> <p>OpenTSDB 2.0 provides support for special monotonically increasing counter data handling including the ability to set a \"rollover\" value and suppress anomalous fluctuations. When the <code class=\"docutils literal\"><span class=\"pre\">counterMax</span></code> value is specified in a query, if a data point approaches this value and the point after is less than the previous, the max value will be used to calculate an accurate rate given the two points. For example, if we were recording an integer counter on 2 bytes, the maximum value would be 65,535. If the value at <code class=\"docutils literal\"><span class=\"pre\">t0</span></code> is <code class=\"docutils literal\"><span class=\"pre\">64000</span></code> and the value at <code class=\"docutils literal\"><span class=\"pre\">t1</span></code> is <code class=\"docutils literal\"><span class=\"pre\">1000</span></code>, the resulting rate per second would be calculated as <code class=\"docutils literal\"><span class=\"pre\">-63000</span></code>. However we know that it's likely the counter rolled over so we can set the max to <code class=\"docutils literal\"><span class=\"pre\">65535</span></code> and now the calculation will be <code class=\"docutils literal\"><span class=\"pre\">65535</span> <span class=\"pre\">-</span> <span class=\"pre\">t0</span> <span class=\"pre\">+</span> <span class=\"pre\">t1</span></code> to give us <code class=\"docutils literal\"><span class=\"pre\">2535</span></code>.</p> <p>Systems that track data in counters often revert to 0 when restarted. When that happens and we could get a spurious result when using the max counter feature. For example, if the counter has reached <code class=\"docutils literal\"><span class=\"pre\">2000</span></code> at <code class=\"docutils literal\"><span class=\"pre\">t0</span></code> and someone reboots the server, the next value may be <code class=\"docutils literal\"><span class=\"pre\">500</span></code> at <code class=\"docutils literal\"><span class=\"pre\">t1</span></code>. If we set our max to <code class=\"docutils literal\"><span class=\"pre\">65535</span></code> the result would be <code class=\"docutils literal\"><span class=\"pre\">65535</span> <span class=\"pre\">-</span> <span class=\"pre\">2000</span> <span class=\"pre\">+</span> <span class=\"pre\">500</span></code> to give us <code class=\"docutils literal\"><span class=\"pre\">64035</span></code>. If the normal rate is a few points per second, this particular spike, with <code class=\"docutils literal\"><span class=\"pre\">30s</span></code> between points, would create a rate spike of <code class=\"docutils literal\"><span class=\"pre\">2,134.5</span></code>! To avoid this, we can set the <code class=\"docutils literal\"><span class=\"pre\">resetValue</span></code> which will, when the rate exceeds this value, return a data point of <code class=\"docutils literal\"><span class=\"pre\">0</span></code> so as to avoid spikes in either direction. For the example above, if we know that our rate almost never exceeds 100, we could configure a <code class=\"docutils literal\"><span class=\"pre\">resetValue</span></code> of <code class=\"docutils literal\"><span class=\"pre\">100</span></code> and when the data point above is calculated, it will return <code class=\"docutils literal\"><span class=\"pre\">0</span></code> instead of <code class=\"docutils literal\"><span class=\"pre\">2,134.5</span></code>. The default value of 0 means the reset value will be ignored, no rates will be suppressed.</p>   <h2>Order of operations</h2> <p>Understanding the order of operations is important. When returning query results the following is the order in which processing takes place:</p> <ol class=\"arabic simple\"> <li>Grouping</li> <li>Down Sampling</li> <li>Interpolation</li> <li>Aggregation</li> <li>Rate Calculation</li> </ol><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/query/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/query/index.html</a>\n  </p>\n</div>\n","user_guide/metadata":"<h1>Metadata</h1> <p>The primary purpose of OpenTSDB is to store timeseries data points and allow for various operations on that data. However it helps to know what kind of data is stored and provide some context when working with the information. OpenTSDB's metadata is data about the data points. Much of it is user configurable to provide tie-ins with external tools such as search engines or issue tracking systems. This chapter describes various metadata available and what it's used for.</p>  <h2>UIDMeta</h2> <p>Every data point stored in OpenTSDB has at least three UIDs associated with it. There will always be a <code class=\"docutils literal\"><span class=\"pre\">metric</span></code> and one or more tag pairs consisting of a <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> or tag name, and a <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> or tag value. When a new name for one of these UIDs comes into the system, a Unique ID is assigned so that there is always a UID name and numeric identifier pair.</p> <p>Each UID may also have a metadata entry recorded in the <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table. Data available for each UID includes immutable fields such as the <code class=\"docutils literal\"><span class=\"pre\">uid</span></code>, <code class=\"docutils literal\"><span class=\"pre\">type</span></code>, <code class=\"docutils literal\"><span class=\"pre\">name</span></code> and <code class=\"docutils literal\"><span class=\"pre\">created</span></code> timestamp that reflects the time when the UID was first assigned. Additionally some fields may be edited such as the <code class=\"docutils literal\"><span class=\"pre\">description</span></code>, <code class=\"docutils literal\"><span class=\"pre\">notes</span></code>, <code class=\"docutils literal\"><span class=\"pre\">displayName</span></code> and a set of <code class=\"docutils literal\"><span class=\"pre\">custom</span></code> key/value pairs to record extra information. For details on the fields, see the <a class=\"reference internal\" href=\"../api_http/uid/uidmeta\"><em>/api/uid/uidmeta</em></a> endpoint.</p> <p>Whenever a new UIDMeta object is created or modified, it will be pushed to the Search plugin if a plugin has been configured and loaded. For information about UID values, see <a class=\"reference internal\" href=\"uids\"><em>UIDs and TSUIDs</em></a>.</p>   <h2>TSMeta</h2> <p>Each timeseries in OpenTSDB is uniquely identified by the combination of it's metric UID and tag name/value UIDs, creating a TSUID as per <a class=\"reference internal\" href=\"uids\"><em>UIDs and TSUIDs</em></a>. When a new timeseries is received, a TSMeta object can be recorded in the <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table in a row identified by the TSUID. The meta object includes some immutable fields such as the <code class=\"docutils literal\"><span class=\"pre\">tsuid</span></code>, <code class=\"docutils literal\"><span class=\"pre\">metric</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tags</span></code>, <code class=\"docutils literal\"><span class=\"pre\">lastReceived</span></code> and <code class=\"docutils literal\"><span class=\"pre\">created</span></code> timestamp that reflects the time when the TSMeta was first received. Additionally some fields can be edited such as a <code class=\"docutils literal\"><span class=\"pre\">description</span></code>, <code class=\"docutils literal\"><span class=\"pre\">notes</span></code> and others. See <a class=\"reference internal\" href=\"../api_http/uid/tsmeta\"><em>/api/uid/tsmeta</em></a> for details.</p>   <h2>Enabling Metadata</h2> <p>If you want to use metadata in your OpenTSDB setup, you must explicitly enable real-time metadata tracking and/or use the CLI tools. There are multiple options for meta data generation due to impacts on performance, so before you enable any of these settings, please test the impact on your TSDs before enabling the settings in production.</p> <p>Four options are available, starting with the least impact to the most.</p> <ul class=\"simple\"> <li>\n<code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_realtime_uid</span></code> - When enabled, any time a new metric, tag name or tag value is assigned a UID, a UIDMeta object is generated and optionally sent to the configured search plugin. As UIDs are assigned fairly infrequently, this setting should not impact performance very much.</li> <li>\n<code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_tsuid_tracking</span></code> - When enabled, every time a data point is recorded, a <code class=\"docutils literal\"><span class=\"pre\">1</span></code> is written to the <code class=\"docutils literal\"><span class=\"pre\">tsdb-meta</span></code> table with the timestamp of the given data point. Enabling this setting will generate twice the number of <em>puts</em> to storage and may require a greater amount of memory heap. For example a single TSD should be able to acheive 6,000 data points per second with about 2GB of heap.</li> <li>\n<code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_tsuid_incrementing</span></code> - When this setting is enabled, every data point written will increment a counter in the <code class=\"docutils literal\"><span class=\"pre\">tsdb-meta</span></code> table corresponding to the time series the data point belongs to. As every data points spawns an increment request, this can generate a much larger load in a TSD and chew up heap space pretty quickly so only enable this if you can spread the load across multiple TSDs or your writes are fairly small. Enabling incrementing will override the <code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_tsuid_tracking</span></code> setting. For example a single TSD should be able to acheive 3,000 data points per second with about 6GB of heap.</li> <li>\n<code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_realtime_ts</span></code> - When enabled, any time a new time series arrives, a TSMeta object will be created and optionally sent to a configured search plugin. This option will also enable the <code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_tsuid_incrementing</span></code> setting even if it's explicitly set to <code class=\"docutils literal\"><span class=\"pre\">false</span></code> in the config. If you often push new time series to your TSDs, this option may incur a fair amount of overhead and require some garbage collection tuning. If you do not often push new time series, you should be able to enable this setting without a problem, but watch the memory usage of your TSDs.</li> </ul> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Watch your JVM heap usage when enabling any of the real-time meta data settings.</p> </div> <p>For situations where a TSD crashes before metadata can be written to storage or if you do not enable real-time tracking, you can periodically use the <code class=\"docutils literal\"><span class=\"pre\">uid</span></code> CLI tool and the <code class=\"docutils literal\"><span class=\"pre\">metasync</span></code> sub command to generate missing UIDMeta and TSMeta objects. See <a class=\"reference internal\" href=\"cli/uid\"><em>uid</em></a> for information.</p>   <h2>Annotations</h2> <p>Another form of metadata is the <em>annotation</em>. Annotations are simple objects associated with a timestamp and, optionally, a timeseries. Annotations are meant to be a very basic means of recording an event. They are not intended as an event management or issue tracking system. Rather they can be used to link a timeseries to such an external system.</p> <p>Every annotation is associated with a start timestamp. This determines where the note is stored in the backend and may be the start of an event with a beginning and end, or just used to record a note at a specific point in time. Optionally an end timestamp can be set if the note represents a time span, such as an issue that was resolved some time after the start.</p> <p>Additionally, an annotation is defined by a TSUID. If the TSUID field is set to a valid TSUID, the annotation will be stored, and associated, along with the data points for the timeseries defined by the ID. This means that when creating a query for data points, any annotations stored within the requested timespan will be retrieved and optionally returned to the user. These annotations are considered \"local\".</p> <p>If the TSUID is empty, the annotation is considered a \"global\" notation, something associated with all timeseries in the system. When querying, the user can specify that global annotations be fetched for the timespan of the query. These notes will then be returned along with \"local\" annotations.</p> <p>Annotations should have a very brief <em>description</em>, limited to 25 characters or so since the note may appear on a graph. If the requested timespan has many annotations, the graph can become clogged with notes. User interfaces can then let the user select an annotation to retrieve greater detail. This detail may include lengthy \"notes\" and/or a custom map of key/value pairs.</p> <p>Users can add, edit and delete annotations via the Http API at <code class=\"xref doc docutils literal\"><span class=\"pre\">../api_http/annotation</span></code>.</p> <p>An example GnuPlot graph with annotation markers appears below. Notice how only the <code class=\"docutils literal\"><span class=\"pre\">description</span></code> field appears in a box with a blue line recording the <code class=\"docutils literal\"><span class=\"pre\">start_time</span></code>. Only the <code class=\"docutils literal\"><span class=\"pre\">start_time</span></code> appears on the graph.</p> <img alt=\"../_images/annotation_ex.png\" src=\"http://opentsdb.net/docs/build/html/_images/annotation_ex.png\"><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/metadata.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/metadata.html</a>\n  </p>\n</div>\n","user_guide/trees":"<h1>Trees</h1> <p>Along with metadata, OpenTSDB 2.0 introduces the concept of <strong>trees</strong>, a hierarchical method of organizing timeseries into an easily navigable structure that can be browsed similar to a file system on a computer. Users can define a number of trees with various rule sets that organize TSMeta objects into a tree structure. Then users can browse the resulting tree via an HTTP API endpoint. See <a class=\"reference internal\" href=\"../api_http/tree/index\"><em>/api/tree</em></a> for details.</p>  <h2>Tree Terminology</h2> <ul class=\"simple\"> <li>\n<strong>Branch</strong> - Each branch is one node of a tree. It contains a list of child branches and leaves as well as a list of parent branches.</li> <li>\n<strong>Leaf</strong> - The end of a branch and represents a unique timeseries. The leaf will contain a TSUID value that can be used to generate a TSD query. A branch can, and likely will, have multiple leaves</li> <li>\n<strong>Root</strong> - The root branch is the start of the tree and all branches reach out from this root. It has a depth of 0.</li> <li>\n<strong>Depth</strong> - Each time a branch is added to another branch, the depth increases</li> <li>\n<strong>Strict Matching</strong> - When enabled, a timeseries must match a rule in every level of the rule set. If one or more levels fail to match, the timeseries will not be included in the tree.</li> <li>\n<strong>Path</strong> - The name and level of each branch above the current branch in the hierarchy.</li> </ul>   <h2>Branch</h2> <p>Each node of a tree is recorded as a <em>branch</em> object. Each branch contains information such as:</p> <ul class=\"simple\"> <li>\n<strong>Branch ID</strong> - The ID of the branch. This is a hexadecimal value described below.</li> <li>\n<strong>Display Name</strong> - A name for the branch, parsed from a TSMeta object by the tree rule set.</li> <li>\n<strong>Depth</strong> - How deep within the hierarchy the branch resides.</li> <li>\n<strong>Path</strong> - The depth and name of each parent branch (includes the local branch).</li> <li>\n<strong>Branches</strong> - Child branches one depth level below this branch.</li> <li>\n<strong>Leaves</strong> - Leaves that belong to this branch.</li> </ul> <p>Navigating a tree starts at the <strong>root</strong> branch which always has an ID that matches the ID of the tree the branch belongs to. The root should have one or more child branches that can be used to navigate down one level of the tree. Each child can be used to navigate to their children and so on. The root does not have any parent branches and is always at a depth of 0. If a tree has just been defined or enabled, it may not have a root branch yet, and by extension, there won't be any child branches.</p> <p>Each branch will often have a list of child branches. However if a branch is at the end of a path, it may not have any child branches, but it should have a list of leaves.</p> <div class=\"section\" id=\"branch-ids-and-paths\"> <h3>Branch IDs and Paths</h3> <p>Branch IDs are hexadecimal encoded byte arrays similar to TSUIDs but with a different format. Branch IDs always start with the ID of the tree encoded on 2 bytes. Root branches have a branch ID equal to the tree ID. Thus the root for tree <code class=\"docutils literal\"><span class=\"pre\">1</span></code> would have a branch ID of <code class=\"docutils literal\"><span class=\"pre\">0001</span></code>.</p> <p>Each child branch has a <code class=\"docutils literal\"><span class=\"pre\">DisplayName</span></code> value and the hash of this value is used to generate a 32 bit integer ID for the branch. The hash function used is the Java <code class=\"docutils literal\"><span class=\"pre\">java.lang.String</span></code> hash function. The 4 bytes of the integer value are then encoded to 8 hexadecimal characters. For example, if we have a display name of <code class=\"docutils literal\"><span class=\"pre\">sys</span></code> for a branch, the hash returned will be 102093. The TSD will convert that value to hexadecimal <code class=\"docutils literal\"><span class=\"pre\">0001BECD</span></code>.</p> <p>A branch ID is composed of the tree ID concatenated with the ID of each parent above the current branch, concatenated with the ID of the current branch. Thus, if our child branch <code class=\"docutils literal\"><span class=\"pre\">sys</span></code> is a child of the root, we would have a branch ID of <code class=\"docutils literal\"><span class=\"pre\">00010001BECD</span></code>.</p> <p>Lets say there is a branch with a display name of <code class=\"docutils literal\"><span class=\"pre\">cpu</span></code> off of the <code class=\"docutils literal\"><span class=\"pre\">sys</span></code> child branch. <code class=\"docutils literal\"><span class=\"pre\">cpu</span></code> returns a hash of 98728 which converts to <code class=\"docutils literal\"><span class=\"pre\">000181A8</span></code> in hex. The ID of this child would be <code class=\"docutils literal\"><span class=\"pre\">00010001BECD000181A8</span></code>.</p> <p>IDs are created this way primarily due to the method of branch and leaf storage but also as a way to navigate back up a tree from a branch anywhere in the tree structure. This can be particularly useful if you know the end branch of a path and want to move back up one level or more. Unfortunately a deep tree can create very long branch IDs, but a well designed tree really shouldn't be more than 5 to 10 levels deep. Most URI requests should support branches up to 100 levels deep before the URI character constraints are reached.</p> </div>   <h2>Leaves</h2> <p>A unique timeseries is represented as a <em>leaf</em> on the tree. A leaf can appear on any branch in the structure, including the root. But they will usually appear at the end of a series of branches in a branch that has one or more leaves but no child branches. Each leaf contains the TSUID for the timeseries to be used in a query as well as the metric and tag name/values. It also contains a <em>display name</em> that is parsed from the rule set but may not be identical to any of the metric, tag names or tag values.</p> <p>Ideally a timeseries will only appear once on a tree. But if the TSMeta object for a timeseries, OR the UIDMeta for a metric or tag is modified, it may be processed a second time and a second leaf added. This can happen particularly in situations where a tree has a <em>custom</em> rule on the metric, tag name or tag value where the TSMeta has been processed then a user adds a custom field that matches the rule set. In these situations it is recommended to enable <em>strict matching</em> on the tree so that the timeseries will not show up until the custom data has been added.</p>   <h2>Rules</h2> <p>Each tree is dynamically built from a set of rules defined by the user. A rule set must contain at least one rule and usually will have more than one. Each set has multiple <em>levels</em> that determine the order of rule processing. Rules located at level 0 are processed first, then rules at level 1, and so on until all of the rules have been applied to a given timeseries. Each level in the rule set may have multiple rules to handle situations where metrics and tags may not have been planned out ahead of time or some arbitrary data may have snuck in. If multiple rules are stored in a level, the first one with a successful match will be applied and the others ignored. These rules are also ordered by the <em>order</em> field so that a rule with order 0 is processed first, then a rule with order 1 and so on. In logs and when using the test endpoint, rules are usually given IDs in the format of \"[&lt;treeId&gt;:&lt;level&gt;:&lt;order&gt;:&lt;type&gt;]\" such as \"[1:0:1:0]\" indicates the rule for tree 1, at level 0, order 1 of the type <code class=\"docutils literal\"><span class=\"pre\">METRIC</span></code>.</p> <div class=\"section\" id=\"rule-types\"> <h3>Rule Types</h3> <p>Each rule acts on a single component of the timeseries data. Currently available types include:</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"10%\"> <col width=\"70%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Type</th> <th class=\"head\">ID</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>METRIC</td> <td>0</td> <td>Processes the name of the metric associated with the timeseries</td> </tr> <tr class=\"row-odd\">\n<td>METRIC_CUSTOM</td> <td>1</td> <td>Searches the metric metadata custom tag list for the given secondary name. If matched, the value associated with the tag name will be processed.</td> </tr> <tr class=\"row-even\">\n<td>TAGK</td> <td>2</td> <td>Searches the list of tagks for the given name. If matched, the tagv value associated with the tag name will be processed</td> </tr> <tr class=\"row-odd\">\n<td>TAGK_CUSTOM</td> <td>3</td> <td>Searches the list of tagks for the given name. If matched, the tagk metadata custom tag list is searched for the given secondary name. If that matches, the value associated with the custom name will be processed.</td> </tr> <tr class=\"row-even\">\n<td>TAGV_CUSTOM</td> <td>4</td> <td>Searches the list of tagvs for the given name. If matched, the tagv metadata custom tag list is searched for the given secondary name. If that matches, the value associated with the custom name will be processed.</td> </tr> </tbody> </table> </div> <div class=\"section\" id=\"rule-config\"> <h3>Rule Config</h3> <p>A single rule can either process a regex, a separator, or none. If a regex and a separator are defined for a rule, only the regex will be processed and the separator ignored.</p> <p>All changes to a rule are validated to confirm that proper fields are filled out so that the rule can process data. The following fields must be filled out for each rule type:</p> <table class=\"docutils\"> <colgroup> <col width=\"50%\"> <col width=\"25%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Type</th> <th class=\"head\">field</th> <th class=\"head\">customField</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>Metric</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>Metric_Custom</td> <td>X</td> <td>X</td> </tr> <tr class=\"row-even\">\n<td>TagK</td> <td>X</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>TagK_Custom</td> <td>X</td> <td>X</td> </tr> <tr class=\"row-even\">\n<td>TagV_Custom</td> <td>X</td> <td>X</td> </tr> </tbody> </table> </div> <div class=\"section\" id=\"display-formatter\"> <h3>Display Formatter</h3> <p>Occasionally the data extracted from a tag or metric may not be very descriptive. For example, an application may output a timeseries with a tag pair such as \"port=80\" or \"port=443\". With a standard rule that matched on the tagk value \"port\", we would have two branches with the names \"80\" and \"443\". The uninitiated may not know what these numbers mean. Thus users can define a token based formatter that will alter the output of the branch to display useful information. For example, we could declare a formatter of \"{tag_name}: {value}\" and the branches will now display \"port: 80\" and \"port: 443\".</p> <p>Tokens are case sensitive and must appear only one time per formatter. They must also appear exactly as deliniated in the table below:</p> <table class=\"docutils\"> <colgroup> <col width=\"22%\"> <col width=\"44%\"> <col width=\"33%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Token</th> <th class=\"head\">Description</th> <th class=\"head\">Applicable Rule Type</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>{ovalue}</td> <td>Original value processed by the rule. For example, if the rule uses a regex to extract a portion of the value but you do not want the extracted value, you could use the original here.</td> <td>All</td> </tr> <tr class=\"row-odd\">\n<td>{value}</td> <td>The processed value. If a rule has an extracted regex group or the value was split by a separator, this represents the value after that processing has occured.</td> <td>All</td> </tr> <tr class=\"row-even\">\n<td>{tag_name}</td> <td>The name of the tagk or custom tag associated with the value.</td> <td>METRIC_CUSTOM, TAGK_CUSTOM, TAGV_CUSTOM, TAGK</td> </tr> <tr class=\"row-odd\">\n<td>{tsuid}</td> <td>the TSUID of the timeseries</td> <td>All</td> </tr> </tbody> </table> </div> <div class=\"section\" id=\"regex-rules\"> <h3>Regex Rules</h3> <p>In some situations, you may want to extract only a component of a metric, tag or custom value to use for grouping. For example, if you have computers in mutiple data centers with fully qualified domain names that incorporate the name of the DC, but not all metrics include a DC tag, you could use a regex to extract the DC for grouping.</p> <p>The <code class=\"docutils literal\"><span class=\"pre\">regex</span></code> rule parameter must be set with a valid regular expression that includes one or more extraction operators, i.e. the parentheses. If the regex matches on the value provided, the extracted data will be used to build the branch or leaf. If more than one extractions are provided in the regex, you can use the <code class=\"docutils literal\"><span class=\"pre\">regex_group_index</span></code> parameter to choose which extracted value to use. The index is 0 based and defaults to 0, so if you want to choose the output of the second extraction, you would set this index to 1. If the regex does not match on the value or the extraction fails to return a valid string, the rule will be considered a no match.</p> <p>For example, if we have a host tagk with a tagv of <code class=\"docutils literal\"><span class=\"pre\">web01.nyc.mysite.com</span></code>, we could use a regex similar to <code class=\"docutils literal\"><span class=\"pre\">.*\\.(.*)\\..*\\..*</span></code> to extract the \"nyc\" portion of the FQDN and group all of the servers in the \"nyc\" data center under the \"nyc\" branch.</p> </div> <div class=\"section\" id=\"separator-rules\"> <h3>Separator Rules</h3> <p>The metrics for a number of systems are generally strings with a separator, such as a period, to deliniate components of the metric. For example, \"sys.cpu.0.user\". To build a useful tree, you can use a separator rule that will break apart the string based on a character sequence and create a branch or leaf from each individual value. Setting the separator to \".\" for the previous example would yield three branches \"sys\", \"cpu\", \"0\" and one leaf \"user\".</p> </div> <div class=\"section\" id=\"order-of-precedence\"> <h3>Order of Precedence</h3> <p>Each rule can only process a regex, a separator, or neither. If the rule has both a \"regex\" and \"separator\" value in their respective fields, only the \"regex\" will be executed on the timeseries. The \"separator\" will be ignored. If neither \"regex\" or \"separator\" are defined, then when the rule's \"field\" is matched, the entire value for that field will be processed into a branch or leaf.</p> </div>   <h2>Tree Building</h2> <p>First, you must create the <code class=\"docutils literal\"><span class=\"pre\">tsdb-tree</span></code> table in HBase if you haven't already done so. If you enable tree processing and the table does not exist, the TSDs will not start.</p> <p>A tree can be built in two ways. The <code class=\"docutils literal\"><span class=\"pre\">tsd.core.tree.enable_processing</span></code> configuration setting enables real-time tree creation. Whenever a new TSMeta object is created or edited by a user, the TSMeta will be passed through every configured and enabled tree. The resulting branch will be recorded to storage. If a collision occurs or the TSUID failed to match on any rules, a warning will be logged and if the tree options configured, may be recorded to storage.</p> <p>Alternatively you can periodically synchronize all TSMeta objects via the CLI <code class=\"docutils literal\"><span class=\"pre\">uid</span></code> tool. This will scan through the <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table and pass each discovered TSMeta object through configured and enabled trees. See <a class=\"reference internal\" href=\"cli/uid\"><em>uid</em></a> for details.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">For real-time tree building you need to enable the <code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_tracking</span></code> setting as well so that TSMeta objects are created when a timeseries is received.</p> </div> <p>The general process for creating and building a tree is as follows:</p> <ol class=\"arabic simple\"> <li>Create a new tree via the HTTP API</li> <li>Assign one or more rules to the tree via the HTTP API</li> <li>Test the rules with some TSMeta objects via the HTTP API</li> <li>After veryfing the branches would appear correctly, set the tree's <code class=\"docutils literal\"><span class=\"pre\">enable</span></code> flag to <code class=\"docutils literal\"><span class=\"pre\">true</span></code>\n</li> <li>Run the <code class=\"docutils literal\"><span class=\"pre\">uid</span></code> tool with the <code class=\"docutils literal\"><span class=\"pre\">treesync</span></code> sub command to synchronize existing TSMeta objects in the tree</li> </ol> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">When you create a new tree, it will be disabled by default so TSMeta objects will not be processed through the rule set. This is so you have time to configure the rule set and test it to verify that the tree would be built as you expect it to.</p> </div> <div class=\"section\" id=\"rule-processing-order\"> <h3>Rule Processing Order</h3> <p>A tree will usually have more than one rule in order for the resulting tree to be useful. As noted above, rules are organized into levels and orders. A TSMeta is processed through the rule set starting at level 0 and order 0. Processing proceedes through the rules on a level in increasing order. After the first rule on a level that successfully matches on the TSMeta data, processing skips to the next level. This means that rules on a level are effectively <a href=\"#id1\"><span class=\"problematic\" id=\"id2\">``</span></a>or``ed. If level 0 has rules at order 0, 1, 2 and 3, and the TSMeta matches on the rule with an order of 1, the rules with order 2 and 3 will be skipped.</p> <p>When editing rules, it may happen that some levels or orders are skipped or left empty. In these situations, processing simply skips the empty locations. You should do your best to keep things organized properly but the rule processor is a little forgiving.</p> </div> <div class=\"section\" id=\"strict-matching\"> <h3>Strict Matching</h3> <p>All TSMeta objects are processed through every tree. If you only want a single, monolithic tree to organize all of your OpenTSDB timeseries, this isn't a problem. But if you want to create a number of trees for specific subsets of information, you may want to exclude some timeseries entries from creating leaves. The <code class=\"docutils literal\"><span class=\"pre\">strictMatch</span></code> flag on a tree helps to filter out timeseries that belong on one tree but not another. With strict matching enabled, a timeseries must match a rule on every level (that has one or more rules) in the rule set in order for it to be included in the tree. If the meta fails to match on any of the levels with rules, it will be recorded as a not matched entry and no leaf will be generated.</p> <p>By default strict matching is disabled so that as many timeseries as possible can be captured in a tree. If you change this setting on a tree, you may want to delete the existing branches and run a re-sync.</p> </div>   <h2>Collisions</h2> <p>Due to the flexibility of rule sets and the wide variety of metric, tag name and value naming, it is almost inevitable that two different TSMeta entries would try to create the same leaf on a tree. Each branch can only have one leaf with a given display name. For example, if a branch has a leaf named <code class=\"docutils literal\"><span class=\"pre\">user</span></code> with a tsuid of <code class=\"docutils literal\"><span class=\"pre\">010101</span></code> but the tree tries to add a new leaf named <code class=\"docutils literal\"><span class=\"pre\">user</span></code> with a tsuid of <code class=\"docutils literal\"><span class=\"pre\">020202</span></code>, the new leaf will not be added to the tree. Instead, a <em>collision</em> entry will be recorded for the tree to say that tsuid <code class=\"docutils literal\"><span class=\"pre\">0202020</span></code> collided with an existing leaf for tsuid <code class=\"docutils literal\"><span class=\"pre\">010101</span></code>. The HTTP API can then be used to query the collision list to see if a particular TSUID did not appear in the tree due to a collision.</p>   <h2>Not Matched</h2> <p>When <em>strict matching</em> is enabled for a tree, a TSMeta must match on a rule on every level of the rule set in order to be added to the tree. If one or more levels fail to match, the TSUID will not be added. Similar to <em>collisions</em>, a not matched entry will be recorded for every TSUID that failed to be written to the tree. The entry will contain the TSUID and a brief message about which rule and level failed to match.</p>   <h2>Examples</h2> <p>Assume that our TSD has the following timeseries stored:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"20%\"> <col width=\"40%\"> <col width=\"30%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">TS#</th> <th class=\"head\">Metric</th> <th class=\"head\">Tags</th> <th class=\"head\">TSUID</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>1</td> <td>cpu.system</td> <td>dc=dal, host=web01.dal.mysite.com</td> <td>0102040101</td> </tr> <tr class=\"row-odd\">\n<td>2</td> <td>cpu.system</td> <td>dc=dal, host=web02.dal.mysite.com</td> <td>0102040102</td> </tr> <tr class=\"row-even\">\n<td>3</td> <td>cpu.system</td> <td>dc=dal, host=web03.dal.mysite.com</td> <td>0102040103</td> </tr> <tr class=\"row-odd\">\n<td>4</td> <td>app.connections</td> <td>host=web01.dal.mysite.com</td> <td>010101</td> </tr> <tr class=\"row-even\">\n<td>5</td> <td>app.errors</td> <td>host=web01.dal.mysite.com, owner=doe</td> <td>0101010306</td> </tr> <tr class=\"row-odd\">\n<td>6</td> <td>cpu.system</td> <td>dc=lax, host=web01.lax.mysite.com</td> <td>0102050101</td> </tr> <tr class=\"row-even\">\n<td>7</td> <td>cpu.system</td> <td>dc=lax, host=web02.lax.mysite.com</td> <td>0102050102</td> </tr> <tr class=\"row-odd\">\n<td>8</td> <td>cpu.user</td> <td>dc=dal, host=web01.dal.mysite.com</td> <td>0202040101</td> </tr> <tr class=\"row-even\">\n<td>9</td> <td>cpu.user</td> <td>dc=dal, host=web02.dal.mysite.com</td> <td>0202040102</td> </tr> </tbody> </table> <p>Note that for this example we won't be using any custom value rules so we don't need to show the TSMeta objects, but assume these values populate a TSMeta. Also, the TSUIDs are truncated with 1 byte per UID for illustration purposes.</p> <p>Now let's setup a tree with <code class=\"docutils literal\"><span class=\"pre\">strictMatching</span></code> disabled and the following rules:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"20%\"> <col width=\"20%\"> <col width=\"20%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Level</th> <th class=\"head\">Order</th> <th class=\"head\">Rule Type</th> <th class=\"head\">Field (value)</th> <th class=\"head\">Regex</th> <th class=\"head\">Separator</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>0</td> <td>0</td> <td>TagK</td> <td>dc</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>0</td> <td>1</td> <td>TagK</td> <td>host</td> <td>.*\\.(.*)\\.mysite\\.com</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>1</td> <td>0</td> <td>TagK</td> <td>host</td> <td> </td> <td>\\\\.</td> </tr> <tr class=\"row-odd\">\n<td>2</td> <td>0</td> <td>Metric</td> <td> </td> <td> </td> <td>\\\\.</td> </tr> </tbody> </table> <p>The goal for this set of rules is to order our timeseres by data center, then host, then by metric. Our company may have thousands of servers around the world so it doesn't make sense to display all of them in one branch of the tree, rather we want to group them by data center and let users drill down as needed.</p> <p>In our example data, we had some old timeseries that didn't have a <code class=\"docutils literal\"><span class=\"pre\">dc</span></code> tag name. However the <code class=\"docutils literal\"><span class=\"pre\">host</span></code> tag does have a fully qualified domain name with the data center name embedded. Thus the first level of our rule set has two rules. The first will look for a <code class=\"docutils literal\"><span class=\"pre\">dc</span></code> tag, and if found, it will use that tag's value and the second rule is skipped. If the <code class=\"docutils literal\"><span class=\"pre\">dc</span></code> tag does not exist, then the second rule will scan the <code class=\"docutils literal\"><span class=\"pre\">host</span></code> tag's value and attempt to extract the data center name from the FQDN. The second level has one rule and that is used to group on the value of the <code class=\"docutils literal\"><span class=\"pre\">host</span></code> tag so that all metrics belonging to that host can be displayed in branches beneath it. The final level has the metric rule that includes a separator to further group the timeseries by the data contained. Since we have multiple CPU and application metrics, all deliniated by a period, it makes sense to add a separator at this point.</p> <div class=\"section\" id=\"result\"> <h3>Result</h3> <p>The resulting tree would look like this:</p> <ul class=\"simple\"> <li>dal<ul> <li>web01.dal.mysite.com<ul> <li>app<ul> <li>connections (tsuid=010101)</li> <li>errors (tsuid=0101010306)</li> </ul> </li> <li>cpu<ul> <li>system (tsuid=0102040101)</li> <li>user (tsuid=0202040101)</li> </ul> </li> </ul> </li> <li>web02.dal.mysite.com<ul> <li>cpu<ul> <li>system (tsuid=0102040102)</li> <li>user (tsuid=0202040102)</li> </ul> </li> </ul> </li> <li>web03.dal.mysite.com<ul> <li>cpu<ul> <li>system (tsuid=0102040103)</li> </ul> </li> </ul> </li> </ul> </li> <li>lax<ul> <li>web01.lax.mysite.com<ul> <li>cpu<ul> <li>system (tsuid=0102050101)</li> </ul> </li> </ul> </li> <li>web02.lax.mysite.com<ul> <li>cpu<ul> <li>system (tsuid=0102050102)</li> </ul> </li> </ul> </li> </ul> </li> </ul> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/trees.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/trees.html</a>\n  </p>\n</div>\n","user_guide/quickstart":"<h1>Quick Start</h1> <p>Once you have a TSD up and running (after following the <a class=\"reference internal\" href=\"../installation\"><em>Installation</em></a> guide) you can follow the steps below to get some data into OpenTSDB. After you have some data stored, pull up the GUI and try generating some graphs.</p>  <h2>Create Your First Metrics</h2> <p>Metrics need to be registered before you can start storing data points for them. This helps to avoid ingesting unwanted data and catch typos. You can enable auto-metric creation via configuration. To register one or more metrics, call the <code class=\"docutils literal\"><span class=\"pre\">mkmetric</span></code> CLI:</p> <pre data-language=\"python\">./tsdb mkmetric mysql.bytes_received mysql.bytes_sent\n</pre>\n <p>This will create 2 metrics: <code class=\"docutils literal\"><span class=\"pre\">mysql.bytes_received</span></code> and <code class=\"docutils literal\"><span class=\"pre\">mysql.bytes_sent</span></code></p> <p>New tags, on the other hand, are automatically registered whenever they're used for the first time. Right now OpenTSDB only allows you to have up to 2^24 = 16,777,216 different metrics, 16,777,216 different tag names and 16,777,216 different tag values. This is because each one of those is assigned a UID on 3 bytes. Metric names, tag names and tag values have their own UID spaces, which is why you can have 16,777,216 of each kind. The size of each space is configurable but there is no knob that exposes this configuration parameter right now. So bear in mind that using user ID or event ID as a tag value will not work right now if you have a large site.</p>   <h2>Start Collecting Data</h2> <p>So now that we have our 2 metrics, we can start sending data to the TSD. Let's write a little shell script to collect some data off of MySQL and send it to the TSD:</p> <pre data-language=\"python\">cat &gt;mysql-collector.sh &lt;&lt;\\EOF\n#!/bin/bash\nset -e\nwhile true; do\n  mysql -u USER -pPASS --batch -N --execute \"SHOW STATUS LIKE 'bytes%'\" \\\n  | awk -F\"\\t\" -v now=`date +%s` -v host=`hostname` \\\n  '{ print \"put mysql.\" tolower($1) \" \" now \" \" $2 \" host=\" host }'\n  sleep 15\ndone | nc -w 30 host.name.of.tsd PORT\nEOF\nchmod +x mysql-collector.sh\nnohup ./mysql-collector.sh &amp;\n</pre>\n <p>Every 15 seconds, the script will collect 2 data points from MySQL and send them to the TSD. You can use a smaller sleep interval for greater granularity.</p> <p>What does the script do? If you're not a big fan of shell and awk scripting, it may not be obvious how this works. But it's simple. The <code class=\"docutils literal\"><span class=\"pre\">set</span> <span class=\"pre\">-e</span></code> command simply instructs bash to exit with an error if any of the commands fail. This simplifies error handling. The script then enters an infinite loop. In this loop, we query MySQL to retrieve 2 of its status variables:</p> <pre data-language=\"python\">$ mysql -u USER -pPASS --execute \"SHOW STATUS LIKE 'bytes%'\"\n+----------------+-------+\n| Variable_name  | Value |\n+----------------+-------+\n| Bytes_received | 133   |\n| Bytes_sent   | 190   |\n+----------------+-------+\n</pre>\n <p>The <code class=\"docutils literal\"><span class=\"pre\">--batch</span> <span class=\"pre\">-N</span></code> flags ask the mysql command to remove the human friendly fluff so we don't have to filter it out ourselves. Then the output is piped to awk, which is told to split fields on tabs <code class=\"docutils literal\"><span class=\"pre\">-F\"\\t\"</span></code> because with the <code class=\"docutils literal\"><span class=\"pre\">--batch</span></code> flag that's what mysql will use. We also create a couple of variables, one named <code class=\"docutils literal\"><span class=\"pre\">now`</span> <span class=\"pre\">and</span> <span class=\"pre\">initialize</span> <span class=\"pre\">it</span> <span class=\"pre\">to</span> <span class=\"pre\">the</span> <span class=\"pre\">current</span> <span class=\"pre\">timestamp,</span> <span class=\"pre\">the</span> <span class=\"pre\">other</span> <span class=\"pre\">named</span> <span class=\"pre\">``host`</span> <span class=\"pre\">and</span> <span class=\"pre\">set</span> <span class=\"pre\">to</span> <span class=\"pre\">the</span> <span class=\"pre\">hostname</span> <span class=\"pre\">of</span> <span class=\"pre\">the</span> <span class=\"pre\">local</span> <span class=\"pre\">machine.</span> <span class=\"pre\">Then,</span> <span class=\"pre\">for</span> <span class=\"pre\">every</span> <span class=\"pre\">line,</span> <span class=\"pre\">we</span> <span class=\"pre\">print</span> <span class=\"pre\">put</span> <span class=\"pre\">``mysql.</span></code>, followed by the lower-case form of the first word, then by a space, then by the current timestamp, then by the second word (the value), another space, and finally <code class=\"docutils literal\"><span class=\"pre\">host=</span></code> and the current hostname. Rinse and repeat every 15 seconds. The <code class=\"docutils literal\"><span class=\"pre\">-w</span> <span class=\"pre\">30</span></code> parameter given to <code class=\"docutils literal\"><span class=\"pre\">nc</span></code> simply sets a timeout on the connection to the TSD. Bear in mind, this is just an example, in practice you can use tcollector's MySQL collector.</p> <p>If you don't have a MySQL server to monitor, you can try this instead to collect basic load metrics from your Linux servers:</p> <pre data-language=\"python\">cat &gt;loadavg-collector.sh &lt;&lt;\\EOF\n#!/bin/bash\nset -e\nwhile true; do\n  awk -v now=`date +%s` -v host=`hostname` \\\n  '{ print \"put proc.loadavg.1m \" now \" \" $1 \" host=\" host;\n  print \"put proc.loadavg.5m \" now \" \" $2 \" host=\" host }' /proc/loadavg\n  sleep 15\ndone | nc -w 30 host.name.of.tsd PORT\nEOF\nchmod +x loadavg-collector.sh\nnohup ./loadavg-collector.sh &amp;\n</pre>\n <p>This will store a reading of the 1-minute and 5-minute load average of your server in OpenTSDB by sending simple \"telnet-style commands\" to the TSD:</p> <pre data-language=\"python\">put proc.loadavg.1m 1288946927 0.36 host=foo\nput proc.loadavg.5m 1288946927 0.62 host=foo\nput proc.loadavg.1m 1288946942 0.43 host=foo\nput proc.loadavg.5m 1288946942 0.62 host=foo\n</pre>\n   <h2>Batch Imports</h2> <p>Let's imagine that you have a cron job that crunches gigabytes of application logs every day or every hour to extract profiling data. For instance, you could be logging the time taken to process a request and your cron job would compute an average for every 30 second window. Maybe you're particularly interested in 2 types of requests handled by your application, so you'll compute separate averages for those requests, and an another average for every other request type. So your cron job may produce an output file that looks like this:</p> <pre data-language=\"python\">1288900000 42 foo\n1288900000 51 bar\n1288900000 69 other\n1288900030 40 foo\n1288900030 59 bar\n1288900030 80 other\n</pre>\n <p>The first column is a timestamp, the second is the average latency for that 30 second window, and the third is the type of request we're talking about. If you run your cron job on a day worth of logs, you'll end up with 8640 such lines. In order to import those into OpenTSDB, you need to adjust your cron job slightly to produce its output in the following format:</p> <pre data-language=\"python\">myservice.latency.avg 1288900000 42 reqtype=foo\nmyservice.latency.avg 1288900000 51 reqtype=bar\nmyservice.latency.avg 1288900000 69 reqtype=other\nmyservice.latency.avg 1288900030 40 reqtype=foo\nmyservice.latency.avg 1288900030 59 reqtype=bar\nmyservice.latency.avg 1288900030 80 reqtype=other\n</pre>\n <p>Notice we're simply associating each data point with the name of a metric (myservice.latency.avg) and naming the tag that represents the request type. If each server has its own logs and you process them separately, you may want to add another tag to each line like the <code class=\"docutils literal\"><span class=\"pre\">host=foo</span></code> tag we saw in the previous section. This way you'll be able to plot the latency of each server individually, in addition to your average latency across the board and/or per request type. In order to import a data file in the format above (metric timestamp value tags) simply run the following command:</p> <pre data-language=\"python\">./tsdb import your-file\n</pre>\n <p>If your data file is large, consider gzip'ing it first. This can be as simple as piping the output of your cron job to <code class=\"docutils literal\"><span class=\"pre\">gzip</span> <span class=\"pre\">-9</span> <span class=\"pre\">&gt;output.gz</span></code> instead of writing directly to a file. The import command is able to read gzip'ed files and it greatly helps performance for large batch imports.</p>   <h2>Self Monitoring</h2> <p>Each TSD exports some stats about itself through the simple stats command. You can collect those stats and feed them back to the TSD every few seconds. First, create the necessary metrics:</p> <pre data-language=\"python\">echo stats | nc -w 1 localhost 4242 \\\n| awk '{ print $1 }' | sort -u \\\n| xargs ./tsdb mkmetric\n</pre>\n <p>This requests the stats from the TSD (assuming it's running on the local host and listening to port 4242), extract the names of the metrics from the stats and assigns them UIDs. Then you can use this simple script to collect stats and store them in OpenTSDB:</p> <pre data-language=\"python\">#!/bin/bash\nINTERVAL=15\nwhile :; do\n  echo stats || exit\n  sleep $INTERVAL\ndone | nc -w 30 localhost $1 \\\n  | sed 's/^/put /' \\\n  | nc -w 30 localhost $1\n</pre>\n <p>This way you will collect and store stats from the TSD every 15 seconds.</p>   <h2>Create a Graph</h2> <p>Once you've written some data using any of the methods above, you can now try to create a graph using that data. Pull up the GUI in your favorite browser. If you're running your TSD on the localhost, simply visit <a class=\"reference external\" href=\"http://127.0.0.1:4242\">http://127.0.0.1:4242</a>.</p> <p>First, pick one of the metrics and put that in the <code class=\"docutils literal\"><span class=\"pre\">Metric</span></code> box. For example, <code class=\"docutils literal\"><span class=\"pre\">proc.loadavg.1m</span></code>. As you type, you should see auto-complete lines pop up and you can click on any of them.</p> <p>Then click the <code class=\"docutils literal\"><span class=\"pre\">From</span></code> box at the top and a date-picker pop-up should appear. Select any time from yesterday and click on another box. At this point you should see \"Loading graph..\" very briefly followed by the actual graph. If the graph is empty, it may not have found the most recent data points so click the <code class=\"docutils literal\"><span class=\"pre\">(now)</span></code> link and the page should refresh.</p> <p>This initial graph will aggregate all of the time series for the metric you selected. Try limiting your query to a specific host by adding <code class=\"docutils literal\"><span class=\"pre\">host</span></code> as a value in the left-hand box next to the <code class=\"docutils literal\"><span class=\"pre\">Tags</span></code> label (if it isn't already there) and add the specific host name (e.g. <code class=\"docutils literal\"><span class=\"pre\">foo</span></code>) in the right-hand box. After clicking in another box you should see the graph re-draw with different information.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/quickstart.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/quickstart.html</a>\n  </p>\n</div>\n","user_guide/backends/bigtable":"<h1>Bigtable</h1> <p><a class=\"reference external\" href=\"https://cloud.google.com/\">Google Cloud Platform</a> provides hosting of Google's Bigtable database, the original inspiration of HBase and many NoSQL storage systems. Because HBase is so similar to Bigtable, running OpenTSDB 2.3 and later with Google's backend is simple. Indeed, the schemas (see <a class=\"reference internal\" href=\"hbase\"><em>HBase Schema</em></a>) are exactly the same so all you have to do is create your Bigtable instance, create your TSDB tables using the Bigtable HBase shell, and fire up the TSDs.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The clients for Bigtable are in beta and undergoing a number of changes. Performance should improve as we adjust the code and uncover new tuning parameters. Please help us out on the mailing list or by modifying the code in GitHub.</p> </div>  <h2>Setup</h2> <ol class=\"arabic simple\"> <li>Setup your Google Cloud Platform account.</li> <li>Follow the steps in <a class=\"reference external\" href=\"https://cloud.google.com/bigtable/docs/creating-cluster\">Creating a Cloud Bigtable Cluster</a>.</li> <li>Follow the steps in <a class=\"reference external\" href=\"https://cloud.google.com/bigtable/docs/hbase-shell-quickstart\">HBase Shell Quickstart</a>, paying attention to where you download your JSON key file.</li> <li>Set the <cite>HBASE_HOME</cite> environment variable to your Bigtable shell directory and run the <cite>src/create_table.sh</cite> script. If the script fails to launch the shell, try running the shell manually and execute the <cite>create</cite> statements substituting the proper values.</li> <li>Build TSDB by executing <cite>sh build-bigtable.sh</cite> (or if you prefer Maven, <cite>sh build-bigtable.sh pom.xml</cite>)</li> <li>Prepare the <cite>opentsdb.conf</cite> file with the required and/or optional configuration parameters below.</li> <li>Run the TSD via <cite>build/tsdb tsd --config=&lt;path&gt;/opentsdb.conf</cite>\n</li> </ol>   <h2>Configuration</h2> <p>The following is a table of required and optional parameters to run OpenTSDB with Bigtable. These are in addition to the standard TSD configuration parameters from <a class=\"reference internal\" href=\"../configuration\"><em>Configuration</em></a>.</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"60%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Property</th> <th class=\"head\">Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>google.bigtable.project.id</td> <td>String</td> <td>Required</td> <td>The project ID hosting your Bigtable cluster.</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>google.bigtable.cluster.name</td> <td>String</td> <td>Required</td> <td>The cluster ID you assigned to your Bigtable cluster at creation.</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>google.bigtable.zone.name</td> <td>String</td> <td>Required</td> <td>The zone where your Bigtable cluster is operating; chosen at creation.</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>hbase.client.connection.impl</td> <td>String</td> <td>Required</td> <td>The class that will be used to implement the HBase API AsyncBigtable will use as a shim between the Bigtable client and OpenTSDB. Set this to <cite>com.google.cloud.bigtable.hbase1_0.BigtableConnection</cite>\n</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>google.bigtable.auth.service.account.enable</td> <td>Boolean</td> <td>Required</td> <td>Whether or not to use a Google cloud service account to connect. Set this to <cite>true</cite>\n</td> <td>false</td> </tr> <tr class=\"row-odd\">\n<td>google.bigtable.auth.json.keyfile</td> <td>String</td> <td>Required</td> <td>The full path to the JSON formatted key file associated with the service account you want to use for Bigtable access. Download this from your cloud console.</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>google.bigtable.grpc.channel.count</td> <td>Integer</td> <td>Optional</td> <td>The number of sockets opened to the Bigtable API for handling RPCs. For higher throughput consider increasing the channel count.</td> <td>4</td> </tr> </tbody> </table> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Google's Bigtable client communicates with their servers over HTTP2 with TLS using ALPN. As Java 7 and 8 (dunno about 9) lack native ALPN support, a <a class=\"reference external\" href=\"http://www.eclipse.org/jetty/documentation/current/alpn-chapter.html\">library</a> must be loaded at JVM start to modify the JVM's bytecode. The build script for OpenTSDB will attempt to detect your JDK version and download the proper version of ALPN but if you have a custom JVM or something other than Hotspot or OpenJDK you may run into issues. Try different versions of the <cite>alpn-boot</cite> JAR to see what works for you.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/backends/bigtable.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/backends/bigtable.html</a>\n  </p>\n</div>\n","user_guide/backends/cassandra":"<h1>Cassandra</h1> <p>Cassandra is an eventually consistent key value store similar to HBase and Google`s Bigtable. It implements a distributed hash map with column families originally it supported a Thrift based API very close to HBase`s. Lately Cassandra has moved towards a SQL like query language with much more flexibility around data types, joints and filters. Thankfully the Thrift interface is still there so it`s easy to convert the OpenTSDB HBase schema and calls to Cassandra at a low level through the AsyncHBase <code class=\"docutils literal\"><span class=\"pre\">HBaseClient</span></code> API. <a class=\"reference external\" href=\"https://github.com/OpenTSDB/asynccassandra\">AsyncCassandra</a> is a shim between OpenTSDB and Cassandra for trying out TSDB with an alternate backend.</p>  <h2>Setup</h2> <ol class=\"arabic simple\"> <li>Setup a Cassandra cluster using the <code class=\"docutils literal\"><span class=\"pre\">ByteOrderedPartitioner</span></code>. This is critical as we require the row keys to be sorted. Because this setting affects the entire node, you may need to setup a cluster dedicated to OpenTSDB.</li> <li>Create the proper keyspsaces and column families by using the <cite>cassandra-cli</cite> script:</li> </ol> <pre data-language=\"python\">create keyspace tsdb;\nuse tsdb;\ncreate column family t with comparator = BytesType;\n\ncreate keyspace tsdbuid;\nuse tsdbuid;\ncreate column family id with comparator = BytesType;\ncreate column family name with comparator = BytesType;\n</pre>\n <ol class=\"arabic simple\" start=\"3\"> <li>Build TSDB by executing <cite>sh build-cassandra.sh</cite> (or if you prefer Maven, <cite>sh build-cassandra.sh pom.xml</cite>)</li> <li>Modify your <cite>opentsdb.conf</cite> file with the <cite>asynccassandra.seeds</cite> parameter, e.g. <cite>asynccassandra.seeds=127.0.0.1:9160</cite>.</li> <li>In the config file, set <cite>tsd.storage.hbase.uid_table=tsdbuid</cite>\n</li> <li>Run the tsd via <cite>build/tsdb tsd --config=&lt;path&gt;/opentsdb.conf</cite>\n</li> </ol> <p>If you intend to use meta data or tree features, repeat the keyspace creation with the proper table name.</p>   <h2>Configuration</h2> <p>The following is a table with required and optional parameters to run OpenTSDB with Cassandra. These are in addition to the standard TSD configuration parameters from <a class=\"reference internal\" href=\"../configuration\"><em>Configuration</em></a></p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"60%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Property</th> <th class=\"head\">Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>asynccassandra.seeds</td> <td>String</td> <td>Required</td> <td>The list of nodes in your Cassandra cluster. These can be formatted <cite>&lt;hostname&gt;:&lt;port&gt;</cite>\n</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>asynccassandra.port</td> <td>Integer</td> <td>Optional</td> <td>An optional port to use for all nodes if not configured in the seeds setting.</td> <td>9160</td> </tr> </tbody> </table><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/backends/cassandra.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/backends/cassandra.html</a>\n  </p>\n</div>\n","user_guide/cli/mkmetric":"<h1>mkmetric</h1> <p>mkmetric is a shortcut to the <code class=\"docutils literal\"><span class=\"pre\">uid</span> <span class=\"pre\">assign</span> <span class=\"pre\">metrics</span> <span class=\"pre\">&lt;metric&gt;</span></code> command where you can provide multiple metric names in a single call and UIDs will be assigned or retrieved. If any of the metrics already exist, the assigned UID will be returned.</p>  <h2>Parameters</h2> <pre data-language=\"bash\">mkmetric metric [metrics]\n</pre>\n <p>Simply supply one or more space separate metric names in the call.</p> <p>Example</p> <pre data-language=\"bash\">mkmetric sys.cpu.user sys.cpu.nice sys.cpu.idle\n</pre>\n   <h2>Response</h2> <p>The response is the literal \"metrics\" followed by the name of the metric and a Java formatted byte array representing the UID assigned or retrieved for each metric, one per line.</p> <p>Example</p> <pre data-language=\"bash\">metrics sys.cpu.user: [0, 0, -58]\nmetrics sys.cpu.nice: [0, 0, -57]\nmetrics sys.cpu.idle: [0, 0, -59]\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/mkmetric.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/mkmetric.html</a>\n  </p>\n</div>\n","user_guide/cli/import":"<h1>import</h1> <p>The import command enables bulk loading of time series data into OpenTSDB. You provide one or more files and OpenTSDB will parse and load the data. Data must be formatted in the Telnet <code class=\"docutils literal\"><span class=\"pre\">put</span></code> style with one data point per line in a text file. Each file may optionally be compressed with GZip and if so, must end with the <code class=\"docutils literal\"><span class=\"pre\">.gz</span></code> extension.</p> <p>For more information on storing data in OpenTSDB, please see <a class=\"reference internal\" href=\"../writing\"><em>Writing Data</em></a></p>  <h2>Parameters</h2> <pre data-language=\"bash\">import path [...paths]\n</pre>\n <p>Paths may be absolute or relative</p> <p>Example</p> <pre data-language=\"bash\">import /home/hobbes/timeseries1.gz /home/hobbes/timeseries2.gz\n</pre>\n   <h2>Input Format</h2> <p>The format is the same as the Telnet <code class=\"docutils literal\"><span class=\"pre\">put</span></code> interface.</p> <blockquote> <div>&lt;metric&gt; &lt;timestamp&gt; &lt;value&gt; &lt;tagk=tagv&gt; [&lt;tagkN=tagvN&gt;]</div>\n</blockquote> <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>metric</strong> Is the name of the metric. Note that the metric name may not include spaces.</li> <li>\n<strong>timestamp</strong> Is the absolute timestamp of the data point in seconds or milliseconds</li> <li>\n<strong>value</strong> Is the value to store</li> <li>\n<strong>tagk=tagv</strong> Is a pair of one or more space sparate tag name and value pairs. Note that the tags may not have spaces in them.</li> </ul> </div>\n</blockquote> <p>Example:</p> <blockquote> <div>sys.cpu.user 1356998400 42 host=web01 cpu=0</div>\n</blockquote> <p>Successful processing will result in responses like:</p> <blockquote> <div>23:07:05.323 [main] INFO net.opentsdb.tools.TextImporter - Processed file in 22 ms, 2 data points (90.9 points/s)</div>\n</blockquote> <p>However if an error occurs, the importer will stop and the errant line will be printed. For example:</p> <blockquote> <div>23:07:06.375 [main] ERROR net.opentsdb.tools.TextImporter - Exception caught while processing file timeseries1.gz line=sys.cpu.system 1356998400 42 host=web02 novalue=</div>\n</blockquote> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Data points processed up to the error are written to storage. You should edit the file and clear all data points up to the line where the error occurred. If you fix the line and restart the import, conflicts may occur with the existing data. Future updates to OpenTSDB will handle this situation gracefully.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/import.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/import.html</a>\n  </p>\n</div>\n","user_guide/cli/query":"<h1>query</h1> <p>The query command line tool is meant to be a quick debugging tool for extracting data from OpenTSDB. The HTTP API will usually be much quicker when querying data as it incorprates caches and open connections to storage. Results are printed to stdout in a text format with one data point per line.</p> <p>Note that a query may return data points before and after the timespan requested. These are used in downsampling and graphing.</p>  <h2>Parameters</h2> <pre data-language=\"bash\">query [Gnuplot opts] START-DATE [END-DATE] &lt;aggregator&gt; [rate] [counter,max,reset] [downsample N FUNC] &lt;metric&gt; [&lt;tagk=tagv&gt;] [...&lt;tagk=tagv&gt;] [...queries]\n</pre>\n <table class=\"docutils\"> <colgroup> <col width=\"15%\"> <col width=\"5%\"> <col width=\"40%\"> <col width=\"5%\"> <col width=\"35%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>Gnuplot opts</td> <td>Strings</td> <td>Optional values used to generate Gnuplot scripts and graphs. Note that the actual graph PNG will not be generated, only the files (written to the temp directory)</td> <td> </td> <td>+wxh=1286x836</td> </tr> <tr class=\"row-odd\">\n<td>START-DATE</td> <td>String or Integer</td> <td>Starting time for the query. This may be an absolute or relative time. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details</td> <td> </td> <td>1h-ago</td> </tr> <tr class=\"row-even\">\n<td>END-DATE</td> <td>String or Integer</td> <td>Optional end time for the query. If not provided, the current time is used. This may be an absolute or relative time. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details</td> <td>Current timestamp</td> <td>2014/01/01-00:00:00</td> </tr> <tr class=\"row-odd\">\n<td>aggregator</td> <td>String</td> <td>A function to use when multiple timeseries are included in the results</td> <td> </td> <td>sum</td> </tr> <tr class=\"row-even\">\n<td>rate</td> <td>String</td> <td>The literal <code class=\"docutils literal\"><span class=\"pre\">rate</span></code> if the timeseries represents a counter and the results should be returned as delta per second</td> <td> </td> <td>rate</td> </tr> <tr class=\"row-odd\">\n<td>counter</td> <td>String</td> <td>Optional literal <code class=\"docutils literal\"><span class=\"pre\">counter</span></code> that indicates the underlying data is a monotonically increasong counter that may roll over</td> <td> </td> <td>counter</td> </tr> <tr class=\"row-even\">\n<td>max</td> <td>Integer</td> <td>A positive integer representing the maximum value for the counter</td> <td>Java Long.MaxValue</td> <td>65535</td> </tr> <tr class=\"row-odd\">\n<td>resetValue</td> <td>Integer</td> <td>An optional value that, when exceeded, will cause the aggregator to return a 0 instead of the calculated rate. Useful when data sources are frequently reset to avoid spurious spikes.</td> <td> </td> <td>65000</td> </tr> <tr class=\"row-even\">\n<td>downsample N FUNC</td> <td>String</td> <td>Optional downsampling specifier to group data into larger time spans and reduce the amount of data returned. Format is the literal <code class=\"docutils literal\"><span class=\"pre\">downsample</span></code> followed by a timespan in milliseconds and an aggregation function name</td> <td> </td> <td>downsample 300000 avg</td> </tr> <tr class=\"row-odd\">\n<td>metric</td> <td>String</td> <td>Required name of a metric to query for</td> <td> </td> <td>sys.cpu.user</td> </tr> <tr class=\"row-even\">\n<td>tagk=tagv</td> <td>String</td> <td>Optional pairs of tag names and tag values</td> <td> </td> <td>host=web01</td> </tr> <tr class=\"row-odd\">\n<td>additional queries</td> <td>String</td> <td>Optional additional queries to execute. Each query must follow the same format starting with an aggregator. All queries share the same start and end times.</td> <td> </td> <td>sum tsd.hbase.rpcs type=scan</td> </tr> </tbody> </table> <p>For more details on querying, please see <a class=\"reference internal\" href=\"../query/index\"><em>Querying or Reading Data</em></a>.</p> <p>Example:</p> <pre data-language=\"bash\">query 1h-ago now sum tsd.hbase.rpcs type=put sum tsd.hbase.rpcs type=scan\n</pre>\n   <h2>Output Format</h2> <p>Data is printed to stdout with one data point per line. If one or more Gnuplot options were specified, then scripts and data files for each query will be written to the configured temporary directory.</p> <blockquote> <div>&lt;metric&gt; &lt;timestamp&gt; &lt;value&gt; {&lt;tagk=tagv&gt;[,..&lt;tagkN=tagvN&gt;]}</div>\n</blockquote> <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>metric</strong> Is the name of the metric queried</li> <li>\n<strong>timestamp</strong> Is the absolute timestamp of the data point in seconds or milliseconds</li> <li>\n<strong>value</strong> Is the data point value</li> <li>\n<strong>tagk=tagv</strong> Is a list of common tag name and value pairs for all timeseries represented in the query</li> </ul> </div>\n</blockquote> <p>Example:</p> <pre data-language=\"bash\">tsd.hbase.rpcs 1393376401000 28067146491 {type=put, fqdn=tsdb-data-1}\ntsd.hbase.rpcs 1393376461000 28067526510 {type=put, fqdn=tsdb-data-1}\ntsd.hbase.rpcs 1393376521000 28067826659 {type=put, fqdn=tsdb-data-1}\ntsd.hbase.rpcs 1393376581000 28068126093 {type=put, fqdn=tsdb-data-1}\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/query.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/query.html</a>\n  </p>\n</div>\n","user_guide/writing":"<h1>Writing Data</h1> <p>You may want to jump right in and start throwing data into your TSD, but to really take advantage of OpenTSDB's power and flexibility, you may want to pause and think about your naming schema. After you've done that, you can proceed to pushing data over the Telnet or HTTP APIs, or use an existing tool with OpenTSDB support such as 'tcollector'.</p>  <h2>Naming Schema</h2> <p>Many metrics administrators are used to supplying a single name for their time series. For example, systems administrators used to RRD-style systems may name their time series <code class=\"docutils literal\"><span class=\"pre\">webserver01.sys.cpu.0.user</span></code>. The name tells us that the time series is recording the amount of time in user space for cpu <code class=\"docutils literal\"><span class=\"pre\">0</span></code> on <code class=\"docutils literal\"><span class=\"pre\">webserver01</span></code>. This works great if you want to retrieve just the user time for that cpu core on that particular web server later on.</p> <p>But what if the web server has 64 cores and you want to get the average time across all of them? Some systems allow you to specify a wild card such as <code class=\"docutils literal\"><span class=\"pre\">webserver01.sys.cpu.*.user</span></code> that would read all 64 files and aggregate the results. Alternatively, you could record a new time series called <code class=\"docutils literal\"><span class=\"pre\">webserver01.sys.cpu.user.all</span></code> that represents the same aggregate but you must now write '64 + 1' different time series. What if you had a thousand web servers and you wanted the average cpu time for all of your servers? You could craft a wild card query like <code class=\"docutils literal\"><span class=\"pre\">*.sys.cpu.*.user</span></code> and the system would open all 64,000 files, aggregate the results and return the data. Or you setup a process to pre-aggregate the data and write it to <code class=\"docutils literal\"><span class=\"pre\">webservers.sys.cpu.user.all</span></code>.</p> <p>OpenTSDB handles things a bit differently by introducing the idea of 'tags'. Each time series still has a 'metric' name, but it's much more generic, something that can be shared by many unique time series. Instead, the uniqueness comes from a combination of tag key/value pairs that allows for flexible queries with very fast aggregations.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Every time series in OpenTSDB must have at least one tag.</p> </div> <p>Take the previous example where the metric was <code class=\"docutils literal\"><span class=\"pre\">webserver01.sys.cpu.0.user</span></code>. In OpenTSDB, this may become <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,</span> <span class=\"pre\">cpu=0</span></code>. Now if we want the data for an individual core, we can craft a query like <code class=\"docutils literal\"><span class=\"pre\">sum:sys.cpu.user{host=webserver01,cpu=42}</span></code>. If we want all of the cores, we simply drop the cpu tag and ask for <code class=\"docutils literal\"><span class=\"pre\">sum:sys.cpu.user{host=webserver01}</span></code>. This will give us the aggregated results for all 64 cores. If we want the results for all 1,000 servers, we simply request <code class=\"docutils literal\"><span class=\"pre\">sum:sys.cpu.user</span></code>. The underlying data schema will store all of the <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span></code> time series next to each other so that aggregating the individual values is very fast and efficient. OpenTSDB was designed to make these aggregate queries as fast as possible since most users start out at a high level, then drill down for detailed information.</p> <div class=\"section\" id=\"aggregations\"> <h3>Aggregations</h3> <p>While the tagging system is flexible, some problems can arise if you don't understand the querying side of OpenTSDB, hence the need for some forethought. Take the example query above: <code class=\"docutils literal\"><span class=\"pre\">sum:sys.cpu.user{host=webserver01}</span></code>. We recorded 64 unique time series for <code class=\"docutils literal\"><span class=\"pre\">webserver01</span></code>, one time series for each of the CPU cores. When we issued that query, all of the time series for metric <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span></code> with the tag <code class=\"docutils literal\"><span class=\"pre\">host=webserver01</span></code> were retrieved, averaged, and returned as one series of numbers. Let's say the resulting average was <code class=\"docutils literal\"><span class=\"pre\">50</span></code> for timestamp <code class=\"docutils literal\"><span class=\"pre\">1356998400</span></code>. Now we were migrating from another system to OpenTSDB and had a process that pre-aggregated all 64 cores so that we could quickly get the average value and simply wrote a new time series <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01</span></code>. If we run the same query, we'll get a value of <code class=\"docutils literal\"><span class=\"pre\">100</span></code> at <code class=\"docutils literal\"><span class=\"pre\">1356998400</span></code>. What happened? OpenTSDB aggregated all 64 time series <em>and</em> the pre-aggregated time series to get to that 100. In storage, we would have something like this:</p> <pre data-language=\"python\">sys.cpu.user host=webserver01    1356998400  50\nsys.cpu.user host=webserver01,cpu=0  1356998400  1\nsys.cpu.user host=webserver01,cpu=1  1356998400  0\nsys.cpu.user host=webserver01,cpu=2  1356998400  2\nsys.cpu.user host=webserver01,cpu=3  1356998400  0\n...\nsys.cpu.user host=webserver01,cpu=63 1356998400  1\n</pre>\n <p>OpenTSDB will <em>automatically</em> aggregate <em>all</em> of the time series for the metric in a query if no tags are given. If one or more tags are defined, the aggregate will 'include all' time series that match on that tag, regardless of other tags. With the query <code class=\"docutils literal\"><span class=\"pre\">sum:sys.cpu.user{host=webserver01}</span></code>, we would include <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,cpu=0</span></code> as well as <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,cpu=0,manufacturer=Intel</span></code>, <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,foo=bar</span></code> and <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,cpu=0,datacenter=lax,department=ops</span></code>. The moral of this example is: <em>be careful with your naming schema</em>.</p> </div> <div class=\"section\" id=\"time-series-cardinality\"> <h3>Time Series Cardinality</h3> <p>A critical aspect of any naming schema is to consider the cardinality of your time series. Cardinality is defined as the number of unique items in a set. In OpenTSDB's case, this means the number of items associated with a metric, i.e. all of the possible tag name and value combinations, as well as the number of unique metric names, tag names and tag values. Cardinality is important for two reasons outlined below.</p> <p><strong>Limited Unique IDs (UIDs)</strong></p> <p>There is a limited number of unique IDs to assign for each metric, tag name and tag value. By default there are just over 16 million possible IDs per type. If, for example, you ran a very popular web service and tried to track the IP address of clients as a tag, e.g. <code class=\"docutils literal\"><span class=\"pre\">web.app.hits</span> <span class=\"pre\">clientip=38.26.34.10</span></code>, you may quickly run into the UID assignment limit as there are over 4 billion possible IP version 4 addresses. Additionally, this approach would lead to creating a very sparse time series as the user at address <code class=\"docutils literal\"><span class=\"pre\">38.26.34.10</span></code> may only use your app sporadically, or perhaps never again from that specific address.</p> <p>The UID limit is usually not an issue, however. A tag value is assigned a UID that is completely disassociated from its tag name. If you use numeric identifiers for tag values, the number is assigned a UID once and can be used with many tag names. For example, if we assign a UID to the number <code class=\"docutils literal\"><span class=\"pre\">2</span></code>, we could store timeseries with the tag pairs <code class=\"docutils literal\"><span class=\"pre\">cpu=2</span></code>, <code class=\"docutils literal\"><span class=\"pre\">interface=2</span></code>, <code class=\"docutils literal\"><span class=\"pre\">hdd=2</span></code> and <code class=\"docutils literal\"><span class=\"pre\">fan=2</span></code> while consuming only 1 tag value UID (<code class=\"docutils literal\"><span class=\"pre\">2</span></code>) and 4 tag name UIDs (<code class=\"docutils literal\"><span class=\"pre\">cpu</span></code>, <code class=\"docutils literal\"><span class=\"pre\">interface</span></code>, <code class=\"docutils literal\"><span class=\"pre\">hdd</span></code> and <code class=\"docutils literal\"><span class=\"pre\">fan</span></code>).</p> <p>If you think that the UID limit may impact you, first think about the queries that you want to execute. If we look at the <code class=\"docutils literal\"><span class=\"pre\">web.app.hits</span></code> example above, you probably only care about the total number of hits to your service and rarely need to drill down to a specific IP address. In that case, you may want to store the IP address as an annotation. That way you could still benefit from low cardinality but if you need to, you could search the results for that particular IP using external scripts. (Note: Support for annotation queries is expected in a <em>future</em> version of OpenTSDB.)</p> <p>If you desperately need more than 16 million values, you can increase the number of bytes that OpenTSDB uses to encode UIDs from 3 bytes up to a maximum of 8 bytes. This change would require modifying the value in source code, recompiling, deploying your customized code to all TSDs which will access this data, and maintaining this customization across all future patches and releases.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">It is possible that your situation requires this value to be increased. If you choose to modify this value, you must start with fresh data and a new UID table. Any data written with a TSD expecting 3-byte UID encoding will be incompatible with this change, so ensure that all of your TSDs are running the same modified code and that any data you have stored in OpenTSDB prior to making this change has been exported to a location where it can be manipulated by external tools. See the <code class=\"docutils literal\"><span class=\"pre\">TSDB.java</span></code> file for the values to change.</p> </div> <p><strong>Query Speed</strong></p> <p>Cardinality also affects query speed a great deal, so consider the queries you will be performing frequently and optimize your naming schema for those. OpenTSDB creates a new row per time series per hour. If we have the time series <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span> <span class=\"pre\">host=webserver01,cpu=0</span></code> with data written every second for 1 day, that would result in 86400 rows of data. However if we have 8 possible CPU cores for that host, now we have 691200 rows of data. This looks good because we can get easily a sum or average of CPU usage across all cores by issuing a query like <code class=\"docutils literal\"><span class=\"pre\">start=1d-ago&amp;m=avg:sys.cpu.user{host=webserver01}</span></code>.</p> <p>However what if we have 20,000 hosts, each with 8 cores? Now we will have 3.8 million rows per day due to a high cardinality of host values. Queries for the average core usage on host <code class=\"docutils literal\"><span class=\"pre\">webserver01</span></code> will be slower as it must pick out 691200 rows out of 3.8 million.</p> <p>The benefits of this schema are that you have very deep granularity in your data, e.g., storing usage metrics on a per-core basis. You can also easily craft a query to get the average usage across all cores an all hosts: <code class=\"docutils literal\"><span class=\"pre\">start=1d-ago&amp;m=avg:sys.cpu.user</span></code>. However queries against that particular metric will take longer as there are more rows to sift through.</p> <p>Here are some common means of dealing with cardinality:</p> <p><strong>Pre-Aggregate</strong> - In the example above with <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span></code>, you generally care about the average usage on the host, not the usage per core. While the data collector may send a separate value per core with the tagging schema above, the collector could also send one extra data point such as <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user.avg</span> <span class=\"pre\">host=webserver01</span></code>. Now you have a completely separate timeseries that would only have 24 rows per day and with 20K hosts, only 480K rows to sift through. Queries will be much more responsive for the per-host average and you still have per-core data to drill down to separately.</p> <p><strong>Shift to Metric</strong> - What if you really only care about the metrics for a particular host and don't need to aggregate across hosts? In that case you can shift the hostname to the metric. Our previous example becomes <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user.websvr01</span> <span class=\"pre\">cpu=0</span></code>. Queries against this schema are very fast as there would only be 192 rows per day for the metric. However to aggregate across hosts you would have to execute multiple queries and aggregate outside of OpenTSDB. (Future work will include this capability).</p> </div> <div class=\"section\" id=\"naming-conclusion\"> <h3>Naming Conclusion</h3> <p>When you design your naming schema, keep these suggestions in mind:</p> <ul class=\"simple\"> <li>Be consistent with your naming to reduce duplication. Always use the same case for metrics, tag names and values.</li> <li>Use the same number and type of tags for each metric. E.g. don't store <code class=\"docutils literal\"><span class=\"pre\">my.metric</span> <span class=\"pre\">host=foo</span></code> and <code class=\"docutils literal\"><span class=\"pre\">my.metric</span> <span class=\"pre\">datacenter=lga</span></code>.</li> <li>Think about the most common queries you'll be executing and optimize your schema for those queries</li> <li>Think about how you may want to drill down when querying</li> <li>Don't use too many tags, keep it to a fairly small number, usually up to 4 or 5 tags (By default, OpenTSDB supports a maximum of 8 tags).</li> </ul> </div>   <h2>Data Specification</h2> <p>Every time series data point requires the following data:</p> <ul class=\"simple\"> <li>metric - A generic name for the time series such as <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span></code>, <code class=\"docutils literal\"><span class=\"pre\">stock.quote</span></code> or <code class=\"docutils literal\"><span class=\"pre\">env.probe.temp</span></code>.</li> <li>timestamp - A Unix/POSIX Epoch timestamp in seconds or milliseconds defined as the number of seconds that have elapsed since January 1st, 1970 at 00:00:00 UTC time. Only positive timestamps are supported at this time.</li> <li>value - A numeric value to store at the given timestamp for the time series. This may be an integer or a floating point value.</li> <li>tag(s) - A key/value pair consisting of a <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> (the key) and a <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> (the value). Each data point must have at least one tag.</li> </ul> <div class=\"section\" id=\"timestamps\"> <h3>Timestamps</h3> <p>Data can be written to OpenTSDB with second or millisecond resolution. Timestamps must be integers and be no longer than 13 digits (See first [NOTE] below). Millisecond timestamps must be of the format <code class=\"docutils literal\"><span class=\"pre\">1364410924250</span></code> where the final three digits represent the milliseconds. Applications that generate timestamps with more than 13 digits (i.e., greater than millisecond resolution) must be rounded to a maximum of 13 digits before submitting or an error will be generated.</p> <p>Timestamps with second resolution are stored on 2 bytes while millisecond resolution are stored on 4. Thus if you do not need millisecond resolution or all of your data points are on 1 second boundaries, we recommend that you submit timestamps with 10 digits for second resolution so that you can save on storage space. It's also a good idea to avoid mixing second and millisecond timestamps for a given time series. Doing so will slow down queries as iteration across mixed timestamps takes longer than if you only record one type or the other. OpenTSDB will store whatever you give it.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">When writing to the telnet interface, timestamps may optionally be written in the form <code class=\"docutils literal\"><span class=\"pre\">1364410924.250</span></code>, where three digits representing the milliseconds are placed after a period. Timestamps sent to the <code class=\"docutils literal\"><span class=\"pre\">/api/put</span></code> endpoint over HTTP <em>must</em> be integers and may not have periods. Data with millisecond resolution can only be extracted via the <code class=\"docutils literal\"><span class=\"pre\">/api/query</span></code> endpoint or CLI command at this time. See <a class=\"reference internal\" href=\"query/index\"><em>Querying or Reading Data</em></a> for details.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Providing millisecond resolution does not necessarily mean that OpenTSDB supports write speeds of 1 data point per millisecond over many time series. While a single TSD may be able to handle a few thousand writes per second, that would only cover a few time series if you're trying to store a point every millisecond. Instead OpenTSDB aims to provide greater measurement accuracy and you should generally avoid recording data at such a speed, particularly for long running time series.</p> </div> </div> <div class=\"section\" id=\"metrics-and-tags\"> <h3>Metrics and Tags</h3> <p>The following rules apply to metric and tag values:</p> <ul class=\"simple\"> <li>Strings are case sensitive, i.e. \"Sys.Cpu.User\" will be stored separately from \"sys.cpu.user\"</li> <li>Spaces are not allowed</li> <li>Only the following characters are allowed: <code class=\"docutils literal\"><span class=\"pre\">a</span></code> to <code class=\"docutils literal\"><span class=\"pre\">z</span></code>, <code class=\"docutils literal\"><span class=\"pre\">A</span></code> to <code class=\"docutils literal\"><span class=\"pre\">Z</span></code>, <code class=\"docutils literal\"><span class=\"pre\">0</span></code> to <code class=\"docutils literal\"><span class=\"pre\">9</span></code>, <code class=\"docutils literal\"><span class=\"pre\">-</span></code>, <code class=\"docutils literal\"><span class=\"pre\">_</span></code>, <code class=\"docutils literal\"><span class=\"pre\">.</span></code>, <code class=\"docutils literal\"><span class=\"pre\">/</span></code> or Unicode letters (as per the specification)</li> </ul> <p>Metric and tags are not limited in length, though you should try to keep the values fairly short.</p> </div> <div class=\"section\" id=\"integer-values\"> <h3>Integer Values</h3> <p>If the value from a <code class=\"docutils literal\"><span class=\"pre\">put</span></code> command is parsed without a decimal point (<code class=\"docutils literal\"><span class=\"pre\">.</span></code>), it will be treated as a signed integer. Integers are stored, unsigned, with variable length encoding so that a data point may take as little as 1 byte of space or up to 8 bytes. This means a data point can have a minimum value of -9,223,372,036,854,775,808 and a maximum value of 9,223,372,036,854,775,807 (inclusive). Integers cannot have commas or any character other than digits and the dash (for negative values). For example, in order to store the maximum value, it must be provided in the form <code class=\"docutils literal\"><span class=\"pre\">9223372036854775807</span></code>.</p> </div> <div class=\"section\" id=\"floating-point-values\"> <h3>Floating Point Values</h3> <p>If the value from a <code class=\"docutils literal\"><span class=\"pre\">put</span></code> command is parsed with a decimal point (<code class=\"docutils literal\"><span class=\"pre\">.</span></code>) it will be treated as a floating point value. Currently all floating point values are stored on 4 bytes, single-precision, with support for 8 bytes planned for a future release. Floats are stored in IEEE 754 floating-point \"single format\" with positive and negative value support. Infinity and Not-a-Number values are not supported and will throw an error if supplied to a TSD. See <a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/IEEE_floating_point\">Wikipedia</a> and the <a class=\"reference external\" href=\"http://docs.oracle.com/javase/specs/jls/se7/html/jls-4.html#jls-4.2.3\">Java Documentation</a> for details.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Because OpenTSDB only supports floating point values, it is not suitable for storing measurements that require exact values like currency. This is why, when storing a value like <code class=\"docutils literal\"><span class=\"pre\">15.2</span></code> the database may return <code class=\"docutils literal\"><span class=\"pre\">15.199999809265137</span></code>.</p> </div> </div> <div class=\"section\" id=\"ordering\"> <h3>Ordering</h3> <p>Unlike other solutions, OpenTSDB allows for writing data for a given time series in any order you want. This enables significant flexibility in writing data to a TSD, allowing for populating current data from your systems, then importing historical data at a later time.</p> </div> <div class=\"section\" id=\"duplicate-data-points\"> <h3>Duplicate Data Points</h3> <p>Writing data points in OpenTSDB is generally idempotent within an hour of the original write. This means you can write the value <code class=\"docutils literal\"><span class=\"pre\">42</span></code> at timestamp <code class=\"docutils literal\"><span class=\"pre\">1356998400</span></code> and then write <code class=\"docutils literal\"><span class=\"pre\">42</span></code> again for the same time and nothing bad will happen. However if you have compactions enabled to reduce storage consumption and write the same data point after the row of data has been compacted, an exception may be returned when you query over that row. If you attempt to write two different values with the same timestamp, a duplicate data point exception may be thrown during query time. This is due to a difference in encoding integers on 1, 2, 4 or 8 bytes and floating point numbers. If the first value was an integer and the second a floating point, the duplicate error will always be thrown. However if both values were floats or they were both integers that could be encoded on the same length, then the original value may be overwritten if a compaction has not occurred on the row.</p> <p>In most situations, if a duplicate data point is written it is usually an indication that something went wrong with the data source such as a process restarting unexpectedly or a bug in a script. OpenTSDB will fail \"safe\" by throwing an exception when you query over a row with one or more duplicates so you can down the issue.</p> <p>With OpenTSDB 2.1 you can enable last-write-wins by setting the <code class=\"docutils literal\"><span class=\"pre\">tsd.storage.fix_duplicates</span></code> configuration value to <code class=\"docutils literal\"><span class=\"pre\">true</span></code>. With this flag enabled, at query time, the most recent value recorded will be returned instead of throwing an exception. A warning will also be written to the log file noting a duplicate was found. If compaction is also enabled, then the original compacted value will be overwritten with the latest value.</p> </div>   <h2>Input Methods</h2> <p>There are currently three main methods to get data into OpenTSDB: Telnet API, HTTP API and batch import from a file. Alternatively you can use a tool that provides OpenTSDB support, or if you're extremely adventurous, use the Java library.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Don't try to write directly to the underlying storage system, e.g. HBase. Just don't. It'll get messy quickly.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If the <code class=\"docutils literal\"><span class=\"pre\">tsd.mode</span></code> is set to <code class=\"docutils literal\"><span class=\"pre\">ro</span></code> instead of <code class=\"docutils literal\"><span class=\"pre\">rw</span></code>, the TSD will not accept data points through RPC calls. Telnet style calls will throw an exception and calls to the HTTP endpoint will return a 404 error. However it is still possible to write via the JAVA API when the mode is set to read only.</p> </div> <div class=\"section\" id=\"telnet\"> <h3>Telnet</h3> <p>The easiest way to get started with OpenTSDB is to open up a terminal or telnet client, connect to your TSD and issue a <code class=\"docutils literal\"><span class=\"pre\">put</span></code> command and hit 'enter'. If you are writing a program, simply open a socket, print the string command with a new line and send the packet. The telnet command format is:</p> <pre data-language=\"python\">put &lt;metric&gt; &lt;timestamp&gt; &lt;value&gt; &lt;tagk1=tagv1[ tagk2=tagv2 ...tagkN=tagvN]&gt;\n</pre>\n <p>For example:</p> <pre data-language=\"python\">put sys.cpu.user 1356998400 42.5 host=webserver01 cpu=0\n</pre>\n <p>Each <code class=\"docutils literal\"><span class=\"pre\">put</span></code> can only send a single data point. Don't forget the newline character, e.g. <code class=\"docutils literal\"><span class=\"pre\">\\n</span></code> at the end of your command.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The Telnet method of writing is discouraged as it doesn't provide a way of determining which data points failed to write due to formatting or storage errors. Instead use the HTTP API.</p> </div> </div> <div class=\"section\" id=\"http-api\"> <h3>Http API</h3> <p>As of version 2.0, data can be sent over HTTP in formats supported by 'Serializer' plugins. Multiple, un-related data points can be sent in a single HTTP POST request to save bandwidth. See the <a class=\"reference internal\" href=\"../api_http/put\"><em>/api/put</em></a> for details.</p> </div> <div class=\"section\" id=\"batch-import\"> <h3>Batch Import</h3> <p>If you are importing data from another system or you need to backfill historical data, you can use the <code class=\"docutils literal\"><span class=\"pre\">import</span></code> CLI utility. See <a class=\"reference internal\" href=\"cli/import\"><em>import</em></a> for details.</p> </div>   <h2>Write Performance</h2> <p>OpenTSDB can scale to writing millions of data points per 'second' on commodity servers with regular spinning hard drives. However users who fire up a VM with HBase in stand-alone mode and try to slam millions of data points at a brand new TSD are disappointed when they can only write data in the hundreds of points per second. Here's what you need to do to scale for brand new installs or testing and for expanding existing systems.</p> <div class=\"section\" id=\"uid-assignment\"> <h3>UID Assignment</h3> <p>The first sticking point folks run into is ''uid assignment''. Every string for a metric, tag key and tag value must be assigned a UID before the data point can be stored. For example, the metric <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span></code> may be assigned a UID of <code class=\"docutils literal\"><span class=\"pre\">000001</span></code> the first time it is encountered by a TSD. This assignment takes a fair amount of time as it must fetch an available UID, write a UID to name mapping and a name to UID mapping, then use the UID to write the data point's row key. The UID will be stored in the TSD's cache so that the next time the same metric comes through, it can find the UID very quickly.</p> <p>Therefore, we recommend that you 'pre-assign' UID to as many metrics, tag keys and tag values as you can. If you have designed a naming schema as recommended above, you'll know most of the values to assign. You can use the CLI tools <a class=\"reference internal\" href=\"cli/mkmetric\"><em>mkmetric</em></a>, <a class=\"reference internal\" href=\"cli/uid\"><em>uid</em></a> or the HTTP API <a class=\"reference internal\" href=\"../api_http/uid/index\"><em>/api/uid</em></a> to perform pre-assignments. Any time you are about to send a bunch of new metrics or tags to a running OpenTSDB cluster, try to pre-assign or the TSDs will bog down a bit when they get the new data.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If you restart a TSD, it will have to lookup the UID for every metric and tag so performance will be a little slow until the cache is filled.</p> </div> </div> <div class=\"section\" id=\"random-metric-uid-assignment\"> <h3>Random Metric UID Assignment</h3> <p>With 2.2 you can randomly assign UIDs to metrics for better region server write distribution. Because metric UIDs are located at the start of the row key, if a new set of busy metric are created, all writes for those metric will be on the same server until the region splits. With random UID generation enabled, the new metrics will be distributed across the key space and likely to wind up in different regions on different servers.</p> <p>Random metric generation can be enabled or disabled at any time by modifying the <code class=\"docutils literal\"><span class=\"pre\">tsd.core.uid.random_metrics</span></code> flag and data is backwards compatible all the way back to OpenTSDB 1.0. However it is recommended that you pre-split your TSDB data table according to the full metric UID space. E.g. if you use the default UID size in OpenTSDB, UIDs are 3 bytes wide, thus you can have 16,777,215 values. If you already have data in your TSDB table and choose to enable random UIDs, you may want to create new regions.</p> <p>When generating random IDs, TSDB will try up to 10 times to assign a UID without a collision. Thus as the number of assigned metrics increases so too will the number of collisions and the likely hood that a data point may be dropped due to retries. If you enable random IDs and keep adding more metrics then you may want to increase the number of bytes on metric UIDs. Note that the UID change is not backwards compatible so you have to create a new table and migrate your old data.</p> </div> <div class=\"section\" id=\"salting\"> <h3>Salting</h3> <p>In 2.2 salting is supported to greatly increase write distribution across region servers. When enabled, a configured number of bytes are prepended to each row key. Each metric and combination of tags is then hashed into one \"bucket\", the ID of which is written to the salt bytes. Distribution is improved particularly for high-cardinality metrics (those with a large number of tag combinations) as the time series are split across the configured bucket count, thus routed to different regions and different servers. For example, without salting, a metric with 1 million series will be written to a single region on a single server. With salting enabled and a bucket size of 20, the series will be split across 20 regions (and 20 servers if the cluster has that many hosts) where each region has 50,000 series.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Because salting modifies the storage format, you cannot enable or disable salting at whim. If you have existing data, you must start a new data table and migrate data from the old table into the new one. Salted data cannot be read from previous versions of OpenTSDB.</p> </div> <p>To enable salting you must modify the config file parameter <code class=\"docutils literal\"><span class=\"pre\">tsd.storage.salt.width</span></code> and optionally <code class=\"docutils literal\"><span class=\"pre\">tsd.storage.salt.buckets</span></code>. We recommend setting the salt width to <code class=\"docutils literal\"><span class=\"pre\">1</span></code> and determine the number of buckets based on a factor of the number of region servers in your cluster. Note that at query time, the TSD will fire <code class=\"docutils literal\"><span class=\"pre\">tsd.storage.salt.buckets</span></code> number of scanners to fetch data. The proper number of salt buckets must be determined through experimentation as at some point query performance may suffer due to having too many scanners open and collating the results. In the future the salt width and buckets may be configurable but we didn't want folks changing settings on accident and losing data.</p> </div> <div class=\"section\" id=\"appends\"> <h3>Appends</h3> <p>Also in 2.2, writing to HBase columns via appends is now supported. This can improve both read and write performance in that TSDs will no longer maintain a queue of rows to compact at the end of each hour, thus preventing a massive read and re-write operation in HBase. However due to the way appends operate in HBase, an increase in CPU utilization, store file size and HDFS traffic will occur on the region servers. Make sure to monitor your HBase servers closely.</p> <p>At read time, only one column is returned per row similar to post-TSD-compaction rows. However note that if the <code class=\"docutils literal\"><span class=\"pre\">tsd.storage.repair_appends</span></code> is enabled, then when a column has duplicates or out of order data, it will be re-written to HBase. Also columns with many duplicates or ordering issues may slow queries as they must be resolved before answering the caller.</p> <p>Appends can be enabled and disabled at any time. However versions of OpenTSDB prior to 2.2 will skip over appended values.</p> </div> <div class=\"section\" id=\"pre-split-hbase-regions\"> <h3>Pre-Split HBase Regions</h3> <p>For brand new installs you will see much better performance if you pre-split the regions in HBase regardless of if you're testing on a stand-alone server or running a full cluster. HBase regions handle a defined range of row keys and are essentially a single file. When you create the <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> table and start writing data for the first time, all of those data points are being sent to this one file on one server. As a region fills up, HBase will automatically split it into different files and move it to other servers in the cluster, but when this happens, the TSDs cannot write to the region and must buffer the data points. Therefore, if you can pre-allocate a number of regions before you start writing, the TSDs can send data to multiple files or servers and you'll be taking advantage of the linear scalability immediately.</p> <p>The simplest way to pre-split your <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> table regions is to estimate the number of unique metric names you'll be recording. If you have designed a naming schema, you should have a pretty good idea. Let's say that we will track 4,000 metrics in our system. That's not to say 4,000 time series, as we're not counting the tags yet, just the metric names such as \"sys.cpu.user\". Data points are written in row keys where the metric's UID comprises the first bytes, 3 bytes by default. The first metric will be assigned a UID of <code class=\"docutils literal\"><span class=\"pre\">000001</span></code> as a hex encoded value. The 4,000th metric will have a UID of <code class=\"docutils literal\"><span class=\"pre\">000FA0</span></code> in hex. You can use these as the start and end keys in the script from the <a class=\"reference external\" href=\"http://hbase.apache.org/book/perf.writing.html\">HBase Book</a> to split your table into any number of regions. 256 regions may be a good place to start depending on how many time series share each metric.</p> <p>TODO - include scripts for pre-splitting.</p> <p>The simple split method above assumes that you have roughly an equal number of time series per metric (i.e. a fairly consistent cardinality). E.g. the metric with a UID of <code class=\"docutils literal\"><span class=\"pre\">000001</span></code> may have 200 time series and <code class=\"docutils literal\"><span class=\"pre\">000FA0</span></code> has about 150. If you have a wide range of time series per metric, e.g. <code class=\"docutils literal\"><span class=\"pre\">000001</span></code> has 10,000 time series while <code class=\"docutils literal\"><span class=\"pre\">000FA0</span></code> only has 2, you may need to develop a more complex splitting algorithm.</p> <p>But don't worry too much about splitting. As stated above, HBase will automatically split regions for you so over time, the data will be distributed fairly evenly.</p> </div> <div class=\"section\" id=\"distributed-hbase\"> <h3>Distributed HBase</h3> <p>HBase will run in stand-alone mode where it will use the local file system for storing files. It will still use multiple regions and perform as well as the underlying disk or raid array will let it. You'll definitely want a RAID array under HBase so that if a drive fails, you can replace it without losing data. This kind of setup is fine for testing or very small installations and you should be able to get into the low thousands of data points per second.</p> <p>However if you want serious throughput and scalability you have to setup a Hadoop and HBase cluster with multiple servers. In a distributed setup HDFS manages region files, automatically distributing copies to different servers for fault tolerance. HBase assigns regions to different servers and OpenTSDB's client will send data points to the specific server where they will be stored. You're now spreading operations amongst multiple servers, increasing performance and storage. If you need even more throughput or storage, just add nodes or disks.</p> <p>There are a number of ways to setup a Hadoop/HBase cluster and a ton of various tuning tweaks to make, so Google around and ask user groups for advice. Some general recommendations include:</p> <ul class=\"simple\"> <li>Dedicate a pair of high memory, low disk space servers for the Name Node. Set them up for high availability using something like Heartbeat and Pacemaker.</li> <li>Setup Zookeeper on at least 3 servers for fault tolerance. They must have a lot of RAM and a fairly fast disk for log writing. On small clusters, these can run on the Name node servers.</li> <li>JBOD for the HDFS data nodes</li> <li>HBase region servers can be collocated with the HDFS data nodes</li> <li>At least 1 gbps links between servers, 10 gbps preferable.</li> <li>Keep the cluster in a single data center</li> </ul> </div> <div class=\"section\" id=\"multiple-tsds\"> <h3>Multiple TSDs</h3> <p>A single TSD can handle thousands of writes per second. But if you have many sources it's best to scale by running multiple TSDs and using a load balancer (such as Varnish or DNS round robin) to distribute the writes. Many users colocate TSDs on their HBase region servers when the cluster is dedicated to OpenTSDB.</p> </div> <div class=\"section\" id=\"persistent-connections\"> <h3>Persistent Connections</h3> <p>Enable keep-alives in the TSDs and make sure that any applications you are using to send time series data keep their connections open instead of opening and closing for every write. See <a class=\"reference internal\" href=\"configuration\"><em>Configuration</em></a> for details.</p> </div> <div class=\"section\" id=\"disable-meta-data-and-real-time-publishing\"> <h3>Disable Meta Data and Real Time Publishing</h3> <p>OpenTSDB 2.0 introduced meta data for tracking the kinds of data in the system. When tracking is enabled, a counter is incremented for every data point written and new UIDs or time series will generate meta data. The data may be pushed to a search engine or passed through tree generation code. These processes require greater memory in the TSD and may affect throughput. Tracking is disabled by default so test it out before enabling the feature.</p> <p>2.0 also introduced a real-time publishing plugin where incoming data points can be emitted to another destination immediately after they're queued for storage. This is disabled by default so test any plugins you are interested in before deploying in production.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/writing.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/writing.html</a>\n  </p>\n</div>\n","user_guide/backends/hbase":"<h1>HBase Schema</h1>  <h2>Data Table Schema</h2> <p>All OpenTSDB data points are stored in a single, massive table, named <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> by default. This is to take advantage of HBases ordering and region distribution. All values are stored in the <code class=\"docutils literal\"><span class=\"pre\">t</span></code> column family.</p> <p><strong>Row Key</strong> - Row keys are byte arrays comprised of the metric UID, a base timestamp and the UID for tagk/v pairs: <code class=\"docutils literal\"><span class=\"pre\">&lt;metric_uid&gt;&lt;timestamp&gt;&lt;tagk1&gt;&lt;tagv1&gt;[...&lt;tagkN&gt;&lt;tagvN&gt;]</span></code>. By default, UIDs are encoded on 3 bytes.</p> <p>The timestamp is a Unix epoch value in seconds encoded on 4 bytes. Rows are broken up into hour increments, reflected by the timestamp in each row. Thus each timestamp will be normalized to an hour value, e.g. <em>2013-01-01 08:00:00</em>. This is to avoid stuffing too many data points in a single row as that would affect region distribution. Also, since HBase sorts on the row key, data for the same metric and time bucket, but with different tags, will be grouped together for efficient queries.</p> <p>Some example row keys, represented as hex are:</p> <pre data-language=\"python\">00000150E22700000001000001\n00000150E22700000001000001000002000004\n00000150E22700000001000002\n00000150E22700000001000003\n00000150E23510000001000001\n00000150E23510000001000001000002000004\n00000150E23510000001000002\n00000150E23510000001000003\n00000150E24320000001000001\n00000150E24320000001000001000002000004\n00000150E24320000001000002\n00000150E24320000001000003\n</pre>\n <p>where:</p> <pre data-language=\"python\">00000150E22700000001000001\n'----''------''----''----'\nmetric  time   tagk  tagv\n</pre>\n <p>This represents a single metric but four time series across three hours. Note how there is one time series with two sets of tags:</p> <pre data-language=\"python\">00000150E22700000001000001000002000004\n'----''------''----''----''----''----'\nmetric  time   tagk  tagv  tagk  tagv\n</pre>\n <p>Tag names (tagk) are sorted alphabetically before storage, so the \"host\" tag will always appear first in the row key/TSUID ahead of \"owner\".</p> <div class=\"section\" id=\"data-point-columns\"> <h3>Data Point Columns</h3> <p>By far the most common column are data points. These are the actual values recorded when data is sent to the TSD for storage.</p> <p><strong>Column Qualifiers</strong> - The qualifier is comprised of 2 or 4 bytes that encode an offset from the row's base time and flags to determine if the value is an integer or a decimal value. Qualifiers encode an offset from the row base time as well as the format and length of the data stored.</p> <p>Columns with 2 byte qualifiers have an offset in seconds. The first 12 bits of the qualifer represent an integer that is a delta from the timestamp in the row key. For example, if the row key is normalized to <code class=\"docutils literal\"><span class=\"pre\">1292148000</span></code> and a data point comes in for <code class=\"docutils literal\"><span class=\"pre\">1292148123</span></code>, the recorded delta will be <code class=\"docutils literal\"><span class=\"pre\">123</span></code>. The last 4 bits are format flags</p> <p>Columns with 4 byte qualifiers have an offset in milliseconds. The first 4 <em>bits</em> of the qualifier will always be set to <code class=\"docutils literal\"><span class=\"pre\">1</span></code> or <code class=\"docutils literal\"><span class=\"pre\">F</span></code> in hex. The next 22 bits encode the offset in milliseconds as an unsigned integer. The next 2 bits are reserved and the final 4 bits are format flags.</p> <p>The last 4 bits of either column type describe the data stored. The first bit is a flag that indicates whether or not the value is an integer or floating point. A value of 0 indicates an integer, 1 indicates a float. The last 3 bits indicate the length of the data, offset by 1. A value of <code class=\"docutils literal\"><span class=\"pre\">000</span></code> indicates a 1 byte value while <code class=\"docutils literal\"><span class=\"pre\">010</span></code> indicates a 2 byte value. The length must reflect a value of 1, 2, 4 or 8. Anything else indicates an error.</p> <p>For example, <code class=\"docutils literal\"><span class=\"pre\">0100</span></code> means the column value is an 8 byte, signed integer. <code class=\"docutils literal\"><span class=\"pre\">1011</span></code> indicates the column value is a 4 byte floating point value So the qualifier for the data point at <code class=\"docutils literal\"><span class=\"pre\">1292148123</span></code> with an integer value of 4294967296 would have a qualifier of <code class=\"docutils literal\"><span class=\"pre\">0000011110110100</span></code> or <code class=\"docutils literal\"><span class=\"pre\">07B4</span></code> in hex.</p> <p><strong>Column Values</strong> - 1 to 8 bytes encoded as indicated by the qualifier flag.</p> </div> <div class=\"section\" id=\"compactions\"> <h3>Compactions</h3> <p>If compactions have been enabled for a TSD, a row may be compacted after it's base hour has passed or a query has run over the row. Compacted columns simply squash all of the data points together to reduce the amount of overhead consumed by disparate data points. Data is initially written to individual columns for speed, then compacted later for storage efficiency. Once a row is compacted, the individual data points are deleted. Data may be written back to the row and compacted again later.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The OpenTSDB compaction process is entirely separate in scope and definition than the HBase idea of compactions.</p> </div> <p><strong>Column Qualifiers</strong> - The qualifier for a compacted column will always be an even number of bytes and is simply a concatenation of the qualifiers for every data point that was in the row. Since we know each data point qualifier is 2 bytes, it's simple to split this up. A qualifier in hex with 2 data points may look like <code class=\"docutils literal\"><span class=\"pre\">07B407D4</span></code>.</p> <p><strong>Column Values</strong> - The value is also a concatenation of all of the individual data points. The qualifier is split first and the flags for each data point determine if the parser consumes 4 or 8 bytes</p> </div> <div class=\"section\" id=\"annotations-or-other-objects\"> <h3>Annotations or Other Objects</h3> <p>A row may store notes about the timeseries inline with the datapoints. Objects differ from data points by having an odd number of bytes in the qualifier.</p> <p><strong>Column Qualifiers</strong> - The qualifier is on 3 or 5 bytes with the first byte an ID that denotes the column as a qualifier. The first byte will always have a hex value of <code class=\"docutils literal\"><span class=\"pre\">01</span></code> for annotations (future object types will have a different prefix). The remaining bytes encode the timestamp delta from the row base time in a manner similar to a data point, though without the flags. If the qualifier is 3 bytes in length, the offset is in seconds. If the qualifier is 5 bytes in length, the offset is in milliseconds. Thus if we record an annotation at <code class=\"docutils literal\"><span class=\"pre\">1292148123</span></code>, the delta will be <code class=\"docutils literal\"><span class=\"pre\">123</span></code> and the qualifier, in hex, will be <code class=\"docutils literal\"><span class=\"pre\">01007B</span></code>.</p> <p><strong>Column Values</strong> - Annotation values are UTF-8 encoded JSON objects. Do not modify this value directly. The order of the fields is important, affecting CAS calls.</p> </div>   <h2>UID Table Schema</h2> <p>A separate, smaller table called <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> stores UID mappings, both forward and reverse. Two columns exist, one named <code class=\"docutils literal\"><span class=\"pre\">name</span></code> that maps a UID to a string and another <code class=\"docutils literal\"><span class=\"pre\">id</span></code> mapping strings to UIDs. Each row in the column family will have at least one of three columns with mapping values. The standard column qualifiers are:</p> <ul class=\"simple\"> <li>\n<code class=\"docutils literal\"><span class=\"pre\">metrics</span></code> for mapping metric names to UIDs</li> <li>\n<code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> for mapping tag names to UIDs</li> <li>\n<code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> for mapping tag values to UIDs.</li> </ul> <p>The <code class=\"docutils literal\"><span class=\"pre\">name</span></code> family may also contain additional meta-data columns if configured.</p> <div class=\"section\" id=\"id-column-family\"> <h3>\n<code class=\"docutils literal\"><span class=\"pre\">id</span></code> Column Family</h3> <p><strong>Row Key</strong> - This will be the string assigned to the UID. E.g. for a metric we may have a value of <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.user</span></code> or for a tag value it may be <code class=\"docutils literal\"><span class=\"pre\">42</span></code>.</p> <p><strong>Column Qualifiers</strong> - One of the standard column types above.</p> <p><strong>Column Value</strong> - An unsigned integer encoded on 3 bytes by default reflecting the UID assigned to the string for the column type. If the UID length has been changed in the source code, the width may vary.</p> </div> <div class=\"section\" id=\"name-column-family\"> <h3>\n<code class=\"docutils literal\"><span class=\"pre\">name</span></code> Column Family</h3> <p><strong>Row Key</strong> - The unsigned integer UID encoded on 3 bytes by default. If the UID length has been changed in the source code, the width may be different.</p> <p><strong>Column Qualifiers</strong> - One of the standard column types above OR one of <code class=\"docutils literal\"><span class=\"pre\">metrics_meta</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tagk_meta</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tagv_meta</span></code>.</p> <p><strong>Column Value</strong> - For the standard qualifiers above, the string assigned to the UID. For a <code class=\"docutils literal\"><span class=\"pre\">*_meta</span></code> column, the value will be a UTF-8 encoded, JSON formatted UIDMeta Object as a string. Do not modify the column value outside of OpenTSDB. The order of the fields is important, affecting CAS calls.</p> </div> <div class=\"section\" id=\"uid-assignment-row\"> <h3>UID Assignment Row</h3> <p>Within the <code class=\"docutils literal\"><span class=\"pre\">id</span></code> column family is a row with a single byte key of <code class=\"docutils literal\"><span class=\"pre\">\\x00</span></code>. This is the UID row that is incremented for the proper column type (metrics, tagk or tagv) when a new UID is assigned. The column values are 8 byte signed integers and reflect the maximum UID assigned for each type. On assignment, OpenTSDB calls HBase's atomic increment command on the proper column to fetch a new UID.</p> </div>   <h2>Meta Table Schema</h2> <p>This table is an index of the different time series stored in OpenTSDB and can contain meta-data for each series as well as the number of data points stored for each series. Note that data will only be written to this table if OpenTSDB has been configured to track meta-data or the user creates a TSMeta object via the API. Only one column family is used, the <code class=\"docutils literal\"><span class=\"pre\">name</span></code> family and currently there are two types of columns, the meta column and the counter column.</p> <div class=\"section\" id=\"row-key\"> <h3>Row Key</h3> <p>This is the same as a data point table row key without the timestamp. E.g. <code class=\"docutils literal\"><span class=\"pre\">&lt;metric_uid&gt;&lt;tagk1&gt;&lt;tagv1&gt;[...&lt;tagkN&gt;&lt;tagvN&gt;]</span></code>. It is shared for all column types.</p> </div> <div class=\"section\" id=\"tsmeta-column\"> <h3>TSMeta Column</h3> <p>These columns store UTF-8 encoded, JSON formatted objects similar to UIDMeta objects. The qualifier is always <code class=\"docutils literal\"><span class=\"pre\">ts_meta</span></code>. Do not modify these column values outside of OpenTSDB or it may break CAS calls.</p> </div> <div class=\"section\" id=\"counter-column\"> <h3>Counter Column</h3> <p>These columns are atomic incrementers that count the number of data points stored for a time series. The qualifier is <code class=\"docutils literal\"><span class=\"pre\">ts_counter</span></code> and the value is an 8 byte signed integer.</p> </div>   <h2>Tree Table Schema</h2> <p>This table behaves as an index, organizing time series into a heirarchichal structure similar to a file system for use with tools such as Graphite or other dashboards. A tree is defined by a set of rules that process a TSMeta object to determine where in the heirarchy, if at all, a time series should appear.</p> <p>Each tree is assigned a Unique ID consisting of an unsigned integer starting with <code class=\"docutils literal\"><span class=\"pre\">1</span></code> for the first tree. All rows related to a tree are prefixed with this ID encoded as a two byte array. E.g. <code class=\"docutils literal\"><span class=\"pre\">\\x00\\x01</span></code> for UID <code class=\"docutils literal\"><span class=\"pre\">1</span></code>.</p> <div class=\"section\" id=\"id1\"> <h3>Row Key</h3> <p>Tree definition rows are keyed with the ID of the tree on two bytes. Columns pertaining to the tree definition, as well as the root branch, appear in this row. Definitions are generated by the user.</p> <p>Two special rows may be included. They are keyed on <code class=\"docutils literal\"><span class=\"pre\">&lt;tree</span> <span class=\"pre\">ID&gt;\\x01</span></code> for the <code class=\"docutils literal\"><span class=\"pre\">collisions</span></code> row and <code class=\"docutils literal\"><span class=\"pre\">&lt;tree</span> <span class=\"pre\">ID&gt;\\x02</span></code> for the <code class=\"docutils literal\"><span class=\"pre\">not</span> <span class=\"pre\">matched</span></code> row. These are generated during tree processing and will be described later.</p> <p>The remaining rows are branch and leaf rows containing information about the hierarchy. The rows are keyed on <code class=\"docutils literal\"><span class=\"pre\">&lt;tree</span> <span class=\"pre\">ID&gt;&lt;branch</span> <span class=\"pre\">ID&gt;</span></code> where the <code class=\"docutils literal\"><span class=\"pre\">branch</span> <span class=\"pre\">ID</span></code> is a concatenataion of hashes of the branch display names. For example, if we have a flattened branch <code class=\"docutils literal\"><span class=\"pre\">dal.web01.myapp.bytes_sent</span></code> where each branch name is separated by a period, we would have 3 levels of branching. <code class=\"docutils literal\"><span class=\"pre\">dal</span></code>, <code class=\"docutils literal\"><span class=\"pre\">web01</span></code> and <code class=\"docutils literal\"><span class=\"pre\">myapp</span></code>. The leaf would be named <code class=\"docutils literal\"><span class=\"pre\">bytes_sent</span></code> and links to a TSUID. Hashing each branch name in Java returns a 4 byte integer and converting to hex for readability yields:</p> <ul class=\"simple\"> <li>\n<code class=\"docutils literal\"><span class=\"pre\">dal</span></code> = x00x01x83x8F</li> <li>\n<code class=\"docutils literal\"><span class=\"pre\">web01</span></code> = x06xBCx4Cx55</li> <li>\n<code class=\"docutils literal\"><span class=\"pre\">myapp</span></code> = x06x38x7CxF5</li> </ul> <p>If this branch belongs to tree <code class=\"docutils literal\"><span class=\"pre\">1</span></code>, the row key for <code class=\"docutils literal\"><span class=\"pre\">dal</span></code> would be <code class=\"docutils literal\"><span class=\"pre\">\\x00\\x01\\x00\\x01\\x83\\x8F</span></code>. The branch for <code class=\"docutils literal\"><span class=\"pre\">myapp</span></code> would be <code class=\"docutils literal\"><span class=\"pre\">\\x00\\x01\\x00\\x01\\x83\\x8F\\x06\\xBC\\x4C\\x55\\x06\\x38\\x7C\\xF5</span></code>. This schema allows for navigation by providing a row key filter using a prefix including the tree ID and current branch level and a wild-card to match any number of child branch levels (usually only one level down).</p> </div> <div class=\"section\" id=\"tree-column\"> <h3>Tree Column</h3> <p>A Tree is defined as a UTF-8 encoded JSON object in the <code class=\"docutils literal\"><span class=\"pre\">tree</span></code> column of a tree row (identified by the tree's ID). The object contains descriptions and configuration settings for processing time series through the tree. Do not modify this object outside of OpenTSDB as it may break CAS calls.</p> </div> <div class=\"section\" id=\"rule-column\"> <h3>Rule Column</h3> <p>In the tree row there are 0 or more rule columns that define a specific processing task on a time series. These columns are also UTF-8 encoded JSON objects and are modified with CAS calls. The qualifier id of the format <code class=\"docutils literal\"><span class=\"pre\">rule:&lt;level&gt;:&lt;order&gt;</span></code> where <code class=\"docutils literal\"><span class=\"pre\">&lt;level&gt;</span></code> is the main processing order of a rule in the set (starting at 0) and <code class=\"docutils literal\"><span class=\"pre\">order</span></code> is the processing order of a rule (starting at 0) within a given level. For example <code class=\"docutils literal\"><span class=\"pre\">rule:1:0</span></code> defines a rule at level 1 and order 0.</p> </div> <div class=\"section\" id=\"tree-collision-column\"> <h3>Tree Collision Column</h3> <p>If collision storage is enabled for a tree, a column is recorded for each time series that would have created a leaf that was already created for a previous time series. These columns are used to debug rule sets and only appear rin the collision row for a tree. The qualifier is of the format <code class=\"docutils literal\"><span class=\"pre\">tree_collision:&lt;tsuid&gt;</span></code> where the TSUID is a byte array representing the time series identifier. This allows for a simple <code class=\"docutils literal\"><span class=\"pre\">getRequest</span></code> call to determine if a particular time series did not appear in a tree due to a collision. The value of a colission column is the byte array of the TSUID that was recorded as a leaf.</p> </div> <div class=\"section\" id=\"not-matched-column\"> <h3>Not Matched Column</h3> <p>Similar to collisions, when enabled for a tree, a column can be recorded for each time series that failed to match any rules in the rule set and therefore, did not appear in the tree. These columns only appear in the not matched row for a tree. The qualifier is of the format <code class=\"docutils literal\"><span class=\"pre\">tree_not_matched:&lt;TSUID&gt;</span></code> where the TSUID is a byte array representing the time series identifier. The value of a not matched column is the byte array of the TSUID that failed to match a rule.</p> </div> <div class=\"section\" id=\"branch-column\"> <h3>Branch Column</h3> <p>Branch columns have the qualifier <code class=\"docutils literal\"><span class=\"pre\">branch</span></code> and contain a UTF-8 JSON encoded object describing the current branch and any child branches that may exist. A branch column may appear in any row except the collision or not matched columns. Branches in the tree definition row are the <code class=\"docutils literal\"><span class=\"pre\">root</span></code> branch and link to the first level of child branches. These links are used to traverse the heirarchy.</p> </div> <div class=\"section\" id=\"leaf-column\"> <h3>Leaf Column</h3> <p>Leaves are mappings to specific time series and represent the end of a hierarchy. Leaf columns have a qualifier format of <code class=\"docutils literal\"><span class=\"pre\">leaf:&lt;TSUID&gt;</span></code> where the TUID is a byte array representing the time series identifier. The value of a leaf is a UTF-8 encoded JSON object describing the leaf. Leaves may appear in any row other than the collision or not matched rows.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/backends/hbase.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/backends/hbase.html</a>\n  </p>\n</div>\n","user_guide/cli/uid":"<h1>uid</h1> <p>The UID utility provides various functions to search or modify information in the <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table. This includes UID assignments for metrics, tag names and tag values as well as UID meta data, timeseries meta data and tree definitions or data.</p> <p>Use the UID utility with the command line:</p> <pre data-language=\"python\">uid &lt;subcommands&gt; [arguments]\n</pre>\n  <h2>Common CLI Parameters</h2> <p>Parameters specific to the UID utility include:</p>   <h2>Lookup</h2> <p>The lookup command is the default for <code class=\"docutils literal\"><span class=\"pre\">uid</span></code> used to lookup the UID assigned to a name or the name assinged to a UID for a given type.</p> <div class=\"section\" id=\"command-format\"> <h3>Command Format</h3> <pre data-language=\"python\">&lt;kind&gt; &lt;name&gt;\n&lt;kind&gt; &lt;UID&gt;\n</pre>\n </div> <div class=\"section\" id=\"example-command\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid tagk host\n</pre>\n </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"python\">tagk host: [0, 0, 1]\n</pre>\n </div>   <h2>grep</h2> <p>The grep sub command performs a regular expression search for the given UID type and returns a list of all UID names that match the expression. Fields required for the grep command include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"50%\"> <col width=\"10%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>kind</td> <td>String</td> <td>The type of the UID to search for. Must be one of <code class=\"docutils literal\"><span class=\"pre\">metrics</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>\n</td> <td> </td> <td>tagk</td> </tr> <tr class=\"row-odd\">\n<td>expression</td> <td>String</td> <td>The regex expression to search with</td> <td> </td> <td>disk.*write</td> </tr> </tbody> </table> <div class=\"section\" id=\"id1\"> <h3>Command Format</h3> <pre data-language=\"python\">grep &lt;kind&gt; '&lt;expression&gt;'\n</pre>\n </div> <div class=\"section\" id=\"id2\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid grep metrics 'disk.*write'\n</pre>\n </div> <div class=\"section\" id=\"id3\"> <h3>Example Response</h3> <pre data-language=\"python\">metrics iostat.disk.msec_write: [0, 3, -67]\nmetrics iostat.disk.write_merged: [0, 3, -69]\nmetrics iostat.disk.write_requests: [0, 3, -70]\nmetrics iostat.disk.write_sectors: [0, 3, -68]\n</pre>\n </div>   <h2>assign</h2> <p>This sub command is used to assign IDs to new unique names for metrics, tag names or tag values. Supply a list of one or more values to assign UIDs and the list of assignments will be returned.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>kind</td> <td>String</td> <td>The type of the UID the names represent. Must be one of <code class=\"docutils literal\"><span class=\"pre\">metrics</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>\n</td> <td>tagk</td> </tr> <tr class=\"row-odd\">\n<td>name</td> <td>String</td> <td>One or more names to assign UIDs to. Names must not be in quotes and cannot contain spaces.</td> <td>owner</td> </tr> </tbody> </table> <div class=\"section\" id=\"id4\"> <h3>Command Format</h3> <pre data-language=\"python\">assign &lt;kind&gt; &lt;name&gt; [&lt;name&gt;...]\n</pre>\n </div> <div class=\"section\" id=\"id5\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid assign metrics disk.d0 disk.d1 disk.d2 disk.d3\n</pre>\n </div> <div class=\"section\" id=\"id6\"> <h3>Example Response</h3> </div>   <h2>rename</h2> <p>Changes the name of an already assigned UID. If the UID of the given type does not exist, an error will be returned.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">After changing a UID name you must flush the cache (see <a class=\"reference internal\" href=\"../../api_http/dropcaches\"><em>/api/dropcaches</em></a>) or restart all TSDs for the change to take effect. TSDs do not periodically reload UID maps.</p> </div> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>kind</td> <td>String</td> <td>The type of the UID the name represent. Must be one of <code class=\"docutils literal\"><span class=\"pre\">metrics</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>\n</td> <td>tagk</td> </tr> <tr class=\"row-odd\">\n<td>name</td> <td>String</td> <td>The existing UID name</td> <td>owner</td> </tr> <tr class=\"row-even\">\n<td>newname</td> <td>String</td> <td>The new name UID name</td> <td>server_owner</td> </tr> </tbody> </table> <div class=\"section\" id=\"id7\"> <h3>Command Format</h3> <pre data-language=\"python\">rename &lt;kind&gt; &lt;name&gt; &lt;newname&gt;\n</pre>\n </div> <div class=\"section\" id=\"id8\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid rename metrics disk.d0 disk.d0.bytes_read\n</pre>\n </div>   <h2>delete</h2> <p>Removes the mapping of the UID from the <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table. Make sure all sources are no longer writing data using the UID and that sufficient time has passed so that users would not query for data that used the UIDs.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">After deleting a UID, it may still remain in the caches of running TSD servers. Make sure to flush their caches after deleting an entry.</p> </div> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Deleting a UID will not delete the underlying data associated with the UIDs (we're working on that). For metrics this is safe, it won't affect queries. But for tag names and values, if a query scans over data containing the old UID, the query will fail with an exception because it can no longer find the name mapping.</p> </div> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>kind</td> <td>String</td> <td>The type of the UID the name represent. Must be one of <code class=\"docutils literal\"><span class=\"pre\">metrics</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>\n</td> <td>tagk</td> </tr> <tr class=\"row-odd\">\n<td>name</td> <td>String</td> <td>The existing UID name</td> <td>owner</td> </tr> </tbody> </table> <div class=\"section\" id=\"id9\"> <h3>Command Format</h3> <pre data-language=\"python\">delete &lt;kind&gt; &lt;name&gt;\n</pre>\n </div> <div class=\"section\" id=\"id10\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid delete disk.d0\n</pre>\n </div>   <h2>fsck</h2> <p>The UID FSCK command will scan the entire UID table for errors pertaining to name and UID mappings. By default, the run will scan every column in the table and log any errors that were found. With version 2.1 it is possible to fix errors in the table by passing the \"fix\" flag. UIDMeta objects are skipped during scanning. Possible errors include:</p> <table class=\"docutils\"> <colgroup> <col width=\"33%\"> <col width=\"34%\"> <col width=\"33%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Error</th> <th class=\"head\">Description</th> <th class=\"head\">Fix</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>Max ID for metrics is 42 but only 41 entries were found. Maybe 1 IDs were deleted?</td> <td>This indicates one or more UIDs were not used for mapping entries. If a UID was deleted, this message is normal. If UIDs were not deleted, this can indicate wasted UIDs due to auto-assignments by TSDs where data was coming in too fast. Try assigning UIDs up-front as much as possible.</td> <td>No fix necessary</td> </tr> <tr class=\"row-odd\">\n<td>We found an ID of 42 for metrics but the max ID is only 41! Future IDs may be double-assigned!</td> <td>If this happens it is usually due to a corruption and indicates the max ID row was not updated properly.</td> <td>Set the max ID row to the largest detected value</td> </tr> <tr class=\"row-even\">\n<td>Invalid maximum ID for metrics: should be on 8 bytes</td> <td>Indicates a corruption in the max ID row.</td> <td>No fix yet.</td> </tr> <tr class=\"row-odd\">\n<td>Forward metrics mapping is missing reverse mapping: foo -&gt; 000001</td> <td>This may occur if a TSD crashes before the reverse map is written and would only prevent queries from executing against time series using the UID as they would not be able to lookukp the name.</td> <td>The fix is to restore the missing reverse map.</td> </tr> <tr class=\"row-even\">\n<td>Forward metrics mapping bar -&gt; 000001 is different than reverse mapping: 000001 -&gt; foo</td> <td>The reverse map points to a different name than the forward map and this should rarely happen. It will be paired with another message.</td> <td>Depends on the second message</td> </tr> <tr class=\"row-odd\">\n<td>Inconsistent forward metrics mapping bar -&gt; 000001 vs bar -&gt; foo / foo -&gt; 000001</td> <td>With a forward/reverse miss-match, it is possible that a UID was assigned to multiple names for the same type. If this occurs, then data for two different names has been written to the same time series and that data is effectively corrupt.</td> <td>The fix is to delete the forward maps for all names that map to the same UID. Then the UID is given a new name that is a dot seperated concatenation of the previous names with an \"fsck\" prefix. E.g. in the example above we would have a new name of \"fsck.bar.foo\". This name may be used to access data from the corrupt time series. The next time data is written for the errant names, new UIDs will be assigned to each and new time series created.</td> </tr> <tr class=\"row-even\">\n<td>Duplicate forward metrics mapping bar -&gt; 000002 and null -&gt; foo</td> <td>In this case the UID was not used more than once but the reverse mapping was incorrect.</td> <td>The reverse map will be restored, in this case: 000002 -&gt; bar</td> </tr> <tr class=\"row-odd\">\n<td>Reverse metrics mapping is missing forward mapping: bar -&gt; 000002</td> <td>A reverse map was found without a forward map. The UID may have been deleted.</td> <td>Remove the reverse map</td> </tr> <tr class=\"row-even\">\n<td>Inconsistent reverse metrics mapping 000003 -&gt; foo vs 000001 -&gt; foo / foo -&gt; 000001</td> <td>If an orphaned reverse map points to a resolved forward map, this error occurs.</td> <td>Remove the reverse map</td> </tr> </tbody> </table> <p><strong>Options</strong></p> <ul class=\"simple\"> <li>fix - Attempts to fix errors per the table above</li> <li>delete_unknown - Removes any columns in the UID table that do not belong to OpenTSDB</li> </ul> <div class=\"section\" id=\"id11\"> <h3>Command Format</h3> <pre data-language=\"python\">fsck [fix] [delete_unknown]\n</pre>\n </div> <div class=\"section\" id=\"id12\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid fsck fix\n</pre>\n </div> <div class=\"section\" id=\"id13\"> <h3>Example Response</h3> <pre data-language=\"python\">INFO  [main] UidManager: ----------------------------------\nINFO  [main] UidManager: -  Running fsck in FIX mode  -\nINFO  [main] UidManager: -    Remove Unknowns: false  -\nINFO  [main] UidManager: ----------------------------------\nINFO  [main] UidManager: Maximum ID for metrics: 2\nINFO  [main] UidManager: Maximum ID for tagk: 4\nINFO  [main] UidManager: Maximum ID for tagv: 2\nERROR [main] UidManager: Forward tagk mapping is missing reverse mapping: bar -&gt; 000004\nINFO  [main] UidManager: FIX: Restoring tagk reverse mapping: 000004 -&gt; bar\nERROR [main] UidManager: Inconsistent reverse tagk mapping 000003 -&gt; bar vs 000004 -&gt; bar / bar -&gt; 000004\nINFO  [main] UidManager: FIX: Removed tagk reverse mapping: 000003 -&gt; bar\nERROR [main] UidManager: tagk: Found 2 errors.\nINFO  [main] UidManager: 17 KVs analyzed in 334ms (~50 KV/s)\nWARN  [main] UidManager: 2 errors found.\n</pre>\n </div>   <h2>metasync</h2> <p>This command will run through the entire data table, scanning each row of timeseries data and generate missing TSMeta objects and UIDMeta objects or update the created timestamps for each object type if necessary. Use this command after enabling meta tracking with existing data or if you suspect that some timeseries may not have been indexed properly. The command will also push new or updated meta entries to a search engine if a plugin has been configured. If existing meta is corrupted, meaning the TSD is unable to deserialize the object, it will be replaced with a new entry.</p> <p>It is safe to run this command at any time as it will not destroy or overwrite valid data. (Unless you modify columns directly in HBase in a manner inconsistent with the meta data formats). The utility will split the data table into chunks processed by multiple threads so the more cores in your processor, the faster the command will complete.</p> <div class=\"section\" id=\"id14\"> <h3>Command Format</h3> <pre data-language=\"python\">metasync\n</pre>\n </div> <div class=\"section\" id=\"id15\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid metasync\n</pre>\n </div>   <h2>metapurge</h2> <p>This sub command will mark all TSMeta and UIDMeta objects for deletion in the UID table. This is useful for downgrading from 2.0 to a 1.x version or simply flushing all meta data and starting over with a <code class=\"docutils literal\"><span class=\"pre\">metasync</span></code>.</p> <div class=\"section\" id=\"id16\"> <h3>Command Format</h3> <pre data-language=\"python\">metapurge\n</pre>\n </div> <div class=\"section\" id=\"id17\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid metapurge\n</pre>\n </div>   <h2>treesync</h2> <p>Runs through the list of TSMeta objects in the UID table and processes each through all configured and enabled trees to compile branches. This command may be run at any time and will not affect existing objects.</p> <div class=\"section\" id=\"id18\"> <h3>Command Format</h3> <pre data-language=\"python\">treesync\n</pre>\n </div> <div class=\"section\" id=\"id19\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid treesync\n</pre>\n </div>   <h2>treepurge</h2> <p>Removes all branches, collision, not matched data and optionally the tree definition itself for a given tree. Parameters include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>id</td> <td>Integer</td> <td>ID of the tree to purge</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>definition</td> <td>Flag</td> <td>Add this literal after the ID to delete the definition of the tree as well as the data</td> <td>definition</td> </tr> </tbody> </table> <div class=\"section\" id=\"id20\"> <h3>Command Format</h3> <pre data-language=\"python\">treepurge &lt;id&gt; [definition]\n</pre>\n </div> <div class=\"section\" id=\"id21\"> <h3>Example Command</h3> <pre data-language=\"python\">./tsdb uid treepurge 1\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/uid.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/uid.html</a>\n  </p>\n</div>\n","user_guide/cli/search":"<h1>search</h1> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Available in 2.1</p> </div> <p>The search command allows for searching OpenTSDB to reteive a list of time series or associated meta data. Search does not return actual data points or time series objects stored in the data table. Use the query tools to access that data. Currently only the <code class=\"docutils literal\"><span class=\"pre\">lookup</span></code> command is implemented.</p>  <h2>Lookup</h2> <p>Lookup queries use either the meta data table or the main data table to determine what time series are associated with a given metric, tag name, tag value, tag pair or combination thereof. For example, if you want to know what metrics are available for a tag pair <code class=\"docutils literal\"><span class=\"pre\">host=web01</span></code> you can execute a lookup to find out.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">By default lookups are performed against the <code class=\"docutils literal\"><span class=\"pre\">tsdb-meta</span></code> table. You must enable real-time meta data creation or perform a <code class=\"docutils literal\"><span class=\"pre\">metasync</span></code> using the <code class=\"docutils literal\"><span class=\"pre\">uid</span></code> command in order to retreive data from a lookup. Alternatively you can lookup against the raw data table but this can take a very long time depending on how much data is in your system.</p> </div> <div class=\"section\" id=\"command-format\"> <h3>Command Format</h3> <pre data-language=\"bash\">search lookup &lt;query&gt;\n</pre>\n </div> <div class=\"section\" id=\"parameters\"> <h3>Parameters</h3> <table class=\"docutils\"> <colgroup> <col width=\"15%\"> <col width=\"5%\"> <col width=\"40%\"> <col width=\"5%\"> <col width=\"35%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>query</td> <td>String</td> <td>One or more command line queries similar to a data CLI query. See the query section below.</td> <td> </td> <td>tsd.hbase.rpcs type=</td> </tr> <tr class=\"row-odd\">\n<td>--use_data_table</td> <td>Flag</td> <td>Optional flag that will cause the lookup to run against the main <code class=\"docutils literal\"><span class=\"pre\">tsdb-data</span></code> table. <em>NOTE:</em> This can take a very long time to complete.</td> <td>Not set</td> <td>--use_data_table</td> </tr> </tbody> </table> </div> <div class=\"section\" id=\"query-format\"> <h3>Query Format</h3> <p>For details on crafting a query, see <a class=\"reference internal\" href=\"../../api_http/search/lookup\"><em>/api/search/lookup</em></a>. The CLI query is similar to an API query but spaces are used as separators instead of commas and curly braces are not used.</p> <pre data-language=\"bash\">[&lt;metric&gt;] [[tagk]=[tagv]] ...[[tagk]=[tagv]]\n</pre>\n <p>At least one metric, tagk or tagv is required.</p> </div> <div class=\"section\" id=\"example-command\"> <h3>Example Command</h3> <pre data-language=\"bash\">search lookup tsd.hbase.rpcs type=\n</pre>\n </div> <div class=\"section\" id=\"output\"> <h3>Output</h3> <p>During a lookup, the results will be printed to standard out. Note that if you have logging enabled, messages may be interspersed with the results. Set the logging level to WARN or ERROR in the <code class=\"docutils literal\"><span class=\"pre\">logback.xml</span></code> configuration to supress these warnings. You may want to run the lookup in the background and capture standard out to a file, particularly when running lookups against the data table as these may take a long time to complete.</p> <pre data-language=\"bash\">&lt;tsuid&gt; &lt;metric name&gt; &lt;tag/value pairs&gt;\n</pre>\n <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>tsuid</strong> Is the hex encoded UID of the time series</li> <li>\n<strong>metric name</strong> Is the decoded name of the metric the row represents</li> <li>\n<strong>tag/value pairs</strong> Are the tags associated with the time series</li> </ul> </div>\n</blockquote> </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"bash\">0023E3000002017358000006017438 tsd.hbase.rpcs type=openScanner host=tsdb-1.mysite.com\n</pre>\n <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">During scanning, if the UID for a metric, tag name or tag value cannot be resolved to a name, an exception will be thrown.</p> </div> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/search.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/search.html</a>\n  </p>\n</div>\n","user_guide/cli/tsd":"<h1>tsd</h1> <p>The TSD command launches the OpenTSDB daemon in the foreground so that it can accept connections over TCP and HTTP. If successful, you should see a number of messages then:</p> <pre data-language=\"python\">2014-02-26 18:33:02,472 INFO  [main] TSDMain: Ready to serve on 0.0.0.0:4242\n</pre>\n <p>The daemon will continue to run until killed via a Telnet or HTTP command is sent to tell it to stop. If an error occurred, such as failure to connect to Zookeeper or the inability to bind to the proper interface and port, an error will be logged and the daemon will exit.</p> <p>Note that the daemon does not fork and run in the background.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/tsd.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/tsd.html</a>\n  </p>\n</div>\n","user_guide/utilities/clean_cache":"<h1>clean_cache.sh</h1> <p>OpenTSDB uses a directory for caching graphs and gnuplot scripts. Unfortunately it doesn't clean up after itself at this time so a simple shell script is included to purge all files in the directory if drive where the directory resides drops below 10% of free space. Simply add this script as a cron entry and set it to run as often as you like.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">This script will purge all files in the directory. Don't store anything important in the temp directory.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/utilities/clean_cache.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/utilities/clean_cache.html</a>\n  </p>\n</div>\n","user_guide/utilities/tsddrain":"<h1>tsddrain.py</h1> <p>This is a simple utility for consuming data points from collectors while a TSD, HBase or HDFS is underoing maintenance. The script should be run on the same port as a TSD and accepts data in the <code class=\"docutils literal\"><span class=\"pre\">put</span></code> Telnet style. Data points are then written directly to disk in a format that can be used with the <a class=\"reference internal\" href=\"../cli/import\"><em>import</em></a> command once HBase is back up.</p>  <h2>Parameters</h2> <pre data-language=\"bash\">tsddrain.py &lt;port&gt; &lt;directory&gt;\n</pre>\n <table class=\"docutils\"> <colgroup> <col width=\"15%\"> <col width=\"5%\"> <col width=\"40%\"> <col width=\"5%\"> <col width=\"35%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>port</td> <td>Integer</td> <td>The TCP port to listen on</td> <td> </td> <td>4242</td> </tr> <tr class=\"row-odd\">\n<td>directory</td> <td>String</td> <td>Path to a directory where data files should be written. A file is created for each client with the IP address of the client as the file name,</td> <td> </td> <td>/opt/temptsd/</td> </tr> </tbody> </table> <p>Example</p> <pre data-language=\"bash\">./tsddrain.py 4242 /opt/temptsd/\n</pre>\n   <h2>Results</h2> <p>On succesfully binding to the default IPv4 address <code class=\"docutils literal\"><span class=\"pre\">0.0.0.0</span></code> and port it will simply print out the line below and start writing. When you're ready to resume using a TSD, simply kill the process.</p> <pre data-language=\"bash\">Use Ctrl-C to stop me.\n</pre>\n <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Tsddrain does not accept HTTP input at this time.</p> </div> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Test throughput on your systems to make sure it handles the load properly. Since it writes each point to disk immediately this can result in a huge disk IO load so very large OpenTSDB installations may require a larger number of drains than TSDs.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/utilities/tsddrain.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/utilities/tsddrain.html</a>\n  </p>\n</div>\n","user_guide/cli/scan":"<h1>scan</h1> <p>The scan command is useful for debugging and exporting data points. Provide a start time, optional end time and one or more queries and the response will be raw byte data from storage or data points in a text format acceptable for use with the <strong>import</strong> command. Scan also provides a rudimentary means of deleting data. The scan command accepts common CLI arguments. Data is emitted to standard out.</p> <p>Note that while queries require an aggregator, it is effectively ignored. If a query encompasses many time series, the scan output may be extremely large so be careful when crafting queries.</p>  <h2>Parameters</h2> <pre data-language=\"bash\">scan [--delete|--import] START-DATE [END-DATE] query [queries...]\n</pre>\n <table class=\"docutils\"> <colgroup> <col width=\"15%\"> <col width=\"5%\"> <col width=\"40%\"> <col width=\"5%\"> <col width=\"35%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>--delete</td> <td>Flag</td> <td>Optional flag that deletes data in any row that matches the query. See warning below.</td> <td>Not set</td> <td>--delete</td> </tr> <tr class=\"row-odd\">\n<td>--import</td> <td>flag</td> <td>Optional flag that outputs results in a text format useful for importing or storing as a backup.</td> <td>Not set</td> <td>--import</td> </tr> <tr class=\"row-even\">\n<td>START-DATE</td> <td>String or Integer</td> <td>Starting time for the query. This may be an absolute or relative time. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details</td> <td> </td> <td>1h-ago</td> </tr> <tr class=\"row-odd\">\n<td>END-DATE</td> <td>String or Integer</td> <td>Optional end time for the query. If not provided, the current time is used. This may be an absolute or relative time. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details</td> <td>Current timestamp</td> <td>2014/01/01-00:00:00</td> </tr> <tr class=\"row-even\">\n<td>query</td> <td>String</td> <td>One or more command line queries</td> <td> </td> <td>sum tsd.hbase.rpcs type=put</td> </tr> </tbody> </table> <p>Example:</p> <pre data-language=\"bash\">scan --import 1h-ago now sum tsd.hbase.rpcs type=put sum tsd.hbase.rpcs type=scan\n</pre>\n <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p>If you include the <code class=\"docutils literal\"><span class=\"pre\">--delete</span></code> flag, <strong>ALL</strong> data in 'any' row that matches on the query will be deleted permanently. Rows are separated on 1 hour boundaries so that if you issued a scan command with a start and end time that covered 10 minutes within a single hour, the entire hour of data will be deleted.</p> <p class=\"last\">Deletions will also delete any Annotations or non-TSDB related data in a row.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The scan command returns data on row boundaries (1 hour) so results may include data previous to and after the specified start and end times.</p> </div>   <h2>Raw Output</h2> <p>The default output for <code class=\"docutils literal\"><span class=\"pre\">scan</span></code> is a raw dump of the rows and columns that match the given queries. This is useful in debugging situations such as data point collisions or encoding issues. As the output includes raw byte arrays and the format changes slightly depending on the data, it is not easily machine paresable.</p> <p>Row keys, column qualifiers and column values are emitted as Java byte arrays. These are surrounded by square brackets and individual bytes are represented as signed integers (as Java does not have native unsigned ints). Row keys are printed first followed by a new line. Then each column is printed on it's own row and is indented with two spaces to indicate it belongs to the previous row. If a compacted column is found, the raw data and number of compacted values is printed followed by a new line. Each compacted data point is printed on it's own indented line. Annotations are also emitted in raw mode.</p> <p>The various formats are listed below. The <code class=\"docutils literal\"><span class=\"pre\">\\t</span></code> expression represents a tab. <code class=\"docutils literal\"><span class=\"pre\">space</span></code> indicates a space character.</p> <div class=\"section\" id=\"row-key-format\"> <h3>Row Key Format</h3> <pre data-language=\"bash\">[&lt;row key&gt;] &lt;metric name&gt; &lt;row timestamp&gt; (&lt;datetime&gt;) &lt;tag/value pairs&gt;\n</pre>\n <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>row key</strong> Is the raw byte array of the row key</li> <li>\n<strong>metric name</strong> Is the decoded name of the metric the row represents</li> <li>\n<strong>row timestamp</strong> Is the base timestamp of the row in seconds (on 1 hour boundaries)</li> <li>\n<strong>datetime</strong> Is the system default formatted human readable timestamp</li> <li>\n<strong>tag/value pairs</strong> Are the tags associated with the time series</li> </ul> </div>\n</blockquote> <p>Example:</p> <pre data-language=\"bash\">[0, 0, 1, 80, -30, 39, 0, 0, 0, 1, 0, 0, 1] sys.cpu.user 1356998400 (Mon Dec 31 19:00:00 EST 2012) {host=web01}\n</pre>\n </div> <div class=\"section\" id=\"single-data-point-column-format\"> <h3>Single Data Point Column Format</h3> <pre data-language=\"bash\">&lt;two spaces&gt;[&lt;qualifier&gt;]\\t[&lt;value&gt;]\\t&lt;offset&gt;\\t&lt;l|f&gt;\\t&lt;timestamp&gt;\\t(&lt;datetime&gt;)\n</pre>\n <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>qualifier</strong> Is the raw byte array of the column qualifier</li> <li>\n<strong>value</strong> Is the raw byte array of the column value</li> <li>\n<strong>offset</strong> Is the number of seconds or milliseconds (based on timestamp) of offset from the row base timestamp</li> <li>\n<strong>l|f</strong> Is either <code class=\"docutils literal\"><span class=\"pre\">l</span></code> to indicate the value is an Integer (Java Long) or <code class=\"docutils literal\"><span class=\"pre\">f</span></code> for a floating point value.</li> <li>\n<strong>timestamp</strong> Is the absolute timestamp of the data point in seconds or milliseconds</li> <li>\n<strong>datetime</strong> Is the system default formatted human readable timestamp</li> </ul> </div>\n</blockquote> <p>Example:</p> <pre data-language=\"bash\">[0, 17]     [0, 17] [1, 1]  1     l     1356998401    (Mon Dec 31 19:00:01 EST 2012)\n</pre>\n </div> <div class=\"section\" id=\"compacted-column-format\"> <h3>Compacted Column Format</h3> <pre data-language=\"bash\">&lt;two spaces&gt;[&lt;qualifier&gt;]\\t[&lt;value&gt;] = &lt;number of datapoints&gt; values:\n</pre>\n <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>qualifier</strong> Is the raw byte array of the column qualifier</li> <li>\n<strong>value</strong> Is the raw byte array of the column value</li> <li>\n<strong>number of datapoints</strong> Is the number of data points in the compacted column</li> </ul> </div>\n</blockquote> <p>Example:</p> <pre data-language=\"bash\">[-16, 0, 0, 7, -16, 0, 2, 7, -16, 0, 1, 7]  [0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 6, 0] = 3 values:\n</pre>\n <p>Each data point within the compacted column follows the same format as a single column with the addition of two spaces of indentation.</p> </div> <div class=\"section\" id=\"annotation-column-format\"> <h3>Annotation Column Format</h3> <pre data-language=\"bash\">&lt;two spaces&gt;[&lt;qualifier&gt;]\\t[&lt;value&gt;]\\t&lt;offset&gt;\\t&lt;JSON\\&gt;\\t&lt;timestamp\\&gt;\\t(&lt;datetime&gt;)\n</pre>\n <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>qualifier</strong> Is the raw byte array of the column qualifier</li> <li>\n<strong>value</strong> Is the raw byte array of the column value</li> <li>\n<strong>offset</strong> Is the number of seconds or milliseconds (based on timestamp) of offset from the row base timestamp</li> <li>\n<strong>JSON</strong> Is the decoded JSON data stored in the column</li> <li>\n<strong>timestamp</strong> Is the absolute timestamp of the data point in seconds or milliseconds</li> <li>\n<strong>datetime</strong> Is the system default formatted human readable timestamp</li> </ul> </div>\n</blockquote> <p>Example:</p> <pre data-language=\"bash\">[1, 0, 0]   [123, 34...]  0     {\"tsuid\":\"000001000001000001\",\"startTime\":1356998400,\"endTime\":0,\"description\":\"Annotation on seconds\",\"notes\":\"\",\"custom\":null}    1356998416000   (Mon Dec 31 19:00:16 EST 2012)\n</pre>\n </div>   <h2>Import Format</h2> <p>The import format is the same as a Telnet style <code class=\"docutils literal\"><span class=\"pre\">put</span></code> command.</p> <pre data-language=\"bash\">&lt;metric&gt; &lt;timestamp&gt; &lt;value&gt; &lt;tagk=tagv&gt;[...&lt;tagk=tagv&gt;]\n</pre>\n <p>Where:</p> <blockquote> <div>\n<ul class=\"simple\"> <li>\n<strong>metric</strong> Is the name of the metric as a string</li> <li>\n<strong>timestamp</strong> Is the absolute timestamp of the data point in seconds or milliseconds</li> <li>\n<strong>value</strong> Is the value of the data point</li> <li>\n<strong>tagk=tagv</strong> Are tag name/value pairs separated by spaces</li> </ul> </div>\n</blockquote> <p>Example:</p> <pre data-language=\"bash\">sys.cpu.user 1356998400 42 host=web01 cpu=0\nsys.cpu.user 1356998401 24 host=web01 cpu=0\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/scan.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/scan.html</a>\n  </p>\n</div>\n","user_guide/utilities/varnish":"<h1>Load Balancing with Varnish</h1> <p><a class=\"reference external\" href=\"https://www.varnish-cache.org/\">Varnish</a> is a powerful HTTP load balancer (reverse proxy), which is also very good at caching. When running multiple TSDs, Varnish comes in handy to distribute the HTTP traffic across the TSDs. Bear in mind that write traffic doesn't use the HTTP protocol by default, and as such you can only use Varnish for read queries. Using Varnish will help you easily scale the amount of read capacity of your TSD cluster.</p> <p>The following is a sample Varnish configuration recommended for use with OpenTSDB. It uses a slightly custom load balancing strategy to achieve optimal cache hit rate at the TSD level. This configuration requires at least Varnish 2.1.0 to run, but using Varnish 3.0 or above is strongly recommended.</p> <p>This sample configuration is for 2 backends, named <code class=\"docutils literal\"><span class=\"pre\">foo</span></code> and <code class=\"docutils literal\"><span class=\"pre\">bar</span></code>. You need to substitute at least the host names.</p> <pre data-language=\"python\"># VCL configuration for OpenTSDB.\n\nbackend foo {\n  .host = \"foo\";\n  .port = \"4242\";\n  .probe = {\n    .url = \"/version\";\n    .interval = 30s;\n    .timeout = 10s;\n    .window = 5;\n    .threshold = 3;\n  }\n}\n\nbackend bar {\n  .host = \"bar\";\n  .port = \"4242\";\n  .probe = {\n    .url = \"/version\";\n    .interval = 30s;\n    .timeout = 10s;\n    .window = 5;\n    .threshold = 3;\n  }\n}\n\n# The `client' director will select a backend based on `client.identity'.\n# It's normally used to implement session stickiness but here we abuse it\n# to try to send pairs of requests to the same TSD, in order to achieve a\n# higher cache hit rate.  The UI sends queries first with a \"&amp;json\" at the\n# end, in order to get meta-data back about the results, and then it sends\n# the same query again with \"&amp;png\".  If the second query goes to a different\n# TSD, then that TSD will have to fetch the data from HBase again.  Whereas\n# if it goes to the same TSD that served the \"&amp;json\" query, it'll hit the\n# cache of that TSD and produce the PNG directly without using HBase.\n#\n# Note that we cannot use the `hash' director here, because otherwise Varnish\n# would hash both the \"&amp;json\" and the \"&amp;png\" requests identically, and it\n# would thus serve a cached JSON response to a \"&amp;png\" request.\ndirector tsd client {\n  { .backend = foo; .weight = 100; }\n  { .backend = bar; .weight = 100; }\n}\n\nsub vcl_recv {\n  set req.backend = tsd;\n  # Make sure we hit the same backend based on the URL requested,\n  # but ignore some parameters before hashing the URL.\n  set client.identity = regsuball(req.url, \"&amp;(o|ignore|png|json|html|y2?range|y2?label|y2?log|key|nokey)\\b(=[^&amp;]*)?\", \"\");\n}\n\nsub vcl_hash {\n  # Remove the `ignore' parameter from the URL we hash, so that two\n  # identical requests modulo that parameter will hit Varnish's cache.\n  hash_data(regsuball(req.url, \"&amp;ignore\\b(=[^&amp;]*)?\", \"\"));\n  if (req.http.host) {\n    hash_data(req.http.host);\n  } else {\n    hash_data(server.ip);\n  }\n  return (hash);\n}\n</pre>\n <p>On many Linux distros (including Debian and Ubuntu), you need to put the configuration above in <code class=\"docutils literal\"><span class=\"pre\">/etc/varnish/default.vcl</span></code>. We also recommend tweaking the command-line parameters of <code class=\"docutils literal\"><span class=\"pre\">varnishd</span></code> in order to use a memory-backed cache of about 1GB if you can afford it. On Debian/Ubuntu systems, this is done by editing <code class=\"docutils literal\"><span class=\"pre\">/etc/default/varnish</span></code> to make sure that <code class=\"docutils literal\"><span class=\"pre\">-s</span> <span class=\"pre\">malloc,1G</span></code> is passed to <code class=\"docutils literal\"><span class=\"pre\">varnishd</span></code>.</p> <p>Read more about Varnish:</p> <ul class=\"simple\"> <li><a class=\"reference external\" href=\"http://www.varnish-cache.org/docs/trunk/reference/vcl.html\">The VCL configuration language</a></li> <li><a class=\"reference external\" href=\"http://www.varnish-cache.org/trac/wiki/BackendPolling\">Health checking backends</a></li> <li><a class=\"reference external\" href=\"http://www.varnish-cache.org/trac/wiki/LoadBalancing\">Tweaking the load balancing strategy</a></li> </ul> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">if you're using Varnish 2.x (which is not recommended as we would strongly encourage you to migrate to 3.x) you have to replace each function call <code class=\"docutils literal\"><span class=\"pre\">hash_data(foo);</span></code> to set <code class=\"docutils literal\"><span class=\"pre\">req.hash</span> <span class=\"pre\">+=</span> <span class=\"pre\">foo;</span></code> in the VCL configuration above.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/utilities/varnish.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/utilities/varnish.html</a>\n  </p>\n</div>\n","user_guide/utilities/nagios":"<h1>Alerting with Nagios</h1> <p>OpenTSDB is great, but it's not (yet) a full monitoring platform. Now that you have a bunch of metrics in OpenTSDB, you want to start sending alerts when thresholds are getting too high. It's easy!</p> <p>In the <code class=\"docutils literal\"><span class=\"pre\">tools</span></code> directory is a Python script <code class=\"docutils literal\"><span class=\"pre\">check_tsd</span></code>. This script queries OpenTSDB and returns Nagios compatible output that gives you OK/WARNING/CRITICAL state.</p>  <h2>Parameters</h2> <pre data-language=\"python\">Options:\n  -h, --help      show this help message and exit\n  -H HOST, --host=HOST  Hostname to use to connect to the TSD.\n  -p PORT, --port=PORT  Port to connect to the TSD instance on.\n  -m METRIC, --metric=METRIC\n            Metric to query.\n  -t TAG, --tag=TAG   Tags to filter the metric on.\n  -d SECONDS, --duration=SECONDS\n            How far back to look for data.\n  -D METHOD, --downsample=METHOD\n            Downsample the data over the duration via avg, min,\n            sum, or max.\n  -a METHOD, --aggregator=METHOD\n            Aggregation method: avg, min, sum (default), max.\n  -x METHOD, --method=METHOD\n            Comparison method for -w/-c: gt, ge, lt, le, eq, ne.\n  -w THRESHOLD, --warning=THRESHOLD\n            Threshold for warning.  Uses the comparison method.\n  -c THRESHOLD, --critical=THRESHOLD\n            Threshold for critical.  Uses the comparison method.\n  -v, --verbose     Be more verbose.\n  -T SECONDS, --timeout=SECONDS\n            How long to wait for the response from TSD.\n  -E, --no-result-ok  Return OK when TSD query returns no result.\n  -I SECONDS, --ignore-recent=SECONDS\n            Ignore data points that are that are that recent.\n</pre>\n   <h2>Nagios Setup</h2> <p>Drop the script into your Nagios path and set up a command like this:</p> <pre data-language=\"python\">define command{\n    command_name check_tsd\n    command_line $USER1$/check_tsd -H $HOSTADDRESS$ $ARG1$\n}\n</pre>\n <p>Then define a host in nagios for your TSD server(s). You can give it a check_command that is guaranteed to always return something if the backend is healthy.</p> <pre data-language=\"python\">define host{\n    host_name         tsd\n    address         tsd\n    check_command       check_tsd!-d 60 -m rate:tsd.rpc.received -t type=put -x lt -c 1\n    [...]\n}\n</pre>\n <p>Then define some service checks for the things you want to monitor.</p> <pre data-language=\"python\">define service{\n    host_name             tsd\n    service_description       Apache too many internal errors\n    check_command           check_tsd!-d 300 -m rate:apache.stats.hits -t status=500 -w 1 -c 2\n    [...]\n}\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/utilities/nagios.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/utilities/nagios.html</a>\n  </p>\n</div>\n","api_http/version":"<h1>/api/version</h1> <p>This endpoint returns information about the running version of OpenTSDB.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>This endpoint does not require any parameters via query string or body.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/version\n</pre>\n </div>   <h2>Response</h2> <p>The response is a hash map of version properties and values.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"timestamp\": \"1362712695\",\n  \"host\": \"localhost\",\n  \"repo\": \"/opt/opentsdb/build\",\n  \"full_revision\": \"11c5eefd79f0c800b703ebd29c10e7f924c01572\",\n  \"short_revision\": \"11c5eef\",\n  \"user\": \"localuser\",\n  \"repo_status\": \"MODIFIED\",\n  \"version\": \"2.0.0\"\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/version.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/version.html</a>\n  </p>\n</div>\n","development/plugins":"<h1>Plugins</h1> <p>OpenTSDB implements a very simple plugin model to extend the application. Plugins use the <em>service</em> and <em>service provider</em> facilities built into Java 1.6 that allows for dynamically loading JAR files and instantiating plugin implementations after OpenTSDB has been started. While not as flexible as many framework implementations, all we need to do is load a plugin on startup, initialize the implementation, and start passing data to or through it.</p> <p>To create a plugin, all you have to do is extend one of the <em>abstract</em> plugin classes, write a service description/manifest, compile, drop your JAR (along with any dependencies needed) into the OpenTSDB plugin folder, edit the TSD config and restart. That's all there is to it. No fancy frameworks, no worrying about loading and unloading at strange times, etc.</p>  <h2>Manifest</h2> <p>A plugin JAR requires a manifest with a special <em>services</em> folder and file to enable the <a class=\"reference external\" href=\"http://docs.oracle.com/javase/6/docs/api/java/util/ServiceLoader.html\">ServiceLoader</a> to load it properly. Here are the steps for creating the proper files:</p> <blockquote> <div>\n<ul> <li>\n<p class=\"first\">Create a <code class=\"docutils literal\"><span class=\"pre\">META-INF</span></code> directory under your <code class=\"docutils literal\"><span class=\"pre\">src</span></code> directory. Some IDEs can automatically generate this</p> </li> <li>\n<p class=\"first\">Within the <code class=\"docutils literal\"><span class=\"pre\">META-INF</span></code> directory, create a file named <code class=\"docutils literal\"><span class=\"pre\">MANIFEST.MF</span></code>. Again some IDEs can generate this automatically.</p> </li> <li>\n<p class=\"first\">Edit the <code class=\"docutils literal\"><span class=\"pre\">MANIFEST.MF</span></code> file and add:</p> <pre data-language=\"python\">Manifest-Version: 1.0\n</pre>\n <p>making sure to end with a blank line. You can add more manifest information if you like. This is the bare minimum to satisfy plugin requirements.</p> </li> <li>\n<p class=\"first\">Create a <code class=\"docutils literal\"><span class=\"pre\">services</span></code> directory under <code class=\"docutils literal\"><span class=\"pre\">META-INF</span></code></p> </li> <li>\n<p class=\"first\">Within <code class=\"docutils literal\"><span class=\"pre\">services</span></code> create a file with the canonical class name of the abstract plugin class you are implementing. E.g. if you implement <code class=\"docutils literal\"><span class=\"pre\">net.opentsdb.search.SearchPlugin</span></code>, use that for the name of the file.</p> </li> <li>\n<p class=\"first\">Edit the new file and put the canonical name of each class that implements the abstract interface on a new line of the file. E.g. if your implementation is called <code class=\"docutils literal\"><span class=\"pre\">net.opentsdb.search.ElasticSearch</span></code>, put that on a line. Some quick notes about this file:</p> <ul> <li>\n<p class=\"first\">You can put comments in the service implementation file. The comment character is the <code class=\"docutils literal\"><span class=\"pre\">#</span></code>, just like a Java properties file. E.g.:</p> <pre data-language=\"python\"># ElasticSearch plugin written by John Doe\n# that sends data over HTTP to a number of ElasticSearch servers\nnet.opentsdb.search.ElasticSearch\n</pre>\n </li> <li>\n<p class=\"first\">You can have more than one implementation of the same abstract class in one JAR and in this file. NOTE: If you have widely different implementations, start a different project and JAR. E.g. if you implement a search plugin for ElasticSearch and another for Solr, put Solr in a different project. However if you have two implementations that are very similar but slightly different, you can create one project. For example you could write an ElasticSearch plugin that uses HTTP for a protocol and another that uses Thrift. In that case, you could have a file like:</p> <pre data-language=\"python\"># ElasticSearch HTTP\nnet.opentsdb.search.ElasticSearchHTTP\n# ElasticSearch Thrift\nnet.opentsdb.search.ElasticSearchThrift\n</pre>\n </li> </ul> </li> <li>\n<p class=\"first\">Now compile your JAR and make sure to include the manifest file. Each IDE handles this differently. If you're going command line, try this:</p> <pre data-language=\"python\">jar cvmf &lt;path to MANIFEST.MF&gt; &lt;plugin jar name&gt; &lt;list of class files&gt;\n</pre>\n <p>Where the <code class=\"docutils literal\"><span class=\"pre\">&lt;list</span> <span class=\"pre\">of</span> <span class=\"pre\">class</span> <span class=\"pre\">files&gt;</span></code> includes the services file that you created above. E.g.:</p> <pre data-language=\"python\">jar cvmf META-INF/MANIFEST.MF searchplugin.jar ../bin/net/opentsdb/search/myplugin.class META-INF/services/net.opentsdb.search.SearchPlugin\n</pre>\n </li> </ul> </div>\n</blockquote>   <h2>Startup Plugins</h2> <p>Startup Plugins can be used to perform additional initialization steps during the OpenTSDB startup process.</p> <dl class=\"docutils\"> <dt>There are four hooks available, and they are called in this order:</dt> <dd>\n<ul class=\"first last simple\"> <li>Constructor</li> <li>Initialize</li> <li>Ready</li> <li>Shutdown</li> </ul> </dd> </dl> <div class=\"section\" id=\"constructor\"> <h3>Constructor</h3> <p>In the constructor for your plugin, you should initialize your plugin and make any external connections required here. For example, to connect to a service discovery tool such as Etcd or Curator.</p> </div> <div class=\"section\" id=\"initialize\"> <h3>Initialize</h3> <p>The Initialize hook is called once OpenTSDB has fully read the configuration options, both from the file, and the command line. This is called prior to creating the TSDB object so you can modify the configuration at this time.</p> <p>This hook could be used to register OpenTSDB with a service discovery mechanism or look up the location of an HBase cluster dynamically and populate the connfiguration. You could potentially create HBase tables if they do not exist at this time.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">You will want to make sure you set the status to PENDING or some other non-ready state in your service discovery system when this is called. TSDB has not been initialized yet at this point.</p> </div> </div> <div class=\"section\" id=\"ready\"> <h3>Ready</h3> <p>This hook is called once OpenTSDB has been fully initialized and is ready to serve traffic. This hook could be used to set the status to READY in a service discovery system, change the state of in a load balancer or perform other tasks which require a fully functioning OpenTSDB instance.</p> </div> <div class=\"section\" id=\"shutdown\"> <h3>Shutdown</h3> <p>This hook is called when OpenTSDB is performing shutdown tasks. No work should be done here which requires a functioning and connected OpenTSDB instance. You could use this to update the status of this node within your service discovery mechanism.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/development/plugins.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/development/plugins.html</a>\n  </p>\n</div>\n","development/http_api":"<h1>HTTP API</h1> <p>These are some notes on adding to the HTTP API.</p>  <h2>Reserved Query String Parameters</h2> <p>The following is a list of query string parameters that are used by OpenTSDB across the entire API. Don't try to overload their use please:</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"80%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Parameter</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>serializer</td> <td>The name of a serializer to use for parsing input or formatting return data</td> </tr> <tr class=\"row-odd\">\n<td>method</td> <td>Allows for overriding the HTTP verb when necessary</td> </tr> </tbody> </table><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/development/http_api.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/development/http_api.html</a>\n  </p>\n</div>\n","user_guide/query/dates":"<h1>Dates and Times</h1> <p>OpenTSDB supports a number of date and time formats when querying for data. The following formats are supported in queries submitted through the GUI, CliQuery tool or HTTP API. Every query requires a <strong>start time</strong> and an optional <strong>end time</strong>. If the end time is not specified, the current time on the system where the TSD is running will be used.</p>  <h2>Relative</h2> <p>If you don't know the exact timestamp to request you can submit a time in the past relative to the time on the system where the TSD is running. Relative times follow the format <code class=\"docutils literal\"><span class=\"pre\">&lt;amount&gt;&lt;time</span> <span class=\"pre\">unit&gt;-ago</span></code> where <code class=\"docutils literal\"><span class=\"pre\">&lt;amount&gt;</span></code> is the number of time units and <code class=\"docutils literal\"><span class=\"pre\">&lt;time</span> <span class=\"pre\">unit&gt;</span></code> is the unit of time, such as hours, days, etc. For example, if we provide a <strong>start time</strong> of <code class=\"docutils literal\"><span class=\"pre\">1h-ago</span></code> and leave out the <strong>end time</strong>, our query will return data start at 1 hour ago to the current time. Possible units of time include:</p> <ul class=\"simple\"> <li>ms - Milliseconds</li> <li>s - Seconds</li> <li>m - Minutes</li> <li>h - Hours</li> <li>d - Days (24 hours)</li> <li>w - Weeks (7 days)</li> <li>n - Months (30 days)</li> <li>y - Years (365 days)</li> </ul> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Relative times do not account for leap seconds, leap years or time zones. They simply calculate the number of seconds in the past from the current time.</p> </div>   <h2>Absolute Unix Time</h2> <p>Internally, all data is associated with a Unix (or POSIX) style timestamp. Unix times are defined as the number of seconds that have elapsed since January 1st, 1970 at 00:00:00 UTC time. Timestamps are represented as a positive integer such as <code class=\"docutils literal\"><span class=\"pre\">1364410924</span></code>, representing <code class=\"docutils literal\"><span class=\"pre\">ISO</span> <span class=\"pre\">8601:2013-03-27T19:02:04Z</span></code>. Since calls to store data in OpenTSDB require a Unix timestamp, it makes sense to support the format in queries. Thus you can supply an integer for a start or end time in a query.</p> <p>Queries using Unix timestamps can also support millisecond precision by simply appending three digits. For example providing a start time of <code class=\"docutils literal\"><span class=\"pre\">1364410924000</span></code> and an end time of <code class=\"docutils literal\"><span class=\"pre\">1364410924250</span></code> will return data within a 250 millisecond window. Millisecond timestamps may also be supplied with a period separating the seconds from the milliseconds as in <code class=\"docutils literal\"><span class=\"pre\">1364410924.250</span></code>. Any integers with 13 (or 14) characters will be treated as a millisecond timestamp. Anything 10 characters or less represent seconds. Milliseconds may only be supplied with 3 digit precision. If your tool outputs more than 3 digits you must truncate or round the value.</p>   <h2>Absolute Formatted Time</h2> <p>Since calculating a Unix time in your head is pretty difficult, OpenTSDB also supports human readable absolute date and times. Supported formats include:</p> <ul class=\"simple\"> <li>yyyy/MM/dd-HH:mm:ss</li> <li>yyyy/MM/dd HH:mm:ss</li> <li>yyyy/MM/dd-HH:mm</li> <li>yyyy/MM/dd HH:mm</li> <li>yyyy/MM/dd</li> </ul> <p><code class=\"docutils literal\"><span class=\"pre\">yyyy</span></code> represents the year as a four digit value, e.g. <code class=\"docutils literal\"><span class=\"pre\">2013</span></code>. <code class=\"docutils literal\"><span class=\"pre\">MM</span></code> represents the month of year starting at <code class=\"docutils literal\"><span class=\"pre\">01</span></code> for January to <code class=\"docutils literal\"><span class=\"pre\">12</span></code> for December. <code class=\"docutils literal\"><span class=\"pre\">dd</span></code> represents the day of the month starting at <code class=\"docutils literal\"><span class=\"pre\">01</span></code>. <code class=\"docutils literal\"><span class=\"pre\">HH</span></code> represents the hour of day in 24 hour format starting at <code class=\"docutils literal\"><span class=\"pre\">00</span></code> to <code class=\"docutils literal\"><span class=\"pre\">23</span></code>. <code class=\"docutils literal\"><span class=\"pre\">mm</span></code> represents the minutes starting at <code class=\"docutils literal\"><span class=\"pre\">00</span></code> to <code class=\"docutils literal\"><span class=\"pre\">59</span></code> and <code class=\"docutils literal\"><span class=\"pre\">ss</span></code> represents seconds starting at <code class=\"docutils literal\"><span class=\"pre\">00</span></code> to <code class=\"docutils literal\"><span class=\"pre\">59</span></code>. All months, days, hours, minutes and seconds that are single digits must be preceeded by a 0, e.g. the 5th day of the month must be given as <code class=\"docutils literal\"><span class=\"pre\">05</span></code>. When supplying on the data without a time, the system will assume midnight of the given day.</p> <p>Examples include <code class=\"docutils literal\"><span class=\"pre\">2013/01/23-12:50:42</span></code> or <code class=\"docutils literal\"><span class=\"pre\">2013/01/23</span></code>. Formatted times are converted from the default timezone of the host running the TSD to UTC. HTTP API queries can accept a user supplied time zone to override the local zone.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">When using the CliQuery tool, you must use the format that separates the date from the time with a dash. This is because the command line is split on spaces, so if you put a space in the timestamp, it will fail to parse execute properly.</p> </div>   <h2>Time Zones</h2> <p>When converting human readable timestamps, OpenTSDB will convert to UTC from the timezone configured on the system where the TSD is running. While many servers are configured to UTC, and we recommend that all systems running OpenTSDB use UTC, sometimes a local timezone is used.</p> <p>Queries via query string to the HTTP API can specify a <code class=\"docutils literal\"><span class=\"pre\">tz</span></code> parameter with a timezone identification string in a format applicable to the localization settings of the system running the TSD. For example, we could specify <code class=\"docutils literal\"><span class=\"pre\">tz=America/Los_Angeles</span></code> to convert our timestamp from Los Angeles local time to UTC.</p> <p>Alternatively, if you are unable to change the system timezone, you can provide an override via the config file <code class=\"docutils literal\"><span class=\"pre\">tsd.core.timezone</span></code> property.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/query/dates.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/query/dates.html</a>\n  </p>\n</div>\n","api_http/stats/index":"<h1>/api/stats</h1> <p>This endpoint provides a list of statistics for the running TSD. Sub endpoints return details about other TSD components such as the JVM, thread states or storage client. All statistics are read only.</p> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"jvm\">/api/stats/jvm</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"query\">/api/stats/query</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"region_clients\">/api/stats/region_clients</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"threads\">/api/stats/threads</a></li> </ul> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>No parameters available.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/stats\n</pre>\n </div>   <h2>Response</h2> <p>The response is an array of objects. Fields in the response include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>metric</td> <td>String</td> <td>Name of the metric the statistic is recording</td> <td>tsd.connectionmgr.connections</td> </tr> <tr class=\"row-odd\">\n<td>timestamp</td> <td>Integer</td> <td>Unix epoch timestamp, in seconds, when the statistic was collected and displayed</td> <td>1369350222</td> </tr> <tr class=\"row-even\">\n<td>value</td> <td>Integer</td> <td>The numeric value for the statistic</td> <td>42</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Map</td> <td>A list of key/value tag name/tag value pairs</td> <td><em>See Below</em></td> </tr> </tbody> </table> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"tsd.connectionmgr.connections\",\n    \"timestamp\": 1369350222,\n    \"value\": \"1\",\n    \"tags\": {\n      \"host\": \"wtdb-1-4\"\n    }\n  },\n  {\n    \"metric\": \"tsd.connectionmgr.exceptions\",\n    \"timestamp\": 1369350222,\n    \"value\": \"0\",\n    \"tags\": {\n      \"host\": \"wtdb-1-4\"\n    }\n  },\n  {\n    \"metric\": \"tsd.rpc.received\",\n    \"timestamp\": 1369350222,\n    \"value\": \"0\",\n    \"tags\": {\n      \"host\": \"wtdb-1-4\",\n      \"type\": \"telnet\"\n    }\n  }\n]\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/stats/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/stats/index.html</a>\n  </p>\n</div>\n","api_http/s":"<h1>/s</h1> <p>This endpoint was introduced in 1.0 as a means of accessing static files on the local system. <code class=\"docutils literal\"><span class=\"pre\">/s</span></code> will be maintained in the future and will not be deprecated. The static root is definied in the config file as <code class=\"docutils literal\"><span class=\"pre\">tsd.http.staticroot</span></code> or CLI via <code class=\"docutils literal\"><span class=\"pre\">--staticroot</span></code>.</p> <p>By default, static files will be returned with a header telling clients to cache them for 1 year. Any file that contains <code class=\"docutils literal\"><span class=\"pre\">nocache</span></code> in the name (e.g. <code class=\"docutils literal\"><span class=\"pre\">queryui.nocache.js</span></code>, the idiom used by GWT) will not include the cache header.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The TSD will attempt to return the correct <strong>Content-Type</strong> header for the requested file. However the TSD code doesn't support very many formats at this time, just HTML, JSON, Javascript and PNG. Let us know what formats you need or issue a pull request with your patches.</p> </div> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">The code for this endpoint is very simple and does not include any security. Thus you should make sure that permissions on your static root directory are secure so that users can't write malicious files and serve them out of OpenTSDB. Users shouldn't be able to write files via OpenTSDB, but take precautions just to be safe.</p> </div>  <h2>Verbs</h2> <p>All verbs are supported and simply ignored</p>   <h2>Requests</h2> <p>Query string and content body requests are ignored. Rather the requested file is a component of the path, e.g. <code class=\"docutils literal\"><span class=\"pre\">/s/index.html</span></code> will return the contents of the <code class=\"docutils literal\"><span class=\"pre\">index.html</span></code> file.</p>   <h2>Example Request</h2> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/s/queryui.nocache.js\n</pre>\n   <h2>Response</h2> <p>The response will be the contents of the requested file with appropriate HTTP headers configured.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/s.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/s.html</a>\n  </p>\n</div>\n","user_guide/cli/fsck":"<h1>fsck</h1> <p>Similar to a file system check, the fsck command will scan and, optionally, attempt to repair problems with data points in OpenTSDB's data table. The fsck command only operates on the <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> storage table, scanning the entire data table or any rows of data that match on a given query. Fsck can be used to repair errors and also reclaim space by compacting rows that were not compacted by a TSD and variable-length encoding data points from previous versions of OpenTSDB.</p> <p>By default, running fsck will only report errors found by the query. No changes are made to the underlying data unless you supply the <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> or <code class=\"docutils literal\"><span class=\"pre\">--fix-all</span></code> flags. Generally you should run an fsck without a fix flag first and verify issues found in the log file. If you're confident in the repairs, add a fix flag. Not all errors can be repaired automatically.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Running fsck with <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> or <code class=\"docutils literal\"><span class=\"pre\">--fix-all</span></code> may delete data points, columns or entire rows and deleted data is unrecoverable unless you restore from a backup. (or perform some HBase trickery to restore the data before a major compaction)</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">This page documents the OpenTSDB 2.1 fsck utility. For previous versions, only the <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> flag is available and only data within a query may be fsckd.</p> </div>  <h2>Parameters</h2> <pre data-language=\"bash\">fsck [flags] [START-DATE [END-DATE] query [queries...]]\n</pre>\n <table class=\"docutils\"> <colgroup> <col width=\"15%\"> <col width=\"5%\"> <col width=\"40%\"> <col width=\"5%\"> <col width=\"35%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>--fix</td> <td>Flag</td> <td>Optional flag that will attempt to repair errors. By itself, fix will only repair sign extension bugs, 8 byte floats with 4 byte qualifiers and VLE stand-alone data points. Use in conjunction with other flags to repair more issues.</td> <td>Not set</td> <td>--fix</td> </tr> <tr class=\"row-odd\">\n<td>--fix-all</td> <td>Flag</td> <td>Sets all repair flags to attempt to fix all issues at once. <strong>Use with caution</strong>\n</td> <td>Not set</td> <td>--fix</td> </tr> <tr class=\"row-even\">\n<td>--compact</td> <td>Flag</td> <td>Compacts non-compacted rows during a repair.</td> <td>Not Set</td> <td>--compact</td> </tr> <tr class=\"row-odd\">\n<td>--delete-bad-compacts</td> <td>Flag</td> <td>Removes columns that appear to be compacted but failed parsing. If a column parses properly but the final byte of the value is not set to a 0 or a 1, the column will be left alone.</td> <td>Not Set</td> <td>--delete-bad-compacts</td> </tr> <tr class=\"row-even\">\n<td>--delete-bad-rows</td> <td>Flag</td> <td>Removes any row that doesn't match the OpenTSDB row key format of a metric UID followed by a timestamp and tag UIDs.</td> <td>Not Set</td> <td>--delete-bad-rows</td> </tr> <tr class=\"row-odd\">\n<td>--delete-bad-values</td> <td>Flag</td> <td>Removes any stand-alone data points that could not be repaired or did not conform to the OpenTSDB specification.</td> <td>Not Set</td> <td>--delete-bad-values</td> </tr> <tr class=\"row-even\">\n<td>--delete-orphans</td> <td>Flag</td> <td>Removes rows where one or more UIDs could not be resolved to a name.</td> <td>Not Set</td> <td>--delete-orphans</td> </tr> <tr class=\"row-odd\">\n<td>--delete-unknown_columns</td> <td>Flag</td> <td>Removes any column that does not appear to be a compacted column, a stand-alone data point or a known or future OpenTSDB object.</td> <td>Not Set</td> <td>--delete-unknown-columns</td> </tr> <tr class=\"row-even\">\n<td>--resolve-duplicates</td> <td>Flag</td> <td>Enables duplicate data point resolution by deleting all but the latest or oldest data point. Also see <code class=\"docutils literal\"><span class=\"pre\">--last-write-wins</span></code>.</td> <td>Not Set</td> <td>--resolve-duplicates</td> </tr> <tr class=\"row-odd\">\n<td>--last-write-wins</td> <td>Flag</td> <td>When set, deletes all but the most recently written data point when resolving duplicates. If the config value <code class=\"docutils literal\"><span class=\"pre\">tsd.storage.fix_duplicates</span></code> is set to true, then the latest data point will be kept regardless of this value.</td> <td>Not Set</td> <td>--last-write-wins</td> </tr> <tr class=\"row-even\">\n<td>--full-scan</td> <td>Flag</td> <td>Scans the entire data table. <strong>Note:</strong> This can take a very long time to complete.</td> <td>Not Set</td> <td>--full-scan</td> </tr> <tr class=\"row-odd\">\n<td>--threads</td> <td>Integer</td> <td>The number of threads to use when performing a full scan. The default is twice the number of CPU cores.</td> <td>2 x CPU Cores</td> <td>--threads=16</td> </tr> <tr class=\"row-even\">\n<td>START-DATE</td> <td>String or Integer</td> <td>Starting time for the query. This may be an absolute or relative time. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details</td> <td> </td> <td>1h-ago</td> </tr> <tr class=\"row-odd\">\n<td>END-DATE</td> <td>String or Integer</td> <td>Optional end time for the query. If not provided, the current time is used. This may be an absolute or relative time. See <a class=\"reference internal\" href=\"../query/dates\"><em>Dates and Times</em></a> for details</td> <td>Current timestamp</td> <td>2014/01/01-00:00:00</td> </tr> <tr class=\"row-even\">\n<td>query</td> <td>String</td> <td>One or more command line queries</td> <td> </td> <td>sum tsd.hbase.rpcs type=put</td> </tr> </tbody> </table>   <h2>Examples</h2> <p><strong>Query</strong></p> <pre data-language=\"bash\">fsck --fix 1h-ago now sum tsd.hbase.rpcs type=put sum tsd.hbase.rpcs type=scan\n</pre>\n <p><strong>Full Table</strong></p> <pre data-language=\"bash\">fsck --full-scan --threads=8 --fix --resolve-duplicates --compact\n</pre>\n   <h2>Full Table Vs Queries</h2> <p>Using the <code class=\"docutils literal\"><span class=\"pre\">--full-scan</span></code> flag, the entire OpenTSDB <code class=\"docutils literal\"><span class=\"pre\">tsdb</span></code> data table will be scanned. By default the utility will launch <code class=\"docutils literal\"><span class=\"pre\">2</span> <span class=\"pre\">x</span> <span class=\"pre\">CPU</span> <span class=\"pre\">core</span></code> threads for optimal performance. Data is stored with the metric UID as the start of each row key so the utility will determine the maximum metric UID and split up the main data table equally among threads. If your data is distributed among metrics fairly evenly, then each thread should complete in roughly the same amount of time. However some metrics usually have more data or time series than others so these threads may be running much longer than others. Future updates to OpenTSDB will be able to divy up the workload in a more efficient manner.</p> <p>Alternatively you can spcify a CLI query to fsck over a smaller timespan and look at a specific metric or time series. These queries will almost always complete much faster than a full scan and will uncover similar issues. However orphaned metrics will not found as the query will only operate on known time series. Orphans where tag names or values have been deleted will still be found.</p> <p>Regardless of the method used, fsck only looks at the most recent column value in HBase. If the table is configured to store multiple versions, older versions of a column are ignored.</p>   <h2>Results</h2> <p>The results will be logged with settings in the <code class=\"docutils literal\"><span class=\"pre\">logback.xml</span></code> file. For long fscks, it's recommended to run in the background and configure LogBack to have plenty of space for writing data. On completion, statistics about the run will be printed. An example looks like:</p> <pre data-language=\"python\">2014-07-07 13:09:15,610 INFO  [main] Fsck: Starting full table scan\n2014-07-07 13:09:15,619 INFO  [main] Fsck: Max metric ID is [0]\n2014-07-07 13:09:15,619 INFO  [main] Fsck: Spooling up [1] worker threads\n2014-07-07 13:09:16,358 INFO  [main] Fsck: Thread [0] Finished\n2014-07-07 13:09:16,358 INFO  [main] Fsck: Key Values Processed: 301\n2014-07-07 13:09:16,358 INFO  [main] Fsck: Rows Processed: 1\n2014-07-07 13:09:16,359 INFO  [main] Fsck: Valid Datapoints: 300\n2014-07-07 13:09:16,359 INFO  [main] Fsck: Annotations: 1\n2014-07-07 13:09:16,359 INFO  [main] Fsck: Invalid Row Keys Found: 0\n2014-07-07 13:09:16,360 INFO  [main] Fsck: Invalid Rows Deleted: 0\n2014-07-07 13:09:16,360 INFO  [main] Fsck: Duplicate Datapoints: 0\n2014-07-07 13:09:16,360 INFO  [main] Fsck: Duplicate Datapoints Resolved: 0\n2014-07-07 13:09:16,361 INFO  [main] Fsck: Orphaned UID Rows: 0\n2014-07-07 13:09:16,361 INFO  [main] Fsck: Orphaned UID Rows Deleted: 0\n2014-07-07 13:09:16,361 INFO  [main] Fsck: Possible Future Objects: 0\n2014-07-07 13:09:16,362 INFO  [main] Fsck: Unknown Objects: 0\n2014-07-07 13:09:16,362 INFO  [main] Fsck: Unknown Objects Deleted: 0\n2014-07-07 13:09:16,362 INFO  [main] Fsck: Unparseable Datapoint Values: 0\n2014-07-07 13:09:16,362 INFO  [main] Fsck: Unparseable Datapoint Values Deleted: 0\n2014-07-07 13:09:16,363 INFO  [main] Fsck: Improperly Encoded Floating Point Values: 0\n2014-07-07 13:09:16,363 INFO  [main] Fsck: Improperly Encoded Floating Point Values Fixed: 0\n2014-07-07 13:09:16,363 INFO  [main] Fsck: Unparseable Compacted Columns: 0\n2014-07-07 13:09:16,364 INFO  [main] Fsck: Unparseable Compacted Columns Deleted: 0\n2014-07-07 13:09:16,364 INFO  [main] Fsck: Datapoints Qualified for VLE : 0\n2014-07-07 13:09:16,364 INFO  [main] Fsck: Datapoints Compressed with VLE: 0\n2014-07-07 13:09:16,365 INFO  [main] Fsck: Bytes Saved with VLE: 0\n2014-07-07 13:09:16,365 INFO  [main] Fsck: Total Errors: 0\n2014-07-07 13:09:16,366 INFO  [main] Fsck: Total Correctable Errors: 0\n2014-07-07 13:09:16,366 INFO  [main] Fsck: Total Errors Fixed: 0\n2014-07-07 13:09:16,366 INFO  [main] Fsck: Completed fsck in [1] seconds\n</pre>\n <p>For the most part, these statistics should be self-explanatory. <code class=\"docutils literal\"><span class=\"pre\">Key</span> <span class=\"pre\">Values</span> <span class=\"pre\">Processed</span></code> indicates the number of individual columns in HBase. <code class=\"docutils literal\"><span class=\"pre\">VLE</span></code> referse to <code class=\"docutils literal\"><span class=\"pre\">variable</span> <span class=\"pre\">length</span> <span class=\"pre\">encoding</span></code>.</p> <p>During a run, progress will be reported every 5 seconds so that you know the utility is still working. You should see lines similar to the following:</p> <pre data-language=\"python\">10:14:00.518 INFO  [Fsck.run] - Processed 47689680000 rows, 449891670779 valid datapoints\n10:14:01.518 INFO  [Fsck.run] - Processed 47689730000 rows, 449892264237 valid datapoints\n10:14:02.519 INFO  [Fsck.run] - Processed 47689780000 rows, 449892880333 valid datapoints\n</pre>\n <p>Any time an error is found (and possibly fixed), the log will be updated immediately. Errors will usually include the column where the error was found in the output. Byte arrays are represented in either Java style signed bytes, e.g. <code class=\"docutils literal\"><span class=\"pre\">[0,</span> <span class=\"pre\">1,</span> <span class=\"pre\">-42]</span></code> or hex encoded strings, e.g. <code class=\"docutils literal\"><span class=\"pre\">00000000000000040000000000000005</span></code>. Short-hand references include (k) for the row key, (q) for the qualifier and (v) for the value.</p>   <h2>Types of Errors and Fixes</h2> <p>The following is a list of errors and/or fixes that can be found or performed with fsck.</p> <div class=\"section\" id=\"bad-row-keys\"> <h3>Bad Row Keys</h3> <p>If a row key is found that doesn't conform to the OpenTSDB data table specification <code class=\"docutils literal\"><span class=\"pre\">&lt;metric_UID&gt;&lt;base_timestamp&gt;&lt;tagk1_UID&gt;&lt;tagv1_UID&gt;[...&lt;tagkn_UID&gt;&lt;tagvn_UID&gt;]</span></code>, the entire row is considered invalid.</p> <pre data-language=\"bash\">2014-07-07 15:03:46,483 ERROR [Fsck #0] Fsck: Invalid row key.\n    Key: 000001\n</pre>\n <p><em>Fix:</em></p> <p>If <code class=\"docutils literal\"><span class=\"pre\">--delete-bad-rows</span></code> is set, then the entire row will be removed from HBase.</p> </div> <div class=\"section\" id=\"orphaned-rows\"> <h3>Orphaned Rows</h3> <p>If a row key is parsed as a proper OpenTSDB row, then the UIDs for the time series ID (TSUID) of the row are resolved to their names. If any of the UIDs does not match a name in the <code class=\"docutils literal\"><span class=\"pre\">tsdb-uid</span></code> table, then the row is considered an orphan. This can happen if a UID is manually deleted from the UID table or a deletion does not complete properly.</p> <pre data-language=\"bash\">2014-07-07 15:08:45,057 ERROR [Fsck #0] Fsck: Unable to resolve the metric from the row key.\n    Key: 00000150E22700000001000001\n    No such unique ID for 'metric': [0, 0, 1]\n</pre>\n <p><em>Fix:</em></p> <p>If <code class=\"docutils literal\"><span class=\"pre\">--delete-orphans</span></code> is set, then the entire row will be removed from HBase.</p> </div> <div class=\"section\" id=\"compact-row\"> <h3>Compact Row</h3> <p>While it's not strictly an error, fsck can be used to compact rows into a single column. Compacting rows saves storage space by merging multiple columns into one. This cuts down on HBase overhead. If a TSD that is configured to compact columns crashes, some rows may be missed and remain in stand-alone data point form. As compaction can consume resources, you can use fsck to compact rows when the load on your cluster is reduced.</p> <p>Specifying the <code class=\"docutils literal\"><span class=\"pre\">--compact</span></code> flag along with <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> will compact any row that has stand-alone data points within the query range. During compaction, any data points from old OpenTSDB versions that qualify for VLE will be re-encoded.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If a row is repaired for any reason and has one or more compacted columns, the row will be re-compacted regardless of the <code class=\"docutils literal\"><span class=\"pre\">--compact</span></code> flag.</p> </div> </div> <div class=\"section\" id=\"bad-compacted-column-error\"> <h3>Bad Compacted Column Error</h3> <p>These errors occur when compacted column is found that cannot be parsed into individual data points. This can happen if the qualifier appears correct but the number of bytes in the value array do not match the lengths encoded in the qualifier. Compacted columns with their data points out of order are not considered bad columns. Instead, the column will be sorted properly and re-written if the <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> or <code class=\"docutils literal\"><span class=\"pre\">--fix-all</span></code> flags are present.</p> <pre data-language=\"bash\">2014-07-07 13:29:40,251 ERROR [Fsck #0] Fsck: Corrupted value: couldn't break down into individual values (consumed 20 bytes, but was expecting to consume 24): [k '00000150E22700000001000001' q '000700270033' v '00000000000000040000000000000005000000000000000600'], cells so far: [Cell([0, 7], [0, 0, 0, 0, 0, 0, 0, 4]), Cell([0, 39], [0, 0, 0, 0, 0, 0, 0, 5]), Cell([0, 51], [0, 0, 0, 0])]\n</pre>\n <p><em>Fix:</em></p> <p>The only fix for this error is to delete the column by specifying the <code class=\"docutils literal\"><span class=\"pre\">--delete-bad-compacts</span></code> flag.</p> </div> <div class=\"section\" id=\"compacted-last-byte-error\"> <h3>Compacted Last Byte Error</h3> <p>The last byte of a compacted value is for storing meta data. It will usually be <code class=\"docutils literal\"><span class=\"pre\">0</span></code> if all of the data points are encoded in seconds or milliseconds. If there is a mixture of seconds and milliseconds will be set to <code class=\"docutils literal\"><span class=\"pre\">1</span></code>. If the value is something else then it may be from a future version of OpenTSDB or the column may be invalid.</p> <pre data-language=\"bash\">18:13:35.979 [main] ERROR net.opentsdb.tools.Fsck - The last byte of a compacted should be 0 or 1. Either this value is corrupted or it was written by a future version of OpenTSDB.\n    [k '00000150E22700000001000001' q '00070027' v '00000000000000040000000000000005']\n</pre>\n <p><em>Fix:</em></p> <p>Currently this is not repaired. You can manually set the last byte to 0 or 1 to prevent the error from being thrown. The <code class=\"docutils literal\"><span class=\"pre\">--delete-bad-compacts</span></code> flag will not remove these columns.</p> </div> <div class=\"section\" id=\"value-too-long-or-short\"> <h3>Value Too Long Or Short</h3> <p>This may occur if a value is recorded on greater than 8 bytes for a single data point column. Individual data points are stored on 2 or 4 byte qualifiers. This error cannot happen for a data point within a compacted column. If it was compacted, the column would throw a bad compacted column error as it wouldn't be parseable.</p> <pre data-language=\"bash\">2014-07-07 14:50:44,022 ERROR [Fsck #0] Fsck: This floating point value must be encoded either on 4 or 8 bytes, but it's on 9 bytes.\n    [k '00000150E22700000001000001' q 'F000020B' v '000000000000000005']\n</pre>\n <p><em>Fix:</em></p> <p><code class=\"docutils literal\"><span class=\"pre\">--delete-bad-values</span></code> will remove the column.</p> </div> <div class=\"section\" id=\"old-version-floats\"> <h3>Old Version Floats</h3> <p>Early OpenTSDB versions had a bug in the floating point value storage where the first 4 bytes of an 8 byte value were written with all bits set to 1. The value should be on the last four bytes as the qualifier encodes the length as four bytes. However if the invalid data was compacted, the data cannot be parsed properly and an error will be recorded.</p> <pre data-language=\"bash\">18:43:35.297 [main] ERROR net.opentsdb.tools.Fsck - Floating point value with 0xFF most significant bytes, probably caused by sign extension bug present in revisions [96908436..607256fc].\n    [k '00000150E22700000001000001' q '002B' v 'FFFFFFFF43FA6666']\n</pre>\n <p><em>Fix:</em></p> <p>The <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> flag will repair these errors by rewriting the value without the first four bytes. The qualifier remains unchanged.</p> </div> <div class=\"section\" id=\"byte-floats-with-8-byte-value-ok\"> <h3>4 Byte Floats with 8 Byte Value OK</h3> <p>Some versions of OpenTSDB may have encoded floating point values on 8 bytes when setting the qualifier length to 4 bytes. The first four bytes should be 0. If the value was compacted, the compacted column will be invalid as parsing is no longer possible.</p> <pre data-language=\"bash\">2014-07-07 14:33:34,498 WARN  [Fsck #0] Fsck: Floating point value was marked as 4 bytes long but was actually 8 bytes long\n    [k '00000150E22700000001000001' q '000B' v '0000000040866666']\n</pre>\n <p><em>Fix:</em></p> <p>The <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> flag will repair these errors by rewriting the value without the first four bytes. The qualifier remains unchanged.</p> </div> <div class=\"section\" id=\"byte-floats-with-8-byte-value-bad\"> <h3>4 Byte Floats with 8 Byte Value Bad</h3> <p>In this case a value was encoded on 8 bytes with the first four bytes set to a non-zero value. It could be that the value is an 8 byte double since OpenTSDB never actually encoded on 8 bytes, the value is likely corrupt. If the value was compacted, the compacted column will be invalid as parsing is no longer possible.</p> <pre data-language=\"bash\">2014-07-07 14:37:02,717 ERROR [Fsck #0] Fsck: Floating point value was marked as 4 bytes long but was actually 8 bytes long and the first four bytes were not zeroed\n    [k '00000150E22700000001000001' q '002B' v 'FB02F40F43FA6666']\n</pre>\n <p><em>Fix:</em></p> <p>The <code class=\"docutils literal\"><span class=\"pre\">--delete-bad-values</span></code> flag will remove the column. You could try parsing the value as a Double manually and see if it looks valid, otherwise it's likely a corrupt column.</p> </div> <div class=\"section\" id=\"unknown-object\"> <h3>Unknown Object</h3> <p>OpenTSDB 2.0 supports objects such as annotations in the data table. If a column is found that doesn't match an OpenTSDB object, a compacted column or a stand-alone data point, it is considered an unknown object and can likely be deleted.</p> <pre data-language=\"bash\">2014-07-07 14:55:03,019 ERROR [Fsck #0] Fsck: Unknown qualifier, must be 2, 3, 5 or an even number of bytes.\n    [k '00000150E22700000001000001' q '00270401010101' v '0000000000000005']\n</pre>\n <p><em>Fix:</em></p> <p>The <code class=\"docutils literal\"><span class=\"pre\">--delete-unknown-columns</span></code> flag will remove this column from the row.</p> </div> <div class=\"section\" id=\"future-object\"> <h3>Future Object</h3> <p>Objects are encoded on 3 or 5 byte qualifiers and the type is determined by a prefix. If a prefix is found that OpenTSDB doesn't recognize, then it will report the object but it will not be deleted. Note that this may actually be an unknown or corrupted column as fsck only looks at the qualifier length and the first byte of the qualifier. If that is the case, you can safely delete this column manually.</p> <pre data-language=\"bash\">2014-07-07 14:57:15,858 WARN  [Fsck #0] Fsck: Found an object possibly from a future version of OpenTSDB\n    [k '00000150E22700000001000001' q '042704' v '467574757265204F626A656374']\n</pre>\n <p><em>Fix:</em></p> <p>Future objects are left alone during fsck. Querying over the data with a TSD that doesn't support the object will throw an exception but versions that do support the object should procede normally.</p> </div> <div class=\"section\" id=\"duplicate-timestamps\"> <h3>Duplicate Timestamps</h3> <p>Due to the use of encoding length and type for datapoints in qualifiers, it's possible to record a data point for the same timestamp with two different qualifiers. For example if you post an integer value for time <code class=\"docutils literal\"><span class=\"pre\">1</span></code> and then post a float value for time <code class=\"docutils literal\"><span class=\"pre\">1</span></code>, two different columns will be created. Duplicates can also happen if a row has been compacted and the TSD writes a new stand-alone column that matches a timestamp in the compacted column. At query time, an exception will be thrown as TSD does not know which value is the correct one.</p> <pre data-language=\"bash\">2014-07-07 15:22:43,231 ERROR [Fsck #0] Fsck: More than one column had a value for the same timestamp: (1356998400000)\n  row key: (00000150E22700000001000001)\n  write time: (1388534400000)  compacted: (false)  qualifier: [0, 7]  &lt;--- Keep oldest\n  write time: (1388534400001)  compacted: (false)  qualifier: [0, 11]\n  write time: (1388534400002)  compacted: (false)  qualifier: [0, 3]\n  write time: (1388534400003)  compacted: (false)  qualifier: [0, 1]\n</pre>\n <p><em>Fix:</em></p> <p>If <code class=\"docutils literal\"><span class=\"pre\">--resolve-duplicates</span></code> is set, then all data points except for the latest or the oldest value will be deleted. The fix applies to both stand-alone and compacted data points. If the <code class=\"docutils literal\"><span class=\"pre\">--last-write-wins</span></code> flag is set, then the latest value is saved. Without the <code class=\"docutils literal\"><span class=\"pre\">--last-write-wins</span></code> flag, then the oldest value is saved.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If the <code class=\"docutils literal\"><span class=\"pre\">tsd.storage.fix_duplicates</span></code> configuration value is set to <code class=\"docutils literal\"><span class=\"pre\">true</span></code> then the latest value will be saved regardless of <code class=\"docutils literal\"><span class=\"pre\">--last-write-wins</span></code>.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">With compactions enabled, it is possible (though unlikely) that a data point is written while a row is being compacted. In this case, the compacted column will have a <em>later</em> timestamp than a data point written during the compaction. Therefore the default result of <code class=\"docutils literal\"><span class=\"pre\">--resolve-duplicates</span></code> will keep the stand-alone data point or, if last writes win, then the compacted value.</p> </div> </div> <div class=\"section\" id=\"variable-length-encoding\"> <h3>Variable-Length Encoding</h3> <p>Early OpenTSDB implementations always encoded integer values on 8 bytes. With 2.0, integers were written on the smallest number of bytes possible, either 1, 2, 4 or 8. During fsck, any 8 byte encoded integers detected will be re-written with VLE if the <code class=\"docutils literal\"><span class=\"pre\">--fix</span></code> or <code class=\"docutils literal\"><span class=\"pre\">--fix-all</span></code> flags are specified. This includes stand-alone and compacted values. At the end of a run, the number of bytes saved with VLE are displayed.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/cli/fsck.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/cli/fsck.html</a>\n  </p>\n</div>\n","development/development":"<h1>General Development</h1> <p>OpenTSDB isn't laid out like a typical Java project, instead it's a bit more like a C or C++ environment. This page is to help folks who want to modify OpenTSDB and provide updates back to the community.</p>  <h2>Build System</h2> <p>There are almost as many build systems as there are developers so it's impossible to satisfy everyone no matter which system or layout is chosen. Autotools and GNU Make were chosen early on for OpenTSDB because of their flexibility, portability, and especially speed and popular usage. It's not the easiest to configure but for our needs, it's really not too difficult. We'll spell out what you need to change below and give tips for IDE users who want to setup an environment. Note that the build script can now compile a <code class=\"docutils literal\"><span class=\"pre\">pom.xml</span></code> file for compiling with Maven and work is underway to provide better Maven support. However you still have to modify <code class=\"docutils literal\"><span class=\"pre\">Makefile.am</span></code> if you add or remove classes or dependencies and such.</p>   <h2>Building</h2> <p>OpenTSDB is built using the standard <code class=\"docutils literal\"><span class=\"pre\">./configure</span> <span class=\"pre\">&amp;&amp;</span> <span class=\"pre\">make</span></code> model that is most commonly employed by many open-source projects. Fresh working copies checked out from Git must first be <code class=\"docutils literal\"><span class=\"pre\">./bootstraped</span></code>.</p> <p>Alternatively, there is a <code class=\"docutils literal\"><span class=\"pre\">build.sh</span></code> script you can run that makes as it takes care of all the steps for you. You can give it a Make target in argument, e.g. <code class=\"docutils literal\"><span class=\"pre\">./build.sh</span> <span class=\"pre\">distcheck</span></code> (the default target is <code class=\"docutils literal\"><span class=\"pre\">all</span></code>).</p> <div class=\"section\" id=\"build-targets\"> <h3>Build Targets</h3> <p>The <code class=\"docutils literal\"><span class=\"pre\">build.sh</span></code> script will compile a JAR and the static GWT files for the front-end GUI if no parameters are passed. Additional parameters include:</p> <ul class=\"simple\"> <li>\n<strong>check</strong> - Executes unit tests and reports on the results. You can specify executing the checks in a specific file via <code class=\"docutils literal\"><span class=\"pre\">test_SRC=&lt;path&gt;</span></code>, e.g. <code class=\"docutils literal\"><span class=\"pre\">./build.sh</span> <span class=\"pre\">check</span> <span class=\"pre\">test_SRC=test/uid/TestNoSuchUniqueId.java</span></code>\n</li> <li>\n<strong>pom.xml</strong> - Compile a POM file to compile with Maven.</li> <li>\n<strong>dist</strong> - Downloads dependencies, compiles OpenTSDB and creates a tarball for distribution</li> <li>\n<strong>distcheck</strong> - Same as dist but also runs unit tests. This should be run before issuing pull requests to verify that everything performs correctly.</li> <li>\n<strong>debian</strong> - Compiles OpenTSDB and generates a Debian package</li> </ul> </div>   <h2>Adding a Dependency</h2> <p><em>Please try your best not to</em>. We're extremely picky on the dependencies and will require a code review before we start depending on a new library. The goal isn't to re-invent the wheel either, but we are very mindful about the number and quality of dependent libraries we pull in. If you absolutely must add a new dependency, here are the steps:</p> <ul> <li>\n<p class=\"first\">Find the canonical source to download the dependent JAR file</p> </li> <li>\n<p class=\"first\">Find or create the proper directory under <code class=\"docutils literal\"><span class=\"pre\">third_party/</span></code></p> </li> <li>\n<p class=\"first\">In that directory, create a <code class=\"docutils literal\"><span class=\"pre\">&lt;depdencency&gt;.jar.md5</span></code> file</p> </li> <li>\n<p class=\"first\">Paste the MD5 hash of the entire jar in that file and save it</p> </li> <li>\n<p class=\"first\">Create or edit the <code class=\"docutils literal\"><span class=\"pre\">include.mk</span></code> file and copy the header info from another directory's file</p> </li> <li>\n<p class=\"first\">Add a <code class=\"docutils literal\"><span class=\"pre\">&lt;DEPENDENCY&gt;_VERSION</span> <span class=\"pre\">:=</span> <span class=\"pre\">&lt;version&gt;</span></code> e.g. <code class=\"docutils literal\"><span class=\"pre\">JACKSON_VERSION</span> <span class=\"pre\">:=</span> <span class=\"pre\">1.9.4</span></code></p> </li> <li>\n<p class=\"first\">Add a <code class=\"docutils literal\"><span class=\"pre\">&lt;DEPENDENCY&gt;</span> <span class=\"pre\">:=</span> <span class=\"pre\">third_parth/&lt;DIR&gt;/&lt;dependency&gt;$(&lt;DEPENDENCY&gt;_VERSION).jar</span></code> line e.g. <code class=\"docutils literal\"><span class=\"pre\">JACKSON_CORE</span> <span class=\"pre\">:=</span> <span class=\"pre\">third_party/jackson/jackson-core-lgpl-$(JACKSON_CORE_VERSION).jar</span></code></p> </li> <li>\n<p class=\"first\">Add the canonical source URL in the format <code class=\"docutils literal\"><span class=\"pre\">&lt;DEPENDENCY&gt;_BASE_URL</span> <span class=\"pre\">:=</span> <span class=\"pre\">&lt;URL&gt;</span></code> e.g. <code class=\"docutils literal\"><span class=\"pre\">JACKSON_CORE_BASE_URL</span> <span class=\"pre\">:=</span> <span class=\"pre\">http://repository.codehaus.org/org/codehaus/jackson/jackson-core-lgpl/$(JACKSON_VERSION)</span></code> and note that the JAR name will be appended to the end of the URL</p> </li> <li>\n<p class=\"first\">Add the following lines</p> <pre data-language=\"python\">$(&lt;DEPENDENCY&gt;): $(J&lt;DEPENDENCY&gt;).md5\nset dummy ``$(&lt;DEPENDENCY&gt;_BASE_URL)`` ``$(&lt;DEPENDENCY&gt;)``; shift; $(FETCH_DEPENDENCY)\n</pre>\n <p>e.g.</p> <pre data-language=\"python\">$(JACKSON_CORE): $(JACKSON_CORE).md5\nset dummy ``$(JACKSON_CORE_BASE_URL)`` ``$(JACKSON_CORE)``; shift; $(FETCH_DEPENDENCY)\n</pre>\n </li> <li>\n<p class=\"first\">Add a line <code class=\"docutils literal\"><span class=\"pre\">THIRD_PARTY</span> <span class=\"pre\">+=</span> <span class=\"pre\">$(&lt;DEPENDENCY&gt;)</span></code> e.g. <code class=\"docutils literal\"><span class=\"pre\">THIRD_PARTY</span> <span class=\"pre\">+=</span> <span class=\"pre\">$(JACKSON_CORE)</span></code></p> </li> <li>\n<p class=\"first\">Next, back in the <code class=\"docutils literal\"><span class=\"pre\">third_party/</span></code> directory, edit the <code class=\"docutils literal\"><span class=\"pre\">include.mk</span></code> file and if you added a new directory for your dependency, insert a reference to the <code class=\"docutils literal\"><span class=\"pre\">.mk</span></code> file in the proper alphabetical position.</p> </li> <li>\n<p class=\"first\">Edit <code class=\"docutils literal\"><span class=\"pre\">Makefile.am</span></code></p> <ul> <li>\n<p class=\"first\">Find the <code class=\"docutils literal\"><span class=\"pre\">tsdb_DEPS</span> <span class=\"pre\">=</span> <span class=\"pre\">\\</span></code> line</p> </li> <li>\n<p class=\"first\">Add your new dependency in the proper alphabetical position in the format <code class=\"docutils literal\"><span class=\"pre\">$(&lt;DEPENDENCY&gt;)</span></code>, e.g. <code class=\"docutils literal\"><span class=\"pre\">$(JACKSON_CORE&gt;</span></code>. Note that if you put it the middle of the list, you must finish with the line continuation character, the backslash <code class=\"docutils literal\"><span class=\"pre\">\\</span></code>. If your dependency goes at the end, do not add the backslash.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If the dependency is only used for unit tests, then add it to the <code class=\"docutils literal\"><span class=\"pre\">test_DEPS</span> <span class=\"pre\">=</span> <span class=\"pre\">\\</span></code> list</p> </div> </li> <li>\n<p class=\"first\">Find the <code class=\"docutils literal\"><span class=\"pre\">pom.xml:</span> <span class=\"pre\">pom.xml.in</span> <span class=\"pre\">Makefile</span></code> line in the file</p> </li> <li>\n<p class=\"first\">Add a sed line such as <code class=\"docutils literal\"><span class=\"pre\">-e</span> <span class=\"pre\">'s/@&lt;DEPENDENCY&gt;_VERSION@/$(&lt;DEPENDENCY&gt;_VERSION)/'</span> <span class=\"pre\">\\</span></code> e.g. <code class=\"docutils literal\"><span class=\"pre\">-e</span> <span class=\"pre\">'s/@JACKSON_VERSION@/$(JACKSON_VERSION)/'</span> <span class=\"pre\">\\</span></code></p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Unit test dependencies go here as well as regular items</p> </div> </li> </ul> </li> <li>\n<p class=\"first\">Edit <code class=\"docutils literal\"><span class=\"pre\">pom.xml.in</span></code></p> <ul class=\"simple\"> <li>Find the <code class=\"docutils literal\"><span class=\"pre\">&lt;dependencies&gt;</span></code> XML section</li> <li>Copy and paste an existing dependency section and modify it for your variables</li> </ul> </li> <li>\n<p class=\"first\">Now run a build via <code class=\"docutils literal\"><span class=\"pre\">./build.sh</span></code> and verify that it fetches your dependency and builds without errors. * Then run <code class=\"docutils literal\"><span class=\"pre\">./build.sh</span> <span class=\"pre\">pom.xml</span></code> to verify that the POM is compiled properly and run a <code class=\"docutils literal\"><span class=\"pre\">mvn</span> <span class=\"pre\">compile</span></code> to verify the Maven build works correctly.</p> </li> </ul>   <h2>Adding/Removing/Moving a Class</h2> <p>This is much easier than dealing with a dependency. You only need to modify <code class=\"docutils literal\"><span class=\"pre\">Makefile.am</span></code> and edit the <code class=\"docutils literal\"><span class=\"pre\">tsdb_SRC</span> <span class=\"pre\">:=</span> <span class=\"pre\">\\</span></code> or the <code class=\"docutils literal\"><span class=\"pre\">test_SRC</span> <span class=\"pre\">:=</span> <span class=\"pre\">\\</span></code> lists. If you're adding a class, put it in the proper alphabetical position and account for the proper directory and class name. It is case sensitive so make sure to get that right. If removing a class, just delete the line. If moving a class, add the new line and delete the old one. Be careful to handle the line continuation <code class=\"docutils literal\"><span class=\"pre\">\\</span></code> backslashes. The last class in each list should NOT end with a backslash, the rest need it.</p> <p>After editing, rebuild with <code class=\"docutils literal\"><span class=\"pre\">./build.sh</span></code> and verify that your class was compiled and included properly.</p>   <h2>IDEs</h2> <p>Many devs use an IDE to work on Java projects and despite OpenTSDB's non-java-standard directory layout, working with an IDE is pretty easy. Here are some steps to get up and running with Eclipse though they should work with other environments. This example assumes you're using Eclipse.</p> <ul class=\"simple\"> <li>Clone the GIT repo to a location such as <code class=\"docutils literal\"><span class=\"pre\">/home/$USER/opentsdb</span></code>\n</li> <li>Build the repo with <code class=\"docutils literal\"><span class=\"pre\">./build.sh</span></code> from the directory</li> <li>Fire up Eclipse or your favorite IDE</li> <li>Create a new Java project with a name like <code class=\"docutils literal\"><span class=\"pre\">opentsdb_dev</span></code> so that it winds up in <code class=\"docutils literal\"><span class=\"pre\">/home/$USER/opentsdb_dev</span></code>\n</li> <li>Your dev directory should now have a <code class=\"docutils literal\"><span class=\"pre\">./src</span></code> directory</li> <li>Create a <code class=\"docutils literal\"><span class=\"pre\">net</span></code> directory under <code class=\"docutils literal\"><span class=\"pre\">./src</span></code> so that you have <code class=\"docutils literal\"><span class=\"pre\">./src/net</span></code> (some IDEs may create a <code class=\"docutils literal\"><span class=\"pre\">./src/java</span></code> dir, so add <code class=\"docutils literal\"><span class=\"pre\">./src/java/net</span></code>)</li> <li>Create a symlink to the GIT repo's <code class=\"docutils literal\"><span class=\"pre\">./src</span></code> directory from <code class=\"docutils literal\"><span class=\"pre\">./src/net/opentsdb</span></code>. E.g. <code class=\"docutils literal\"><span class=\"pre\">ln</span> <span class=\"pre\">-s</span> <span class=\"pre\">/home/$USER/opentsdb/src</span> <span class=\"pre\">/home/$USER/opentsdb_dev/src/net/opentdsb</span></code>\n</li> <li>Also, create a <code class=\"docutils literal\"><span class=\"pre\">tsd</span></code> directory under <code class=\"docutils literal\"><span class=\"pre\">./src</span></code> so that you have <code class=\"docutils literal\"><span class=\"pre\">./src/tsd</span></code>\n</li> <li>Create a symlink to the GIT repo's <code class=\"docutils literal\"><span class=\"pre\">./src/tsd/client</span></code> directory from <code class=\"docutils literal\"><span class=\"pre\">./src/tsd/client</span></code>. E.g. <code class=\"docutils literal\"><span class=\"pre\">ln</span> <span class=\"pre\">-s</span> <span class=\"pre\">/home/$USER/opentsdb/src/tsd/client</span> <span class=\"pre\">/home/$USER/opentsdb_dev/src/tsd/client</span></code>\n</li> <li>If your IDE didn't, create a <code class=\"docutils literal\"><span class=\"pre\">./test</span></code> directory under your dev project folder. This will be used for unit tests.</li> <li>Add a <code class=\"docutils literal\"><span class=\"pre\">net</span></code> directory under <code class=\"docutils literal\"><span class=\"pre\">./test</span></code> so you have <code class=\"docutils literal\"><span class=\"pre\">./test/net</span></code>\n</li> <li>Create a symlink to the GIT repo's <code class=\"docutils literal\"><span class=\"pre\">./test</span></code> directory from <code class=\"docutils literal\"><span class=\"pre\">./test/net/opentsdb</span></code>. E.g. <code class=\"docutils literal\"><span class=\"pre\">ln</span> <span class=\"pre\">-s</span> <span class=\"pre\">/home/$USER/opentsdb/test</span> <span class=\"pre\">/home/$USER/opentsdb_dev/test/net/opentdsb</span></code>\n</li> <li>Refresh the directory lists in Eclipse and you should see all of the source files</li> <li>Right click the <code class=\"docutils literal\"><span class=\"pre\">net.opentsdb.tsd.client</span></code> package under SRC and select <code class=\"docutils literal\"><span class=\"pre\">Build</span> <span class=\"pre\">Path</span></code> then <code class=\"docutils literal\"><span class=\"pre\">Exclude</span></code> from the menu</li> <li>Now add the downloaded dependencies by clicking Project -&gt; Properties, click the <code class=\"docutils literal\"><span class=\"pre\">Java</span> <span class=\"pre\">Build</span> <span class=\"pre\">Path</span></code> menu item and click <code class=\"docutils literal\"><span class=\"pre\">Add</span> <span class=\"pre\">External</span> <span class=\"pre\">JARs</span></code> button.</li> <li>Do that for each of the dependencies that were downloaded by the build script</li> <li>Copy the file <code class=\"docutils literal\"><span class=\"pre\">./build/src/BuildData.java</span></code> from the GIT repo, post build, to your <code class=\"docutils literal\"><span class=\"pre\">./src/net/opentsdb/</span></code> directory</li> <li>Now click Run (or Debug) -&gt; Manage Configurations</li> <li>Under Java Application, right click and select New from the pop-up</li> <li>Under the Main tab, brows to your <code class=\"docutils literal\"><span class=\"pre\">opentsdb_dev</span></code> project</li> <li>For the Main Class, search for <code class=\"docutils literal\"><span class=\"pre\">net.opentsdb.tools.TSDMain</span></code>\n</li> <li>Under Arguments, add the runtime arguments to select your Zookeeper quorum and the static and cache directories</li> <li>Run or Debug it and hopefully it worked</li> <li>Now edit away and when you're ready to publish changes, follow the directions above about modifying the build system (if necessary), publish to your own GitHub fork, and issue a pull request.</li> </ul> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p>This won't compile the GWT UI. If you want to do UI work and have made changes, recompile OpenTSDB or export it as a JAR from your IDE, then execute the following command (assuming the directory structure above):</p> <pre data-language=\"python\">java -cp ``&lt;PATH_TO&gt;gwt-dev-2.4.0.jar;&lt;PATH_TO&gt;gwt-user-2.4.0.jar;&lt;PATH_TO&gt;tsdb-1.1.0.jar;/home/$USER/opentsdb/src/net/opentsdb;/home/$USER/opentsdb/src`` com.google.gwt.dev.Compiler -ea -war &lt;PATH_TO_STATIC_DIRECTORY&gt; tsd.Queryui\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/development/development.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/development/development.html</a>\n  </p>\n</div>\n","api_http/serializers/index":"<h1>HTTP Serializers</h1> <p>OpenTSDB supports common data formats via Serializers, plugins that can parse different data formats from an HTTP request and return data in the same format in an HTTP response. Below is a list of formatters included with OpenTSDB, descriptions and a list of formatter specific parameters.</p> <ul class=\"simple\"> <li>\n<a class=\"reference internal\" href=\"json\"><em>JSON Serializer</em></a> - The default formatter for OpenTSDB handles parsing JSON requests and returns all data as JSON.</li> </ul> <p>Please see <a class=\"reference internal\" href=\"../index\"><em>HTTP API</em></a> for details on selecting a serializer.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/serializers/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/serializers/index.html</a>\n  </p>\n</div>\n","api_http/deprecated":"<h1>Deprecated HTTP API</h1> <p>Version 1.0 of OpenTSDB included a rudimentary HTTP API that allowed for querying data, suggesting metric or tag names and a means of accessing static files. The 1.0 API has been carried over to 2.0 for backwards compatibility though most of the calls have been deprecated. Below is a list of the different endpoints and how to use them.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Version 3.0 may discard these deprecated methods so if you are developing tools against the HTTP API, make sure to use the 2.0 version.</p> </div> <p>If an endpoint is marked as (<strong>Deprecated</strong>) below, it should not be used for future development work.</p>  <h2>Generalities</h2> <p>Most of the endpoints can return data in one or more of the following formats:</p> <ul class=\"simple\"> <li>Plain Test - Or ASCII, the default for many requests will return a simple page of data with the Content-Type <code class=\"docutils literal\"><span class=\"pre\">text/plain</span></code>\n</li> <li>HTML - If a request is bad or there was an exception, the response will often be in HTML, hard-coded and not using templates</li> <li>JSON - Many calls can respond in a JSON format when the <code class=\"docutils literal\"><span class=\"pre\">json</span></code> query string parameter is appended</li> <li>PNG - Some requests, including exceptions and errors, can generate an image file. In these cases, an error is sent to GnuPlot and the resulting empty graph with a title consisting of the message is returned. Append the parameter <code class=\"docutils literal\"><span class=\"pre\">png</span></code> to the query string.</li> </ul> <p>The correct Content-Type is returned for each response, e.g. <code class=\"docutils literal\"><span class=\"pre\">text/html;</span> <span class=\"pre\">charset=UTF-8</span></code> for HTML, <code class=\"docutils literal\"><span class=\"pre\">application/json</span></code> for JSON and <code class=\"docutils literal\"><span class=\"pre\">image/png</span></code> for images.</p> <p>Selecting a different output format is done with the <code class=\"docutils literal\"><span class=\"pre\">png</span></code> or <code class=\"docutils literal\"><span class=\"pre\">json</span></code> query string parameter. The value for the parameter is ignored. For example you can request <code class=\"docutils literal\"><span class=\"pre\">http://localhost:4242/suggest?type=metrics&amp;q=sys&amp;json</span></code> to return JSON data.</p>   <h2>/</h2> <p>Requests the root which is the GWT generated OpenTSDB GUI. This endpoint only returns HTML and cannot return other data.</p>   <h2>/aggregators (<strong>Deprecated</strong>)</h2> <p>Returns a list of available aggregation functions in JSON format only. Other formats are ignored. This method does not accept any query string parameters.</p> <p>Example Request:</p> <pre data-language=\"python\">http://localhost:4242/aggregators\n</pre>\n <p>Example Response:</p> <pre data-language=\"python\">[\"min\",\"sum\",\"max\",\"avg\"]\n</pre>\n   <h2>/diediedie (<strong>Deprecated</strong>)</h2> <p>Accessing this endpoint causes the TSD to perform a graceful shutdown and exit. A graceful shutdown prevents data loss by flushing all the buffered edits to HBase before exiting. The endpoint does not return any data and does not accept any parameters.</p>   <h2>/dropcaches (<strong>Deprecated</strong>)</h2> <p>Clears all internal caches such as the UID to name and name to UID maps. It should be used if you have renamed a metric, tagk or tagv.</p>   <h2>/logs (<strong>Deprecated</strong>)</h2> <p>Returns the latest lines logged by the TSD internally, returning the most recent entries first. OpenTSDB uses LogBack and the <code class=\"docutils literal\"><span class=\"pre\">src/logback.xml</span></code> file must have a Cyclic Buffer appender configured for this endpoint to function. The XML configuration determines how many lines will be returned with each call. Output defaults to plain text with message components separated by tabs, or it can be returned as JSON with the proper query string.</p> <p>This endpoint can also change the logging level of ______ at runtime. The query string parameter to use is <code class=\"docutils literal\"><span class=\"pre\">level=&lt;logging_level&gt;</span></code>. For example, you can call <code class=\"docutils literal\"><span class=\"pre\">http://localhost:4242/logs?level=INFO</span></code> to set the log level to <code class=\"docutils literal\"><span class=\"pre\">INFO</span></code>. Valid parameter values are (from the most verbose to the least): <code class=\"docutils literal\"><span class=\"pre\">ALL</span></code> <code class=\"docutils literal\"><span class=\"pre\">TRACE</span></code> <code class=\"docutils literal\"><span class=\"pre\">DEBUG</span></code> <code class=\"docutils literal\"><span class=\"pre\">INFO</span></code> <code class=\"docutils literal\"><span class=\"pre\">WARN</span></code> <code class=\"docutils literal\"><span class=\"pre\">ERROR</span></code> <code class=\"docutils literal\"><span class=\"pre\">OFF</span></code> (names are case insensitive). Note that this method does not change the <code class=\"docutils literal\"><span class=\"pre\">logback.xml</span></code> configuration file and restarting the TSD will reload from that file.</p>   <h2>/q (<strong>Deprecated</strong>)</h2> <p>Queries the TSD for data.</p>   <h2>/s</h2> <p>Serves static files, such as JavaScript generated by the GWT compiler or favicon.ico. The TSD needs a <code class=\"docutils literal\"><span class=\"pre\">--staticroot</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tsd.http.staticroot</span></code> argument to start. This argument is the path to a directory that contains the files served by this end point.</p> <p>When a request for <code class=\"docutils literal\"><span class=\"pre\">GET</span> <span class=\"pre\">/s/queryui.nocache.js</span></code> comes in, for instance, the file <code class=\"docutils literal\"><span class=\"pre\">${staticroot}/queryui.nocache.js</span></code> is sent to the browser.</p> <p>Note: The TSD will allow clients to cache static files for 1 year by default, and will report the age of the file on disk. If the file name contains nocache, then the TSD will tell clients to not cache the file (this idiom is used by GWT).</p>   <h2>/stats (<strong>Deprecated</strong>)</h2> <p>Returns statistics about the running TSD</p>   <h2>/suggest (<strong>Deprecated</strong>)</h2> <p>Used for auto-complete calls to match metrics, tag names or tag values on the given string. Returns JSON data only.</p> <p>Parameters:</p> <ul class=\"simple\"> <li>type - The type of value to suggest. Must be either <code class=\"docutils literal\"><span class=\"pre\">metrics</span></code> for metrics, <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> for tag names or <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> for tag values.</li> <li>q - The string to match on. The match is case-sensitive and only matches on the first characters of each type of data. For example, <code class=\"docutils literal\"><span class=\"pre\">type=metrics&amp;q=sys</span></code> would only return the names of metrics that start with <code class=\"docutils literal\"><span class=\"pre\">sys</span></code> such as <code class=\"docutils literal\"><span class=\"pre\">sys.cpu.0.system</span></code>\n</li> <li>max - An optional maximum number of results to return. The default is 25 and given values must be greater than 0.</li> </ul> <p>Both parameters are required or you will receive an exception.</p> <p>Example Request:</p> <pre data-language=\"python\">http://localhost:4242/suggest?type=metrics&amp;q=df\n</pre>\n <p>Example Response:</p> <pre data-language=\"python\">[\n  \"df.1kblocks.free\",\n  \"df.1kblocks.total\",\n  \"df.1kblocks.used\",\n  \"df.inodes.free\",\n  \"df.inodes.total\",\n  \"df.inodes.used\"\n]\n</pre>\n   <h2>/version (<strong>Deprecated</strong>)</h2> <p>Returns version information about the build of the running TSD. Can be returned in either the default of plain-text or JSON.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/deprecated.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/deprecated.html</a>\n  </p>\n</div>\n","api_http/aggregators":"<h1>/api/aggregators</h1> <p>This endpoint simply lists the names of implemented aggregation functions used in timeseries queries.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>This endpoint does not require any parameters via query string or body.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/aggregators\n</pre>\n </div>   <h2>Response</h2> <p>The response is an array of strings that are the names of aggregation functions that can be used in a timeseries query.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">[\n  \"min\",\n  \"sum\",\n  \"max\",\n  \"avg\",\n  \"dev\"\n]\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/aggregators.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/aggregators.html</a>\n  </p>\n</div>\n","api_http/annotation/index":"<h1>/api/annotation</h1> <p>These endpoints provides a means of adding, editing or deleting annotations stored in the OpenTSDB backend. Annotations are very basic objects used to record a note of an arbitrary event at some point, optionally associated with a timeseries. Annotations are not meant to be used as a tracking or event based system, rather they are useful for providing links to such systems by displaying a notice on graphs or via API query calls.</p> <p>When creating, modifying or deleting annotations, all changes will be propagated to the search plugin if configured.</p>  <h2>Annotation API Endpoints</h2> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"bulk\">/api/annotation/bulk</a></li> </ul> </div> <p>The default <code class=\"docutils literal\"><span class=\"pre\">/annotation</span></code> endpoint deals with one notation at a time. The <code class=\"docutils literal\"><span class=\"pre\">/annotation/bulk</span></code> endpoint allows for adding or updating multiple annotations at a time.</p>   <h2>Verbs</h2> <ul class=\"simple\"> <li>GET - Retrieve a single annotation</li> <li>POST - Create or modify an annotation</li> <li>PUT - Create or replace an annotation</li> <li>DELETE - Delete an annotation</li> </ul>   <h2>Requests</h2> <p>All annotations are identified by the <code class=\"docutils literal\"><span class=\"pre\">startTime</span></code> field and optionally the <code class=\"docutils literal\"><span class=\"pre\">tsuid</span></code> field. Each note can be global, meaning it is associated with all timeseries, or it can be local, meaning it's associated with a specific tsuid. If the tsuid is not supplied or has an empty value, the annotation is considered to be a global note.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>startTime</td> <td>Integer</td> <td>Required</td> <td>A Unix epoch timestamp, in seconds, marking the time when the annotation event should be recorded</td> <td> </td> <td>start_time</td> <td>RW</td> <td>1369141261</td> </tr> <tr class=\"row-odd\">\n<td>endTime</td> <td>Integer</td> <td>Optional</td> <td>An optional end time for the event if it has completed or been resolved</td> <td>0</td> <td>end_time</td> <td>RW</td> <td>1369141262</td> </tr> <tr class=\"row-even\">\n<td>tsuid</td> <td>String</td> <td>Optional</td> <td>A TSUID if the annotation is associated with a timeseries. This may be null or empty if the note was for a global event</td> <td> </td> <td>tsuid</td> <td>RW</td> <td>000001000001000001</td> </tr> <tr class=\"row-odd\">\n<td>description</td> <td>String</td> <td>Optional</td> <td>A brief description of the event. As this may appear on GnuPlot graphs, the description should be very short, ideally less than 25 characters.</td> <td> </td> <td>description</td> <td>RW</td> <td>Network Outage</td> </tr> <tr class=\"row-even\">\n<td>notes</td> <td>String</td> <td>Optional</td> <td>Detailed notes about the event</td> <td> </td> <td>notes</td> <td>RW</td> <td>Switch #5 died and was replaced</td> </tr> <tr class=\"row-odd\">\n<td>custom</td> <td>Map</td> <td>Optional</td> <td>A key/value map to store custom fields and values</td> <td>null</td> <td> </td> <td>RW</td> <td><em>See Below</em></td> </tr> </tbody> </table> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Custom fields cannot be passed via query string. You must use the <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> verbs.</p> </div> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">If your request uses <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code>, any fields that you do not supply with the request will be overwritten with their default values. For example, the <code class=\"docutils literal\"><span class=\"pre\">description</span></code> field will be set to an empty string and the <code class=\"docutils literal\"><span class=\"pre\">custom</span></code> field will be reset to <code class=\"docutils literal\"><span class=\"pre\">null</span></code>.</p> </div> <div class=\"section\" id=\"example-get-request\"> <h3>Example GET Request</h3> <pre data-language=\"python\">http://localhost:4242/api/annotation?start_time=1369141261&amp;tsuid=000001000001000001\n</pre>\n </div> <div class=\"section\" id=\"example-post-request\"> <h3>Example POST Request</h3> <pre data-language=\"javascript\">{\n  \"startTime\":\"1369141261\",\n  \"tsuid\":\"000001000001000001\",\n  \"description\": \"Testing Annotations\",\n  \"notes\": \"These would be details about the event, the description is just a summary\",\n  \"custom\": {\n    \"owner\": \"jdoe\",\n    \"dept\": \"ops\"\n  }\n}\n</pre>\n </div>   <h2>Response</h2> <p>A successful response to a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code>, <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> request will return the full object with the requested changes. Successful <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> calls will return with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no body content. When modifying data, if no changes were present, i.e. the call did not provide any data to store, the response will be a <code class=\"docutils literal\"><span class=\"pre\">304</span></code> without any body content. If the requested annotation did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"tsuid\": \"000001000001000001\",\n  \"description\": \"Testing Annotations\",\n  \"notes\": \"These would be details about the event, the description is just a summary\",\n  \"custom\": {\n    \"owner\": \"jdoe\",\n    \"dept\": \"ops\"\n  },\n  \"endTime\": 0,\n  \"startTime\": 1369141261\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/annotation/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/annotation/index.html</a>\n  </p>\n</div>\n","api_http/config/index":"<h1>/api/config</h1> <p>This endpoint returns information about the running configuration of the TSD. It is read only and cannot be used to set configuration options.</p>  <h2>Conf API Endpoints</h2> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"filters\">/api/config/filters</a></li> </ul> </div>   <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>This endpoint does not require any parameters via query string or body.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/config\n</pre>\n </div>   <h2>Response</h2> <p>The response is a hash map of configuration properties and values.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"tsd.search.elasticsearch.tsmeta_type\": \"tsmetadata\",\n  \"tsd.storage.flush_interval\": \"1000\",\n  \"tsd.network.tcp_no_delay\": \"true\",\n  \"tsd.search.tree.indexer.enable\": \"true\",\n  \"tsd.http.staticroot\": \"/usr/local/opentsdb/staticroot/\",\n  \"tsd.network.bind\": \"0.0.0.0\",\n  \"tsd.network.worker_threads\": \"\",\n  \"tsd.storage.hbase.zk_quorum\": \"localhost\",\n  \"tsd.network.port\": \"4242\",\n  \"tsd.rpcplugin.DummyRPCPlugin.port\": \"42\",\n  \"tsd.search.elasticsearch.hosts\": \"localhost\",\n  \"tsd.network.async_io\": \"true\",\n  \"tsd.rtpublisher.plugin\": \"net.opentsdb.tsd.RabbitMQPublisher\",\n  \"tsd.search.enableindexer\": \"false\",\n  \"tsd.rtpublisher.rabbitmq.user\": \"guest\",\n  \"tsd.search.enable\": \"false\",\n  \"tsd.search.plugin\": \"net.opentsdb.search.ElasticSearch\",\n  \"tsd.rtpublisher.rabbitmq.hosts\": \"localhost\",\n  \"tsd.core.tree.enable_processing\": \"false\",\n  \"tsd.stats.canonical\": \"true\",\n  \"tsd.http.cachedir\": \"/tmp/opentsdb/\",\n  \"tsd.http.request.max_chunk\": \"16384\",\n  \"tsd.http.show_stack_trace\": \"true\",\n  \"tsd.core.auto_create_metrics\": \"true\",\n  \"tsd.storage.enable_compaction\": \"true\",\n  \"tsd.rtpublisher.rabbitmq.pass\": \"guest\",\n  \"tsd.core.meta.enable_tracking\": \"true\",\n  \"tsd.mq.enable\": \"true\",\n  \"tsd.rtpublisher.rabbitmq.vhost\": \"/\",\n  \"tsd.storage.hbase.data_table\": \"tsdb\",\n  \"tsd.storage.hbase.uid_table\": \"tsdb-uid\",\n  \"tsd.http.request.enable_chunked\": \"true\",\n  \"tsd.core.plugin_path\": \"/usr/local/opentsdb/plugins\",\n  \"tsd.storage.hbase.zk_basedir\": \"/hbase\",\n  \"tsd.rtpublisher.enable\": \"false\",\n  \"tsd.rpcplugin.DummyRPCPlugin.hosts\": \"localhost\",\n  \"tsd.storage.hbase.tree_table\": \"tsdb-tree\",\n  \"tsd.network.keep_alive\": \"true\",\n  \"tsd.network.reuse_address\": \"true\",\n  \"tsd.rpc.plugins\": \"net.opentsdb.tsd.DummyRpcPlugin\"\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/config/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/config/index.html</a>\n  </p>\n</div>\n","api_http/dropcaches":"<h1>/api/dropcaches</h1> <p>This endpoint purges the in-memory data cached in OpenTSDB. This includes all UID to name and name to UID maps for metrics, tag names and tag values.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">This endpoint does not purge the on-disk temporary cache where graphs and other files are stored.</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>This endpoint does not require any parameters via query string or body.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/dropcaches\n</pre>\n </div>   <h2>Response</h2> <p>The response is a hash map of information. Unless something goes wrong, this should always result in a <code class=\"docutils literal\"><span class=\"pre\">status</span></code> of <code class=\"docutils literal\"><span class=\"pre\">200</span></code> and a message of <code class=\"docutils literal\"><span class=\"pre\">Caches</span> <span class=\"pre\">dropped</span></code>.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"message\": \"Caches dropped\",\n  \"status\": \"200\"\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/dropcaches.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/dropcaches.html</a>\n  </p>\n</div>\n","user_guide/utilities/tcollector":"<h1>TCollector</h1> <p><a class=\"reference external\" href=\"https://github.com/OpenTSDB/tcollector/\">tcollector</a> is a client-side process that gathers data from local collectors and pushes the data to OpenTSDB. You run it on all your hosts, and it does the work of sending each host's data to the TSD.</p> <p>OpenTSDB is designed to make it easy to collect and write data to it. It has a simple protocol, simple enough for even a shell script to start sending data. However, to do so reliably and consistently is a bit harder. What do you do when your TSD server is down? How do you make sure your collectors stay running? This is where tcollector comes in.</p> <p>Tcollector does several things for you:</p> <ul class=\"simple\"> <li>Runs all of your data collectors and gathers their data</li> <li>Does all of the connection management work of sending data to the TSD</li> <li>You don't have to embed all of this code in every collector you write</li> <li>Does de-duplication of repeated values</li> <li>Handles all of the wire protocol work for you, as well as future enhancements</li> </ul>  <h2>Deduplication</h2> <p>Typically you want to gather data about everything in your system. This generates a lot of datapoints, the majority of which don't change very often over time (if ever). However, you want fine-grained resolution when they do change. Tcollector remembers the last value and timestamp that was sent for all of the time series for all of the collectors it manages. If the value doesn't change between sample intervals, it suppresses sending that datapoint. Once the value does change (or 10 minutes have passed), it sends the last suppressed value and timestamp, plus the current value and timestamp. In this way all of your graphs and such are correct. Deduplication typically reduces the number of datapoints TSD needs to collect by a large fraction. This reduces network load and storage in the backend. A future OpenTSDB release however will improve on the storage format by using RLE (among other things), making it essentially free to store repeated values.</p>   <h2>Collecting lots of metrics with tcollector</h2> <p>Collectors in tcollector can be written in any language. They just need to be executable and output the data to stdout. Tcollector will handle the rest. The collectors are placed in the <code class=\"docutils literal\"><span class=\"pre\">collectors</span></code> directory. Tcollector iterates over every directory named with a number in that directory and runs all the collectors in each directory. If you name the directory <code class=\"docutils literal\"><span class=\"pre\">60</span></code>, then tcollector will try to run every collector in that directory every 60 seconds. The shortest supported interval is 15 seconds, you should use a long-running collector in the 0 folder for intervals shorter than 15 seconds. TCollector will sleep for 15 seconds after each time it runs the collectors so intervals of 15 seconds are the only actually supported intervals. For example, this would allow you to run a collector every 15, 30, 45, 60, 75, or 90 seconds, but not 80 or 55 seconds. Use the directory <code class=\"docutils literal\"><span class=\"pre\">0</span></code> for any collectors that are long-lived and run continuously. Tcollector will read their output and respawn them if they die. Generally you want to write long-lived collectors since that has less overhead. OpenTSDB is designed to have lots of datapoints for each metric (for most metrics we send datapoints every 15 seconds).</p> <p>If there any non-numeric named directories in the <code class=\"docutils literal\"><span class=\"pre\">collectors</span></code> directory, then they are ignored. We've included a <code class=\"docutils literal\"><span class=\"pre\">lib</span></code> and <code class=\"docutils literal\"><span class=\"pre\">etc</span></code> directory for library and config data used by all collectors.</p>   <h2>Installation of tcollector</h2> <p>You need to clone tcollector from GitHub:</p> <pre data-language=\"python\">git clone git://github.com/OpenTSDB/tcollector.git\n</pre>\n <p>and edit 'tcollector/startstop' script to set following variable: <code class=\"docutils literal\"><span class=\"pre\">TSD_HOST=dns.name.of.tsd</span></code></p> <p>To avoid having to run <code class=\"docutils literal\"><span class=\"pre\">mkmetric</span></code> for every metric that tcollector tracks you can to start TSD with the <code class=\"docutils literal\"><span class=\"pre\">--auto-metric</span></code> flag. This is useful to get started quickly, but it's not recommended to keep this flag in the long term, to avoid accidental metric creation.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/utilities/tcollector.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/utilities/tcollector.html</a>\n  </p>\n</div>\n","user_guide/query/examples":"<h1>Query Examples</h1> <p>The following is a list of example queries using an example data set. We'll illustrate a number of common query types that may be encountered so you can get an understanding of how the query system works. Each time series in the example set has only a single data point stored and the UIDs have been truncated to a single byte to make it easier to read. The example queries are all <em>Metric</em> queries from the HTTP API and only show the <code class=\"docutils literal\"><span class=\"pre\">m=</span></code> component. See <a class=\"reference internal\" href=\"../../api_http/query/index\"><em>/api/query</em></a> for details. If you are using a CLI tool, the query format will differ slightly so read the documentation for the particular command.</p>  <h2>Sample Data</h2> <p><strong>Time Series</strong></p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"20%\"> <col width=\"50%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">TS#</th> <th class=\"head\">Metric</th> <th class=\"head\">Tags</th> <th class=\"head\">TSUID</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>1</td> <td>sys.cpu.system</td> <td>dc=dal host=web01</td> <td>0102040101</td> </tr> <tr class=\"row-odd\">\n<td>2</td> <td>sys.cpu.system</td> <td>dc=dal host=web02</td> <td>0102040102</td> </tr> <tr class=\"row-even\">\n<td>3</td> <td>sys.cpu.system</td> <td>dc=dal host=web03</td> <td>0102040103</td> </tr> <tr class=\"row-odd\">\n<td>4</td> <td>sys.cpu.system</td> <td>host=web01</td> <td>010101</td> </tr> <tr class=\"row-even\">\n<td>5</td> <td>sys.cpu.system</td> <td>host=web01 owner=jdoe</td> <td>0101010306</td> </tr> <tr class=\"row-odd\">\n<td>6</td> <td>sys.cpu.system</td> <td>dc=lax host=web01</td> <td>0102050101</td> </tr> <tr class=\"row-even\">\n<td>7</td> <td>sys.cpu.system</td> <td>dc=lax host=web02</td> <td>0102050102</td> </tr> <tr class=\"row-odd\">\n<td>8</td> <td>sys.cpu.user</td> <td>dc=dal host=web01</td> <td>0202040101</td> </tr> <tr class=\"row-even\">\n<td>9</td> <td>sys.cpu.user</td> <td>dc=dal host=web02</td> <td>0202040102</td> </tr> </tbody> </table> <p><strong>UIDs</strong></p> <table class=\"docutils\"> <colgroup> <col width=\"50%\"> <col width=\"50%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">UID</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td><strong>Metrics</strong></td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>cpu.system</td> <td>01</td> </tr> <tr class=\"row-even\">\n<td>cpu.user</td> <td>02</td> </tr> <tr class=\"row-odd\">\n<td><strong>Tagks</strong></td> <td> </td> </tr> <tr class=\"row-even\">\n<td>host</td> <td>01</td> </tr> <tr class=\"row-odd\">\n<td>dc</td> <td>02</td> </tr> <tr class=\"row-even\">\n<td>owner</td> <td>03</td> </tr> <tr class=\"row-odd\">\n<td><strong>Tagvs</strong></td> <td> </td> </tr> <tr class=\"row-even\">\n<td>web01</td> <td>01</td> </tr> <tr class=\"row-odd\">\n<td>web02</td> <td>02</td> </tr> <tr class=\"row-even\">\n<td>web03</td> <td>03</td> </tr> <tr class=\"row-odd\">\n<td>dal</td> <td>04</td> </tr> <tr class=\"row-even\">\n<td>lax</td> <td>05</td> </tr> <tr class=\"row-odd\">\n<td>doe</td> <td>06</td> </tr> </tbody> </table> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">This isn't necesarily the best way to setup your metrics and tags, rather it's meant to be illustrative of how the query system works. In particular, TS #4 and 5, while legitimate timeseries, may screw up your queries unless you know how they work. In general, try to maintain the same number and type of tags for each timeseries.</p> </div>   <h2>Under the Hood</h2> <p>You may want to read up on how OpenTSDB stores timeseries data here: <a class=\"reference internal\" href=\"../backends/index\"><em>Storage</em></a>. Otherwise, remember that each row in storage has a unique key formatted:</p> <pre data-language=\"python\">&lt;metricID&gt;&lt;normalized_timestamp&gt;&lt;tagkID1&gt;&lt;tagvID1&gt;[...&lt;tagkIDN&gt;&lt;tagvIDN&gt;]\n</pre>\n <p>The data table above would be stored as:</p> <pre data-language=\"python\">01&lt;ts&gt;0101\n01&lt;ts&gt;01010306\n01&lt;ts&gt;02040101\n01&lt;ts&gt;02040102\n01&lt;ts&gt;02040103\n01&lt;ts&gt;02050101\n01&lt;ts&gt;02050102\n02&lt;ts&gt;02040101\n02&lt;ts&gt;02040102\n</pre>\n <p>When you query OpenTSDB, here's what happens under the hood.</p> <ul class=\"simple\"> <li>The query is parsed and verified to make sure that the format is correct and that the metrics, tag names and tag values exist. If a single metric, tag name or value doesn't exist in the system, it will kick back an error.</li> <li>Then it sets up a scanner for the underlying storage system.<ul> <li>If the query doesn't have any tags or tag values, then it will grab any rows of data that match <code class=\"docutils literal\"><span class=\"pre\">&lt;metricID&gt;&lt;timestamp&gt;</span></code>, so if you have a ton of time series for a particular metric, this could be many, many rows.</li> <li>If the query does have one or more tags defined, then it will still scan all of the rows matching <code class=\"docutils literal\"><span class=\"pre\">&lt;metricID&gt;&lt;timestamp&gt;</span></code>, but also perform a regex to return only the rows that contain the requested tag.</li> </ul> </li> <li>Once all of the data has been returned, OpenTSDB organizes it into groups, if required</li> <li>If downsampling was requested, each individual time series is down sampled into smaller time spans using the proper aggregator</li> <li>Then each group of data is aggregated using the specific aggregation function</li> <li>If the <code class=\"docutils literal\"><span class=\"pre\">rate</span></code> flag was detected, each aggregate will then be adjusted to get the rate.</li> <li>Results are returned to the caller</li> </ul>   <h2>Query 1 - All Time Series for a Metric</h2> <pre data-language=\"python\">m=sum:cpu.system\n</pre>\n <p>This is the simplest query to make. TSDB will setup a scanner to fetch all data points for the metric UID <code class=\"docutils literal\"><span class=\"pre\">01</span></code> between <em>&lt;start&gt;</em> and <em>&lt;end&gt;</em>. The result will be the a single dataset with time series #1 through #7 summed together. If you have thousands of unique tag combinations for a given metric, they will all be added together into one series.</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {},\n    \"aggregated_tags\": [\n      \"host\"\n    ],\n    \"tsuids\": [\n      \"010101\",\n      \"0101010306\",\n      \"0102050101\",\n      \"0102040101\",\n      \"0102040102\",\n      \"0102040103\",\n      \"0102050102\"\n    ],\n    \"dps\": {\n      \"1346846400\": 130.29999923706055\n    }\n  }\n]\n</pre>\n   <h2>Query 2 - Filter on a Tag</h2> <p>Usually aggregating all of the time series for a metric isn't particularly useful. Instead we can drill down a little by filtering for time series that contain a specific tagk/tagv pair combination. Simply put the pair in curly braces:</p> <pre data-language=\"python\">m=sum:cpu.system{host=web01}\n</pre>\n <p>This will return an aggregate of time series #1, #4, #5 and #6 since they're the only series that include <code class=\"docutils literal\"><span class=\"pre\">host=web01</span></code>.</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"host\": \"web01\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"010101\",\n      \"0101010306\",\n      \"0102040101\",\n      \"0102050101\"\n    ],\n    \"dps\": {\n      \"1346846400\": 63.59999942779541\n    }\n  }\n]\n</pre>\n   <h2>Query 3 - Specific Time Series</h2> <p>What if you want a specific timeseries? You have to include every tag and coresponding value.</p> <pre data-language=\"python\">m=sum:cpu.system{host=web01,dc=lax}\n</pre>\n <p>This will return the data from timeseries #6 only.</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"dc\": \"lax\",\n      \"host\": \"web01\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"0102050101\"\n    ],\n    \"dps\": {\n      \"1346846400\": 15.199999809265137\n    }\n  }\n]\n</pre>\n <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">This is where a tagging scheme will stand or fall. Let's say you want to get just the data from timeseries #4. With the current system, you are unable to. You would send in query #2 <code class=\"docutils literal\"><span class=\"pre\">m=sum:cpu.system{host=web01}</span></code> thinking that it will return just the data from #4, but as we saw, you'll get the aggregate results for #1, #4, #5 and #6. To prevent such an occurance, you would need to add another tag to #4 that differentiates it from other timeseries in the group. Or if you've already commited, you can use TSUID queries.</p> </div>   <h2>Query 4 - TSUID Query</h2> <p>If you know the exact TSUID of the timeseries that you want to retrieve, you can simply pass it in like so:</p> <pre data-language=\"python\">tsuids=sum:0102040102\n</pre>\n <p>The results will be the data points that you requested.</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"dc\": \"lax\",\n      \"host\": \"web01\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"0102050101\"\n    ],\n    \"dps\": {\n      \"1346846400\": 15.199999809265137\n    }\n  }\n]\n</pre>\n   <h2>Query 5 - Multi-TSUID Query</h2> <p>You can also aggregate multiple TSUIDs in the same query, provided they share the same metric. If you attempt to aggregate multiple metrics, the API will issue an error.</p> <pre data-language=\"python\">tsuids=sum:0102040101,0102050101\n</pre>\n <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"host\": \"web01\"\n    },\n    \"aggregated_tags\": [\n      \"dc\"\n    ],\n    \"tsuids\": [\n      \"0102040101\",\n      \"0102050101\"\n    ],\n    \"dps\": {\n      \"1346846400\": 33.19999980926514\n    }\n  }\n]\n</pre>\n   <h2>Query 6 - Grouping</h2> <pre data-language=\"python\">m=sum:cpu.system{host=*}\n</pre>\n <p>The <code class=\"docutils literal\"><span class=\"pre\">*</span></code> (asterisk) is a grouping operator that will return a data set for each unique value of the tag name given. Every timeseries that includes the given metric and the given tag name, regardless of other tags or values, will be included in the results. After the individual timeseries results are grouped, they'll be aggregated and returned.</p> <p>In this example, we will have 3 groups returned:</p> <table class=\"docutils\"> <colgroup> <col width=\"50%\"> <col width=\"50%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Group</th> <th class=\"head\">Time Series Included</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>web01</td> <td>#1, #4, #5, #6</td> </tr> <tr class=\"row-odd\">\n<td>web02</td> <td>#2, #7</td> </tr> <tr class=\"row-even\">\n<td>web03</td> <td>#3</td> </tr> </tbody> </table> <p>TSDB found 7 total timeseries that included the \"host\" tag. There were 3 unique values for that tag (web01, web02, and web03).</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"host\": \"web01\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"010101\",\n      \"0101010306\",\n      \"0102040101\",\n      \"0102050101\"\n    ],\n    \"dps\": {\n      \"1346846400\": 63.59999942779541\n    }\n  },\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"host\": \"web02\"\n    },\n    \"aggregated_tags\": [\n      \"dc\"\n    ],\n    \"tsuids\": [\n      \"0102040102\",\n      \"0102050102\"\n    ],\n    \"dps\": {\n      \"1346846400\": 24.199999809265137\n    }\n  },\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"dc\": \"dal\",\n      \"host\": \"web03\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"0102040103\"\n    ],\n    \"dps\": {\n      \"1346846400\": 42.5\n    }\n  }\n]\n</pre>\n   <h2>Query 7 - Group and Filter</h2> <p>Note that the in example #2, the <code class=\"docutils literal\"><span class=\"pre\">web01</span></code> group included the odd-ball timeseries #4 and #5. We can filter those out by specifying a second tag ala:</p> <pre data-language=\"python\">m=sum:cpu.nice{host=*,dc=dal}\n</pre>\n <p>Now we'll only get results for #1 - #3, but we lose the <code class=\"docutils literal\"><span class=\"pre\">dc=lax</span></code> values.</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"dc\": \"dal\",\n      \"host\": \"web01\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"0102040101\"\n    ],\n    \"dps\": {\n      \"1346846400\": 18\n    }\n  },\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"dc\": \"dal\",\n      \"host\": \"web02\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"0102040102\"\n    ],\n    \"dps\": {\n      \"1346846400\": 9\n    }\n  },\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"dc\": \"dal\",\n      \"host\": \"web03\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"0102040103\"\n    ],\n    \"dps\": {\n      \"1346846400\": 42.5\n    }\n  }\n]\n</pre>\n   <h2>Query 8 - Grouping With OR</h2> <p>The <code class=\"docutils literal\"><span class=\"pre\">*</span></code> operator is greedy and will return <em>all</em> values that are assigned to a tag name. If you only want a few tag values, you can use the <code class=\"docutils literal\"><span class=\"pre\">|</span></code> (pipe) operator instead.</p> <pre data-language=\"python\">m=sum:cpu.nice{host=web01|web02}\n</pre>\n <p>This will find all of the timeseries that include \"host\" values for \"web01\" OR \"web02\", then group them by value, similar to the <code class=\"docutils literal\"><span class=\"pre\">*</span></code> operator. Our groups, this time, will look like this:</p> <table class=\"docutils\"> <colgroup> <col width=\"50%\"> <col width=\"50%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Group</th> <th class=\"head\">Time Series Included</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>web01</td> <td>#1, #4, #5, #6</td> </tr> <tr class=\"row-odd\">\n<td>web02</td> <td>#2, #7</td> </tr> </tbody> </table> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"host\": \"web01\"\n    },\n    \"aggregated_tags\": [],\n    \"tsuids\": [\n      \"010101\",\n      \"0101010306\",\n      \"0102040101\",\n      \"0102050101\"\n    ],\n    \"dps\": {\n      \"1346846400\": 63.59999942779541\n    }\n  },\n  {\n    \"metric\": \"cpu.system\",\n    \"tags\": {\n      \"host\": \"web02\"\n    },\n    \"aggregated_tags\": [\n      \"dc\"\n    ],\n    \"tsuids\": [\n      \"0102040102\",\n      \"0102050102\"\n    ],\n    \"dps\": {\n      \"1346846400\": 24.199999809265137\n    }\n  }\n]\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/query/examples.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/query/examples.html</a>\n  </p>\n</div>\n","api_http/put":"<h1>/api/put</h1> <p>This endpoint allows for storing data in OpenTSDB over HTTP as an alternative to the Telnet interface. Put requests can only be performed via content associated with the POST method. The format of the content is dependent on the serializer selected. However there are some common parameters and responses as documented below.</p> <p>To save on bandwidth, the put API allows clients to store multiple data points in a single request. The data points do not have to be related in any way. Each data point is processed individually and an error with one piece of data will not affect the storing of good data. This means if your request has 100 data points and 1 of them has an error, 99 data points will still be written and one will be rejected. See the Response section below for details on determining what data point was not stored.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If the content you provide with the request cannot be parsed, such JSON content missing a quotation mark or curly brace, then all of the datapoints will be discarded. The API will return an error with details about what went wrong.</p> </div> <p>While the API does support multiple data points per request, the API will not return until every one has been processed. That means metric and tag names/values must be verified, the value parsed and the data queued for storage. If your put request has a large number of data points, it may take a long time for the API to respond, particularly if OpenTSDB has to assign UIDs to tag names or values. Therefore it is a good idea to limit the maximum number of data points per request; 50 per request is a good starting point.</p> <p>Another recommendation is to enable keep-alives on your HTTP client so that you can re-use your connection to the server every time you put data.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">When using HTTP for puts, you may need to enable support for chunks if your HTTP client automatically breaks large requests into smaller packets. For example, CURL will break up messages larger than 2 or 3 data points and by default, OpenTSDB disables chunk support. Enable it by setting <code class=\"docutils literal\"><span class=\"pre\">tsd.http.request.enable_chunked</span></code> to true in the config file.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If the <code class=\"docutils literal\"><span class=\"pre\">tsd.mode</span></code> is set to <code class=\"docutils literal\"><span class=\"pre\">ro</span></code>, the <code class=\"docutils literal\"><span class=\"pre\">/api/put</span></code> endpoint will be unavailable and all calls will return a 404 error.</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>POST</li> </ul>   <h2>Requests</h2> <p>Some query string parameters can be supplied that alter the response to a put request:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>summary</td> <td>Present</td> <td>Optional</td> <td>Whether or not to return summary information</td> <td>false</td> <td>summary</td> <td> </td> <td>/api/put?summary</td> </tr> <tr class=\"row-odd\">\n<td>details</td> <td>Present</td> <td>Optional</td> <td>Whether or not to return detailed information</td> <td>false</td> <td>details</td> <td> </td> <td>/api/put?details</td> </tr> <tr class=\"row-even\">\n<td>sync</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to wait for the data to be flushed to storage before returning the results.</td> <td>false</td> <td>sync</td> <td> </td> <td>/api/put?sync</td> </tr> <tr class=\"row-odd\">\n<td>sync_timeout</td> <td>Integer</td> <td>Optional</td> <td>A timeout, in milliseconds, to wait for the data to be flushed to storage before returning with an error. When a timeout occurs, using the <code class=\"docutils literal\"><span class=\"pre\">details</span></code> flag will tell how many data points failed and how many succeeded. <code class=\"docutils literal\"><span class=\"pre\">sync</span></code> must also be given for this to take effect. A value of 0 means the write will not timeout.</td> <td>0</td> <td>sync_timeout</td> <td> </td> <td>/api/put/?sync&amp;sync_timeout=60000</td> </tr> </tbody> </table> <p>If both <code class=\"docutils literal\"><span class=\"pre\">detailed</span></code> and <code class=\"docutils literal\"><span class=\"pre\">summary</span></code> are present in a query string, the API will respond with <code class=\"docutils literal\"><span class=\"pre\">detailed</span></code> information.</p> <p>The fields and examples below refer to the default JSON serializer.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>metric</td> <td>String</td> <td>Required</td> <td>The name of the metric you are storing</td> <td> </td> <td> </td> <td>W</td> <td>sys.cpu.nice</td> </tr> <tr class=\"row-odd\">\n<td>timestamp</td> <td>Integer</td> <td>Required</td> <td>A Unix epoch style timestamp in seconds or milliseconds. The timestamp must not contain non-numeric characters.</td> <td> </td> <td> </td> <td>W</td> <td>1365465600</td> </tr> <tr class=\"row-even\">\n<td>value</td> <td>Integer, Float, String</td> <td>Required</td> <td>The value to record for this data point. It may be quoted or not quoted and must conform to the OpenTSDB value rules: <a class=\"reference internal\" href=\"../user_guide/writing\"><em>Writing Data</em></a>\n</td> <td> </td> <td> </td> <td>W</td> <td>42.5</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Map</td> <td>Required</td> <td>A map of tag name/tag value pairs. At least one pair must be supplied.</td> <td> </td> <td> </td> <td>W</td> <td>{\"host\":\"web01\"}</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-single-data-point-put\"> <h3>Example Single Data Point Put</h3> <p>You can supply a single data point in a request:</p> <pre data-language=\"javascript\">{\n  \"metric\": \"sys.cpu.nice\",\n  \"timestamp\": 1346846400,\n  \"value\": 18,\n  \"tags\": {\n     \"host\": \"web01\",\n     \"dc\": \"lga\"\n  }\n}\n</pre>\n </div> <div class=\"section\" id=\"example-multiple-data-point-put\"> <h3>Example Multiple Data Point Put</h3> <p>Multiple data points must be encased in an array:</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"sys.cpu.nice\",\n    \"timestamp\": 1346846400,\n    \"value\": 18,\n    \"tags\": {\n       \"host\": \"web01\",\n       \"dc\": \"lga\"\n    }\n  },\n  {\n    \"metric\": \"sys.cpu.nice\",\n    \"timestamp\": 1346846400,\n    \"value\": 9,\n    \"tags\": {\n       \"host\": \"web02\",\n       \"dc\": \"lga\"\n    }\n  }\n]\n</pre>\n </div>   <h2>Response</h2> <p>By default, the put endpoint will respond with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> HTTP status code and no content if all data points were stored successfully. If one or more datapoints had an error, the API will return a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> with an error message in the content.</p> <p>For debugging purposes, you can ask for the response to include a summary of how many data points were stored successfully and failed, or get details about what data points could not be stored and why so that you can fix your client code. Also, errors with a data point will be logged in the TSD's log file so you can look there for issues.</p> <p>Fields present in <code class=\"docutils literal\"><span class=\"pre\">summary</span></code> or <code class=\"docutils literal\"><span class=\"pre\">detailed</span></code> responses include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"80%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>success</td> <td>Integer</td> <td>The number of data points that were queued successfully for storage</td> </tr> <tr class=\"row-odd\">\n<td>failed</td> <td>Integer</td> <td>The number of data points that could not be queued for storage</td> </tr> <tr class=\"row-even\">\n<td>errors</td> <td>Array</td> <td>A list of data points that failed be queued and why. Present in the <code class=\"docutils literal\"><span class=\"pre\">details</span></code> response only.</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-response-with-summary\"> <h3>Example Response with Summary</h3> <pre data-language=\"javascript\">{\n  \"failed\": 1,\n  \"success\": 0\n}\n</pre>\n </div> <div class=\"section\" id=\"example-response-with-details\"> <h3>Example Response With Details</h3> <pre data-language=\"javascript\">{\n  \"errors\": [\n    {\n      \"datapoint\": {\n        \"metric\": \"sys.cpu.nice\",\n        \"timestamp\": 1365465600,\n        \"value\": \"NaN\",\n        \"tags\": {\n          \"host\": \"web01\"\n        }\n      },\n      \"error\": \"Unable to parse value to a number\"\n    }\n  ],\n  \"failed\": 1,\n  \"success\": 0\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/put.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/put.html</a>\n  </p>\n</div>\n","api_http/serializers":"<h1>/api/serializers</h1> <p>This endpoint lists the serializer plugins loaded by the running TSD. Information given includes the name, implemented methods, content types and methods.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>No parameters are available, this is a read-only endpoint that simply returns system data.</p>   <h2>Response</h2> <p>The response is an array of serializer objects. Each object has the following fields:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Field Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>serializer</td> <td>String</td> <td>The name of the serializer, suitable for use in the query string <code class=\"docutils literal\"><span class=\"pre\">serializer=&lt;serializer_name&gt;</span></code> parameter</td> <td>xml</td> </tr> <tr class=\"row-odd\">\n<td>formatters</td> <td>Array&lt;String&gt;</td> <td>An array of methods or endpoints that the serializer implements to convert response data. These usually map to an endpoint such as <code class=\"docutils literal\"><span class=\"pre\">/api/suggest</span></code> mapping to <code class=\"docutils literal\"><span class=\"pre\">Suggest</span></code>. If the serializer does not implement a certain method, the default formatter will respond. Each name also ends with the API version supported, e.g. <code class=\"docutils literal\"><span class=\"pre\">V1</span></code> will support version 1 API calls.</td> <td>\"Error\",\"Suggest\"</td> </tr> <tr class=\"row-even\">\n<td>parsers</td> <td>Array&lt;String&gt;</td> <td>An array of methods or endpoints that the serializer implements to parse user input in the HTTP request body. These usually map to an endpoint such as <code class=\"docutils literal\"><span class=\"pre\">/api/suggest</span></code> will map to <code class=\"docutils literal\"><span class=\"pre\">Suggest</span></code>. If a serializer does not implement a parser, the default serializer will be used. Each name also ends with the API version supported, e.g. <code class=\"docutils literal\"><span class=\"pre\">V1</span></code> will support version 1 API calls.</td> <td>\"Suggest\",\"Put\"</td> </tr> </tbody> </table> <p>This endpoint should always return data with the JSON serializer as the default. If you think the TSD should have other formatters listed, check the plugin documentation to make sure you have the proper plugin and it's located in the right directory.</p>   <h2>Example Response</h2> <pre data-language=\"javascript\">[\n  {\n    \"formatters\": [\n      \"SuggestV1\",\n      \"SerializersV1\",\n      \"ErrorV1\",\n      \"ErrorV1\",\n      \"NotFoundV1\"\n    ],\n    \"serializer\": \"json\",\n    \"parsers\": [\n      \"SuggestV1\"\n    ],\n    \"class\": \"net.opentsdb.tsd.HttpJsonSerializer\",\n    \"response_content_type\": \"application/json; charset=UTF-8\",\n    \"request_content_type\": \"application/json\"\n  }\n]\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/serializers.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/serializers.html</a>\n  </p>\n</div>\n","api_http/suggest":"<h1>/api/suggest</h1> <p>This endpoint provides a means of implementing an \"auto-complete\" call that can be accessed repeatedly as a user types a request in a GUI. It does not offer full text searching or wildcards, rather it simply matches the entire string passed in the query on the first characters of the stored data. For example, passing a query of <code class=\"docutils literal\"><span class=\"pre\">type=metrics&amp;q=sys</span></code> will return the top 25 metrics in the system that start with <code class=\"docutils literal\"><span class=\"pre\">sys</span></code>. Matching is case sensitive, so <code class=\"docutils literal\"><span class=\"pre\">sys</span></code> will not match <code class=\"docutils literal\"><span class=\"pre\">System.CPU</span></code>. Results are sorted alphabetically.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>type</td> <td>String</td> <td>Required</td> <td>The type of data to auto complete on. Must be one of the following: <strong>metrics</strong>, <strong>tagk</strong> or <strong>tagv</strong>\n</td> <td> </td> <td>type</td> <td> </td> <td>metrics</td> </tr> <tr class=\"row-odd\">\n<td>q</td> <td>String</td> <td>Optional</td> <td>A string to match on for the given type</td> <td> </td> <td>q</td> <td> </td> <td>web</td> </tr> <tr class=\"row-even\">\n<td>max</td> <td>Integer</td> <td>Optional</td> <td>The maximum number of suggested results to return. Must be greater than 0</td> <td>25</td> <td>max</td> <td> </td> <td>10</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/suggest?type=metrics&amp;q=sys&amp;max=10\n</pre>\n <p><strong>JSON Content</strong></p> <pre data-language=\"javascript\">{\n  \"type\":\"metrics\",\n  \"q\":\"sys\",\n  \"max\":10\n}\n</pre>\n </div>   <h2>Response</h2> <p>The response is an array of strings of the given type that match the query. If nothing was found to match the query, an empty array will be returned.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">[\n  \"sys.cpu.0.nice\",\n  \"sys.cpu.0.system\",\n  \"sys.cpu.0.user\",\n  \"sys.cpu.1.nice\",\n  \"sys.cpu.1.system\",\n  \"sys.cpu.1.user\"\n]\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/suggest.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/suggest.html</a>\n  </p>\n</div>\n","api_http/uid/index":"<h1>/api/uid</h1> <p>Every metric, tag name and tag value is associated with a unique identifier (UID). Internally, the UID is a binary array assigned to a text value the first time it is encountered or via an explicit assignment request. This endpoint provides utilities for managing UIDs and their associated data. Please see the UID endpoint TOC below for information on what functions are implemented.</p> <p>UIDs exposed via the API are encoded as hexadecimal strings. The UID <code class=\"docutils literal\"><span class=\"pre\">42</span></code> would be expressed as <code class=\"docutils literal\"><span class=\"pre\">00002A</span></code> given the default UID width of 3 bytes.</p> <p>You may also edit meta data associated with timeseries or individual UID objects via the UID endpoint.</p>  <h2>UID API Endpoints</h2> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"assign\">/api/uid/assign</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"tsmeta\">/api/uid/tsmeta</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"uidmeta\">/api/uid/uidmeta</a></li> </ul> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/uid/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/uid/index.html</a>\n  </p>\n</div>\n","user_guide/query/filters":"<h1>Filters</h1> <p>In OpenTSDB 2.2 tag key and value filters were introduced. This makes it easier to extract only the data that you want from storage. The filter framework is plugable to allow for tying into external systems such as asset management or provisioning systems.</p> <p>Multiple filters on the same tag key are allowed and when processed, they are <em>ANDed</em> together e.g. if we have two filters <code class=\"docutils literal\"><span class=\"pre\">host=literal_or(web01)</span></code> and <code class=\"docutils literal\"><span class=\"pre\">host=literal_or(web02)</span></code> the query will always return empty. If two or more filters are included for the same tag key and one has group by enabled but another does not, then group by will effectively be true for all filters on that tag key.</p> <p>Note that some type of filters may cause queries to execute slower than others, e.g. the regex and wildcard filters. Before fetching data from storage, the filters are processed to create a database filter based on UIDs so using the case sensitive \"literal or\" filter is always faster than regex because we can resolve the strings to UIDs and send those to the storage system for filtering. Instead if you ask for regex or wildcards with pre, post or infix filtering the TSD must retrieve all of the rows from storage with the tag key UID, then for each unique row, resolve the UIDs back to strings and then run the filter over the results. Also, filter sets with a large list of literals will be processed post storage to avoid creating a massive filter for the backing store to process. This limit defaults to <code class=\"docutils literal\"><span class=\"pre\">4096</span></code> and can be configured via the <code class=\"docutils literal\"><span class=\"pre\">tsd.query.filter.expansion_limit</span></code> parameter.</p>  <h2>Built-in Filters</h2> <div class=\"section\" id=\"literal-or\"> <h3>literal_or</h3> <p>Takes a single literal value or a pipe delimited list of values and returns any time series matching the results on a case sensitive bases. This is a very efficient filter as it can resolve the strings to UIDs and send that to the storage layer for pre-filtering.</p> <p><em>Examples</em></p> <p><code class=\"docutils literal\"><span class=\"pre\">literal_or(web01|web02|web03)</span></code> <code class=\"docutils literal\"><span class=\"pre\">literal_or(web01)</span></code></p> </div> <div class=\"section\" id=\"ilteral-or\"> <h3>ilteral_or</h3> <p>The same as a <code class=\"docutils literal\"><span class=\"pre\">literal_or</span></code> but is case insensitive. Note that this is not efficient like the literal or as it must post-process all rows from storage.</p> </div> <div class=\"section\" id=\"not-literal-or\"> <h3>not_literal_or</h3> <p>Case sensitive <code class=\"docutils literal\"><span class=\"pre\">literal_or</span></code> that will return series that do <strong>NOT</strong> match the given list of values. Efficient as it can be pre-processed by storage.</p> </div> <div class=\"section\" id=\"not-iliteral-or\"> <h3>not_iliteral_or</h3> <p>Case insensitive <code class=\"docutils literal\"><span class=\"pre\">not_literal_or</span></code>.</p> </div> <div class=\"section\" id=\"wildcard\"> <h3>wildcard</h3> <p>Provides case sensitive postfix, prefix, infix and multi-infix filtering. The wildcard character is an asterisk (star) <code class=\"docutils literal\"><span class=\"pre\">*</span></code>. Multiple wildcards can be used. If only the asterisk is given, the filter effectively returns any time series that include the tag key (and is an efficient filter that can be pre-processed).</p> <p><em>Examples</em> <code class=\"docutils literal\"><span class=\"pre\">wildcard(*mysite.com)</span></code> <code class=\"docutils literal\"><span class=\"pre\">wildcard(web*)</span></code> <code class=\"docutils literal\"><span class=\"pre\">wildcard(web*mysite.com)</span></code> <code class=\"docutils literal\"><span class=\"pre\">wildcard(web*mysite*)</span></code> <code class=\"docutils literal\"><span class=\"pre\">wildcard(*)</span></code></p> </div> <div class=\"section\" id=\"iwildcard\"> <h3>iwildcard</h3> <p>The same as <code class=\"docutils literal\"><span class=\"pre\">wildcard</span></code> but case insensitive.</p> </div> <div class=\"section\" id=\"regexp\"> <h3>regexp</h3> <p>Filters using POSIX compliant regular expressions post fetching from storage. The filter uses Java's built-in regular expression operation. Be careful to escape special characters depending on the query method used.</p> <p><em>Examples</em> <code class=\"docutils literal\"><span class=\"pre\">regexp(web.*)</span></code> <code class=\"docutils literal\"><span class=\"pre\">regexp(web[0-9].mysite.com)</span></code></p> </div>   <h2>Plugins</h2> <p>As developers add plugins we will list them here.</p> <p>To develop a plugin, simply extend the <code class=\"docutils literal\"><span class=\"pre\">net.opentsdb.query.filter.TagVFilter</span></code> class, create JAR per the <a class=\"reference internal\" href=\"../../development/plugins\"><em>Plugins</em></a> documentation and drop it in your plugins directory. On start, the TSD will search for the plugin and load it. If there was an error with the implementation the TSD will not start up and will log the exception.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/query/filters.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/query/filters.html</a>\n  </p>\n</div>\n","user_guide/query/timeseries":"<h1>Understanding Metrics and Time Series</h1> <p>OpenTSDB is a time series database. A time series is a series of numeric data points of some particular metric over time. Each time series consists of a metric plus zero or more tags associated with this metric (we'll cover tags in a bit). A metric is any particular piece of data (e.g. hits to an Apache hosted file) that you wish to track over time.</p> <p>OpenTSDB is also a data plotting system. OpenTSDB plots things a bit differently than other systems. We'll discuss plotting in more detail below, but for now it's important to know that for OpenTSDB, the basis of any given plot is the metric. It takes that metric, finds all of the time series for the time range you select, aggregates those times series together (e.g. by summing them up) and plots the result. The plotting mechanism is very flexible and powerful and you can do much more than this, but for now let's talk about the key to the time series, which is the metric.</p> <p>In OpenTSDB, a metric is named with a string, like <code class=\"docutils literal\"><span class=\"pre\">http.hits</span></code>. To be able to store all the different values for all the places where this metric exists, you tag the data with one or more tags when you send them to the TSD. TSD stores the timestamp, the value, and the tags. When you want to retrieve this data, TSD retrieves all of the values for the time span you supply, optionally with a tag filter you supply, aggregates all these values together how you want, and plots a graph of this value over time.</p> <p>There's a bunch of things in here that we've introduced so far. To help you understand how things work, I'll start with a typical example. Let's say you have a bunch of web servers and you want to track two things: hits to the web server and load average of the system. Let's make up metric names to express this. For load average, let's call it <code class=\"docutils literal\"><span class=\"pre\">proc.loadavg.1min</span></code> (since on Linux you can easily get this data by reading <code class=\"docutils literal\"><span class=\"pre\">/proc/loadavg</span></code>). For many web servers, there is a way to ask the web server for a counter expressing the number of hits to the server since it started. This is a convenient counter upon which to use for a metric we'll call <code class=\"docutils literal\"><span class=\"pre\">http.hits</span></code>. I chose these two examples for two reasons. One, we'll get to see how OpenTSDB easily handles both counters (values that increase over time, except when they get reset by a restart/reboot or overflow) and how it handles normal values that go up and down, like load average. A great advantage of OpenTSDB is that you don't need to do any rate calculation of your counters. It will do it all for you. The second reason is that we can also show you how you can plot two different metrics with different scales on the same graph, which is a great way to correlate different metrics.</p>  <h2>Your first datapoints</h2> <p>Without going into too much detail on how collectors send data to the TSD , you write a collector that periodically sends the current value of these datapoints for each server to the TSD. So the TSD can aggregate the data from multiple hosts, you tag each value with a \"host\" tag. So, if you have web servers A, B, C, etc, they each periodically send something like this to the TSD:</p> <pre data-language=\"python\">put http.hits 1234567890 34877 host=A\nput proc.loadavg.1min 1234567890 1.35 host=A\n</pre>\n <p>Here \"1234567890\" is the current epoch time (date +%s) in seconds. The next number is the value of the metric at this time. This is data from host A, so it's tagged with <code class=\"docutils literal\"><span class=\"pre\">host=A</span></code>. Data from host B would be tagged with <code class=\"docutils literal\"><span class=\"pre\">host=B</span></code>, and so forth. Over time, you'll get a bunch of time series stored in OpenTSDB.</p>   <h2>Your first plot</h2> <p>Now, let's revisit what we talked about here at the beginning. A time series is a series of datapoints of some particular metric (and its tags) over time. For this example, each host is sending two time series to the TSD. If you had 3 boxes each sending these two time series, TSD would be collecting and storing 6 time series. Now that you have the data, let's start plotting.</p> <p>To plot HTTP hits, you just go to the UI and enter <code class=\"docutils literal\"><span class=\"pre\">http.hits</span></code> as your metric name, and enter the time range. Check the \"Rate\" button since this particular metric is a rate counter, and voil?, you have a plot of the rate of HTTP hits to your web servers over time.</p>   <h2>Aggregators</h2> <p>The default for the UI is to aggregate each time series for each host by adding them together (sum). What this means is, TSD is taking the three time series with this metric (host=A, B and C) and adding their values together to come up with the total hits by all web servers at a given time . Note you don't need to send your datapoints at exactly the same time, the TSD will figure it out. So, if each of your hosts was serving 1000 hits per second each at some point in time, the graph would show 3000. What if you wanted to show about how many hits each web server was serving? Two ways. If you just care about the average that each web server was serving, just change the Aggregator method from sum to avg. You can also try the others (max, min) to see the maximum or minimum value. More aggregation functions are in the works (percentiles, etc.). This is done on a per-interval basis , so if at some point in time one of your webservers was serving 50 QPS and the others were serving 100 and later a different webserver was serving 50 QPS and the others were serving 100, for these two points the Min would be 50. In other words it doesn't figure out which time series was the total minimum and just show you that host plot. The other way to see how many hits each web server is serving? This is where we look at the tag fields.</p>   <h2>Downsampling</h2> <p>To reduce the number of datapoints returned, you can specify a downsampling interval and method, such as 1h-avg or 1d-sum. This is also useful (such as when using the max and min) to find best and worst-case datapoints over a given period. Downsampling is most useful to make the graphing phase less intensive and more readable, especially when graphing more datapoints than screen pixels.</p>   <h2>Tag Filters</h2> <p>In the UI you'll see that the TSD has filled one or more \"Tags\", the first one is host. What TSD is saying here that for this time range it sees that the data was tagged with a host tag. You can filter the graph so that it just plots the value of one host. If you fill in A in the host row, you'll just plot the values over time of host A. If you want to give a list of hosts to plot, fill in the list of hosts separated by the pipe symbol, e.g. A|B. This will give you two plots instead of one, one for A and one for B. Finally, you can also specify the special character <a href=\"#id1\"><span class=\"problematic\" id=\"id2\">*</span></a>, which means to plot a line for every host.</p>   <h2>Adding More Metrics</h2> <p>So, now you have a plot of your web hits. How does that correlate against load average? On this same graph, click the \"+\" tab to add a new metric to this existing graph. Enter proc.loadavg.1min as your metric and click \"Right Axis\" so the Y axis is scaled separately and its labels on the right. Make sure \"Rate\" is unchecked, since load average is not a counter metric. Voil?! Now you can see how changes in the rate of web hits affects your system's load average.</p>   <h2>Getting Fancy</h2> <p>Imagine each if your servers actually ran two webservers, say, one for static content and one for dynamic content. Rather than create another metric, just tag the http.hits metric with the server instance. Have your collector send stuff like:</p> <p><code class=\"docutils literal\"><span class=\"pre\">put</span> <span class=\"pre\">http.hits</span> <span class=\"pre\">1234567890</span> <span class=\"pre\">34877</span> <span class=\"pre\">host=A</span> <span class=\"pre\">webserver=static</span> <span class=\"pre\">put</span> <span class=\"pre\">http.hits</span> <span class=\"pre\">1234567890</span> <span class=\"pre\">4357</span> <span class=\"pre\">host=A</span> <span class=\"pre\">webserver=dynamic</span> <span class=\"pre\">put</span> <span class=\"pre\">proc.loadavg.1min</span> <span class=\"pre\">1234567890</span> <span class=\"pre\">1.35</span> <span class=\"pre\">host=A</span></code></p> <p>Why do this instead of creating another metric? Well, what if sometimes you care about plotting total HTTP hits and sometimes you care about breaking out static vs. dynamic hits? With a tag, it's easy. With this new tag, you'll see a webserver tag appear in the UI when plotting this metric. You can leave it blank and it will aggregate up both values into one plot (according to your Aggregator setting) and you can see the total hits, or you can do webserver=* to break out how much each of your static and dynamic instances are collectively doing across your web servers. You can even go deeper and specify webserver=* and host=* to see the full breakdown.</p>   <h2>Guidelines When to Create Metrics</h2> <p>Right now, you cannot combine two metrics into one plot line. This means you want a metric to be the biggest possible aggregation point. If you want to drill down to specifics within a metric, use tags.</p>   <h2>Tags vs. Metrics</h2> <p>The metric should be a specific thing, like \"Ethernet packets\" but not be broken out into a particular instance of a thing. Generally you don't want to collect a metric like net.bytes.eth0, net.bytes.eth1, etc. Collect net.bytes and tag eth0 datapoints with iface=eth0, etc. Don't bother creating separate \"in\" and \"out\" metrics, either. Add the tag direction=in or direction=out. This way you can easily see the total network activity for a given box without having to plot a bunch of metrics. This still gives you the flexibility to drill down and just show activity for a particular interface, or just a particular direction.</p>   <h2>Counters and Rates</h2> <p>If something is a counter, or is naturally something that is a rate, don't convert it to a rate before sending it to the TSD. There's two main reasons for this. First, doing your own rate calculation, reset/overflow handling, etc. is silly, since TSD can do it for you. You also don't have to worry about getting the units-per-second calculation correct based on a slightly inaccurate or changing sample interval. Secondly, if something happens where you lose a datapoint or more, if you are sending the current counter value then you won't lose data, just resolution of that data. The golden rule in TSD is, if your source data is a counter (some counter out of /proc or SNMP), keep it that way. Don't convert it. If you're writing your own collector (say, one that counts how often a particular error message appears in a tail -f of a log), don't reset your counter every sample interval. Let TSD to do the work for you.</p>   <h2>Tags are your Friend</h2> <p>In anything above a small environment, you probably have clusters or groups of machines doing the same thing. Over time these change, though. That's OK. Just use a tag when you send the data to TSD to pass this cluster info along. Add something like cluster=webserver to all the datapoints being sent from each of your webservers, and cluster=db for all your databases, etc.</p> <p>Now when you plot CPU activity for your webserver cluster, you see all of them aggregated into one plot. Then let's say you add a webserver or even change it from a webserver to a database. All you have to do is make sure the right tag gets sent when its role changes, and now that box's CPU activity gets counted toward the right cluster. What's more, all of your historical data is still correct! This is the true power of OpenTSDB. Not only do you never lose resolution of your datapoints over time like RRD-based systems, but historical data doesn't get lost as your boxes shift around. You also don't have to put a bunch of cluster or grouping awareness logic into your dashboards.</p>   <h2>Precisions on Metrics and Tags</h2> <p>The maximum number of tags allowed on a data point is defined by a constant (Const.MAX_NUM_TAGS), which at time of writing is 8. Metric names, tag names and tag values have to be made of alpha numeric characters, dash \"-\", underscore \"_\", period \".\", and forward slash \"/\", as is enforced by the package-private function Tags.validateString.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/query/timeseries.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/query/timeseries.html</a>\n  </p>\n</div>\n","api_http/stats/region_clients":"<h1>/api/stats/region_clients</h1> <p>Returns information about the various HBase region server clients in AsyncHBase. This helps to identify issues with a particular region server. (v2.2)</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>No parameters available.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/stats/region_clients\n</pre>\n </div>   <h2>Response</h2> <p>The response is an array of objects. Fields in the response include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>pendingBreached</td> <td>Integer</td> <td>The total number of times writes to a new region client were discarded because it's pending RPC buffer was full. This should almost always be zero and a positive value indicates the TSD took a long time to connect to a region server.</td> <td>0</td> </tr> <tr class=\"row-odd\">\n<td>writesBlocked</td> <td>Integer</td> <td>How many RPCs (batched or individual) in total were blocked due to the connection's send buffer being full. A positive value indicates a slow HBase server or poor network performance.</td> <td>0</td> </tr> <tr class=\"row-even\">\n<td>inflightBreached</td> <td>Integer</td> <td>The total number of times RPCs were blocked due to too many outstanding RPCs waiting for a response from HBase. A positive value indicates the region server is slow or network performance is poor.</td> <td>0</td> </tr> <tr class=\"row-odd\">\n<td>dead</td> <td>Boolean</td> <td>Whether or not the region client is marked as dead due to a connection close event (such as region server going down)</td> <td>false</td> </tr> <tr class=\"row-even\">\n<td>rpcsInFlight</td> <td>Integer</td> <td>The current number of RPCs sent to HBase and awaiting a response.</td> <td>10</td> </tr> <tr class=\"row-odd\">\n<td>rpcsSent</td> <td>Integer</td> <td>The total number of RPCs sent to HBase.</td> <td>424242</td> </tr> <tr class=\"row-even\">\n<td>rpcResponsesUnknown</td> <td>Integer</td> <td>The total number of responses received from HBase for which we couldn't find an RPC. This may indicate packet corruption or an incompatible HBase version.</td> <td>0</td> </tr> <tr class=\"row-odd\">\n<td>pendingBatchedRPCs</td> <td>Integer</td> <td>The number of RPCs queued in the batched RPC awaiting the next flush or the batch limit.</td> <td>0</td> </tr> <tr class=\"row-even\">\n<td>endpoint</td> <td>String</td> <td>The IP and port of the region server in the format '/&lt;ip&gt;:&lt;port&gt;'</td> <td>/127.0.0.1:35008</td> </tr> <tr class=\"row-odd\">\n<td>rpcResponsesTimedout</td> <td>Integer</td> <td>The total number of responses from HBase for RPCs that have previously timedout. This means HBase may be catching up and responding to stale RPCs.</td> <td>0</td> </tr> <tr class=\"row-even\">\n<td>rpcid</td> <td>Integer</td> <td>The ID of the last RPC sent to HBase. This may be a negative number</td> <td>42</td> </tr> <tr class=\"row-odd\">\n<td>rpcsTimedout</td> <td>Integer</td> <td>The total number of RPCs that have timed out. This may indicate a slow region server, poor network performance or GC issues with the TSD.</td> <td>0</td> </tr> <tr class=\"row-even\">\n<td>pendingRPCs</td> <td>Integer</td> <td>The number of RPCs queued and waiting for the connection handshake with the region server to complete</td> <td>0</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">[\n  {\n    \"pendingBreached\": 0,\n    \"writesBlocked\": 0,\n    \"inflightBreached\": 0,\n    \"dead\": false,\n    \"rpcsInFlight\": 0,\n    \"rpcsSent\": 35704,\n    \"rpcResponsesUnknown\": 0,\n    \"pendingBatchedRPCs\": 452,\n    \"endpoint\": \"/127.0.0.1:35008\",\n    \"rpcResponsesTimedout\": 0,\n    \"rpcid\": 35703,\n    \"rpcsTimedout\": 0,\n    \"pendingRPCs\": 0\n  }\n]\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/stats/region_clients.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/stats/region_clients.html</a>\n  </p>\n</div>\n","api_http/query/index":"<h1>/api/query</h1> <p>Probably the most useful endpoint in the API, <code class=\"docutils literal\"><span class=\"pre\">/api/query</span></code> enables extracting data from the storage system in various formats determined by the serializer selected. Queries can be submitted via the 1.0 query string format or body content.</p>  <h2>Query API Endpoints</h2> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"exp\">/api/query/exp</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"gexp\">/api/query/gexp</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"last\">/api/query/last</a></li> </ul> </div> <p>The <code class=\"docutils literal\"><span class=\"pre\">/query</span></code> endpoint is documented below. As of 2.2 data matching a query can be deleted by using the <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> verb. The configuration parameter <code class=\"docutils literal\"><span class=\"pre\">tsd.http.query.allow_delete</span></code> must be enabled to allow deletions. Data that is deleted will be returned in the query results. Executing the query a second time should return empty results.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">Deleting data is permanent. Also beware that when deleting, some data outside the boundaries of the start and end times may be deleted as data is stored on an hourly basis.</p> </div>   <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> <li>DELETE</li> </ul>   <h2>Requests</h2> <p>Request parameters include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>start</td> <td>String, Integer</td> <td>Required</td> <td>The start time for the query. This can be a relative or absolute timestamp. See <a class=\"reference internal\" href=\"../../user_guide/query/index\"><em>Querying or Reading Data</em></a> for details.</td> <td> </td> <td>start</td> <td> </td> <td>1h-ago</td> </tr> <tr class=\"row-odd\">\n<td>end</td> <td>String, Integer</td> <td>Optional</td> <td>An end time for the query. If not supplied, the TSD will assume the local system time on the server. This may be a relative or absolute timestamp. See <a class=\"reference internal\" href=\"../../user_guide/query/index\"><em>Querying or Reading Data</em></a> for details.</td> <td><em>current time</em></td> <td>end</td> <td> </td> <td>1s-ago</td> </tr> <tr class=\"row-even\">\n<td>queries</td> <td>Array</td> <td>Required</td> <td>One or more sub queries used to select the time series to return. These may be metric <code class=\"docutils literal\"><span class=\"pre\">m</span></code> or TSUID <code class=\"docutils literal\"><span class=\"pre\">tsuids</span></code> queries</td> <td> </td> <td>m or tsuids</td> <td> </td> <td><em>See below</em></td> </tr> <tr class=\"row-odd\">\n<td>noAnnotations</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to return annotations with a query. The default is to return annotations for the requested timespan but this flag can disable the return. This affects both local and global notes and overrides <code class=\"docutils literal\"><span class=\"pre\">globalAnnotations</span></code>\n</td> <td>false</td> <td>no_annotations</td> <td> </td> <td>false</td> </tr> <tr class=\"row-even\">\n<td>globalAnnotations</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not the query should retrieve global annotations for the requested timespan</td> <td>false</td> <td>global_annotations</td> <td> </td> <td>true</td> </tr> <tr class=\"row-odd\">\n<td>msResolution</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to output data point timestamps in milliseconds or seconds. If this flag is not provided and there are multiple data points within a second, those data points will be down sampled using the query's aggregation function.</td> <td>false</td> <td>ms</td> <td> </td> <td>true</td> </tr> <tr class=\"row-even\">\n<td>showTSUIDs</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to output the TSUIDs associated with timeseries in the results. If multiple time series were aggregated into one set, multiple TSUIDs will be returned in a sorted manner</td> <td>false</td> <td>show_tsuids</td> <td> </td> <td>true</td> </tr> <tr class=\"row-odd\">\n<td>showSummary</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to show a summary of timings surrounding the query in the results. This creates another object in the map that is unlike the data point objects.</td> <td>false</td> <td>show_summary</td> <td> </td> <td>true</td> </tr> <tr class=\"row-even\">\n<td>showQuery</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to return the original sub query with the query results. If the request contains many sub queries then this is a good way to determine which results belong to which sub query. Note that in the case of a <code class=\"docutils literal\"><span class=\"pre\">*</span></code> or wildcard query, this can produce a lot of duplicate output.</td> <td>false</td> <td>show_query</td> <td> </td> <td>true</td> </tr> <tr class=\"row-odd\">\n<td>delete</td> <td>Boolean</td> <td>Optional</td> <td>Can be passed to the JSON with a POST to delete any data points that match the given query.</td> <td>false</td> <td> </td> <td>W</td> <td>true</td> </tr> </tbody> </table> <div class=\"section\" id=\"sub-queries\"> <h3>Sub Queries</h3> <p>An OpenTSDB query requires at least one sub query, a means of selecting which time series should be included in the result set. There are two types:</p> <ul class=\"simple\"> <li>\n<strong>Metric Query</strong> - The full name of a metric is supplied along with an optional list of tags. This is optimized for aggregating multiple time series into one result.</li> <li>\n<strong>TSUID Query</strong> - A list of one or more TSUIDs that share a common metric. This is optimized for fetching individual time series where aggregation is not required.</li> </ul> <p>A query can include more than one sub query and any mixture of the two types. When submitting a query via content body, if a list of TSUIDs is supplied, the metric and tags for that particular sub query will be ignored.</p> <p>Each sub query can retrieve individual or groups of timeseries data, performing aggregation or grouping calculations on each set. Fields for each sub query include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"50%\"> <col width=\"10%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>aggregator</td> <td>String</td> <td>Required</td> <td>The name of an aggregation function to use. See <a class=\"reference internal\" href=\"../aggregators\"><em>/api/aggregators</em></a>\n</td> <td> </td> <td>sum</td> </tr> <tr class=\"row-odd\">\n<td>metric</td> <td>String</td> <td>Required</td> <td>The name of a metric stored in the system</td> <td> </td> <td>sys.cpu.0</td> </tr> <tr class=\"row-even\">\n<td>rate</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not the data should be converted into deltas before returning. This is useful if the metric is a continuously incrementing counter and you want to view the rate of change between data points.</td> <td>false</td> <td>true</td> </tr> <tr class=\"row-odd\">\n<td>rateOptions</td> <td>Map</td> <td>Optional</td> <td>Monotonically increasing counter handling options</td> <td><em>See below</em></td> <td><em>See below</em></td> </tr> <tr class=\"row-even\">\n<td>downsample</td> <td>String</td> <td>Optional</td> <td>An optional downsampling function to reduce the amount of data returned.</td> <td><em>See below</em></td> <td>5m-avg</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Map</td> <td>Optional</td> <td>To drill down to specific timeseries or group results by tag, supply one or more map values in the same format as the query string. Tags are converted to filters in 2.2. See the notes below about conversions. Note that if no tags are specified, all metrics in the system will be aggregated into the results. <em>Deprecated in 2.2</em>\n</td> <td> </td> <td><em>See Below</em></td> </tr> <tr class=\"row-even\">\n<td>filters <em>(2.2)</em>\n</td> <td>List</td> <td>Optional</td> <td>Filters the time series emitted in the results. Note that if no filters are specified, all time series for the given metric will be aggregated into the results.</td> <td> </td> <td><em>See Below</em></td> </tr> <tr class=\"row-odd\">\n<td>explicitTags <em>(2.3)</em>\n</td> <td>Boolean</td> <td>Optional</td> <td>Returns the series that include only the tag keys provided in the filters.</td> <td>false</td> <td>true</td> </tr> </tbody> </table> <p><em>Rate Options</em></p> <p>When passing rate options in a query string, the options must be enclosed in curly braces. For example: <code class=\"docutils literal\"><span class=\"pre\">m=sum:rate{counter,,1000}:if.octets.in</span></code>. If you wish to use the default <code class=\"docutils literal\"><span class=\"pre\">counterMax</span></code> but do want to supply a <code class=\"docutils literal\"><span class=\"pre\">resetValue</span></code>, you must add two commas as in the previous example. Additional fields in the <code class=\"docutils literal\"><span class=\"pre\">rateOptions</span></code> object include the following:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"50%\"> <col width=\"10%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>counter</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not the underlying data is a monotonically increasing counter that may roll over</td> <td>false</td> <td>true</td> </tr> <tr class=\"row-odd\">\n<td>counterMax</td> <td>Integer</td> <td>Optional</td> <td>A positive integer representing the maximum value for the counter.</td> <td>Java Long.MaxValue</td> <td>65535</td> </tr> <tr class=\"row-even\">\n<td>resetValue</td> <td>Integer</td> <td>Optional</td> <td>An optional value that, when exceeded, will cause the aggregator to return a <code class=\"docutils literal\"><span class=\"pre\">0</span></code> instead of the calculated rate. Useful when data sources are frequently reset to avoid spurious spikes.</td> <td>0</td> <td>65000</td> </tr> </tbody> </table> <p><em>Downsampling</em></p> <p>Downsample specifications const if an interval, a unit of time, an aggregator and (as of 2.2) an optional fill policy. The format of a downsample spec is:</p> <pre data-language=\"python\">&lt;interval&gt;&lt;units&gt;-&lt;aggregator&gt;[-&lt;fill policy&gt;]\n</pre>\n <p>For example:</p> <pre data-language=\"python\">1h-sum\n30m-avg-nan\n24h-max-zero\n</pre>\n <p>See <a class=\"reference internal\" href=\"../../user_guide/query/aggregators\"><em>Aggregators</em></a> for a list of supported fill policies.</p> <p><em>Filters</em></p> <p>New for 2.2, OpenTSDB includes expanded and plugable filters across tag key and value combinations. For a list of filters loaded in the TSD, see <a class=\"reference internal\" href=\"../config/filters\"><em>/api/config/filters</em></a>. For descriptions of the built-in filters see <a class=\"reference internal\" href=\"../../user_guide/query/filters\"><em>Filters</em></a>. Filters can be used in both query string and POST formatted queries. Multiple filters on the same tag key are allowed and when processed, they are <em>ANDed</em> together e.g. if we have two filters <code class=\"docutils literal\"><span class=\"pre\">host=literal_or(web01)</span></code> and <code class=\"docutils literal\"><span class=\"pre\">host=literal_or(web02)</span></code> the query will always return empty. If two or more filters are included for the same tag key and one has group by enabled but another does not, then group by will effectively be true for all filters on that tag key. Fields for POST queries pertaining to filters include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"50%\"> <col width=\"10%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>type</td> <td>String</td> <td>Required</td> <td>The name of the filter to invoke. See <a class=\"reference internal\" href=\"../config/filters\"><em>/api/config/filters</em></a>\n</td> <td> </td> <td>regexp</td> </tr> <tr class=\"row-odd\">\n<td>tagk</td> <td>String</td> <td>Required</td> <td>The tag key to invoke the filter on</td> <td> </td> <td>host</td> </tr> <tr class=\"row-even\">\n<td>filter</td> <td>String</td> <td>Required</td> <td>The filter expression to evaluate and depends on the filter being used</td> <td> </td> <td>web.*.mysite.com</td> </tr> <tr class=\"row-odd\">\n<td>groupBy</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to group the results by each value matched by the filter. By default all values matching the filter will be aggregated into a single series.</td> <td>false</td> <td>true</td> </tr> </tbody> </table> <p>For URI queries, the type precedes the filter expression in parentheses. The format is <code class=\"docutils literal\"><span class=\"pre\">&lt;tagk&gt;=&lt;type&gt;(&lt;filter_expression&gt;)</span></code>. Whether or not results are grouped depends on which curly bracket the filter is in. Two curly braces are now supported per metric query. The first set is the <em>group by</em> filter and the second is a <em>non group by</em> filter, e.g. <code class=\"docutils literal\"><span class=\"pre\">{host=web01}{colo=regexp(sjc.*)}.</span> <span class=\"pre\">If</span> <span class=\"pre\">you</span> <span class=\"pre\">only</span> <span class=\"pre\">want</span> <span class=\"pre\">to</span> <span class=\"pre\">filter</span> <span class=\"pre\">without</span> <span class=\"pre\">grouping</span> <span class=\"pre\">then</span> <span class=\"pre\">the</span> <span class=\"pre\">first</span> <span class=\"pre\">curly</span> <span class=\"pre\">set</span> <span class=\"pre\">must</span> <span class=\"pre\">be</span> <span class=\"pre\">empty,</span> <span class=\"pre\">e.g.</span> <span class=\"pre\">``{}{host=web*}</span></code></p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Regular expression, wildcard filters with a pre/post/in-fix or literal ors with many values can cause queries to return slower as each row of data must be resolved to their string values then processed.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">When submitting a JSON query to OpenTSDB 2.2 or later, use either <code class=\"docutils literal\"><span class=\"pre\">tags</span></code> OR <code class=\"docutils literal\"><span class=\"pre\">filters</span></code>. Only one will take effect and the order is indeterminate as the JSON parser may deserialize one before the other. We recommend using filters for all future queries.</p> </div> <p><em>Filter Conversions</em></p> <p>Values in the POST query <code class=\"docutils literal\"><span class=\"pre\">tags</span></code> map and the <em>group by</em> curly brace of URI queries are automatically converted to filters to provide backwards compatibility with existing systems. The auto conversions include:</p> <table class=\"docutils\"> <colgroup> <col width=\"25%\"> <col width=\"75%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Example</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td><code class=\"docutils literal\"><span class=\"pre\">&lt;tagk&gt;=*</span></code></td> <td>Wildcard filter, effectively makes sure the tag key is present in the series</td> </tr> <tr class=\"row-odd\">\n<td><code class=\"docutils literal\"><span class=\"pre\">&lt;tagk&gt;=value</span></code></td> <td>Case sensitive literal OR filter</td> </tr> <tr class=\"row-even\">\n<td><code class=\"docutils literal\"><span class=\"pre\">&lt;tagk&gt;=value1|value2|valueN</span></code></td> <td>Case sensitive literal OR filter</td> </tr> <tr class=\"row-odd\">\n<td><code class=\"docutils literal\"><span class=\"pre\">&lt;tagk&gt;=va*</span></code></td> <td>Case insensitive wildcard filter. An asterisk (star) with any other strings now becomes a wildcard filter shortcut</td> </tr> </tbody> </table> </div> <div class=\"section\" id=\"metric-query-string-format\"> <h3>Metric Query String Format</h3> <p>The full specification for a metric query string sub query is as follows:</p> <pre data-language=\"python\">m=&lt;aggregator&gt;:[rate[{counter[,&lt;counter_max&gt;[,&lt;reset_value&gt;]]]}:][&lt;down_sampler&gt;:][explicit_tags:]&lt;metric_name&gt;[{&lt;tag_name1&gt;=&lt;grouping filter&gt;[,...&lt;tag_nameN&gt;=&lt;grouping_filter&gt;]}][{&lt;tag_name1&gt;=&lt;non grouping filter&gt;[,...&lt;tag_nameN&gt;=&lt;non_grouping_filter&gt;]}]\n</pre>\n <p>It can be a little daunting at first but you can break it down into components. If you're ever confused, try using the built-in GUI to plot a graph the way you want it, then look at the URL to see how the query is formatted. Changes to any of the form fields will update the URL (which you can actually copy and paste to share with other users). For examples, please see <a class=\"reference internal\" href=\"../../user_guide/query/examples\"><em>Query Examples</em></a>.</p> </div> <div class=\"section\" id=\"tsuid-query-string-format\"> <h3>TSUID Query String Format</h3> <p>TSUID queries are simpler than Metric queries. Simply pass a list of one or more hexadecimal encoded TSUIDs separated by commas:</p> <pre data-language=\"python\">tsuid=&lt;aggregator&gt;:&lt;tsuid1&gt;[,...&lt;tsuidN&gt;]\n</pre>\n </div> <div class=\"section\" id=\"example-query-string-requests\"> <h3>Example Query String Requests</h3> <pre data-language=\"python\">http://localhost:4242/api/query?start=1h-ago&amp;m=sum:rate:proc.stat.cpu{host=foo,type=idle}\nhttp://localhost:4242/api/query?start=1h-ago&amp;tsuid=sum:000001000002000042,000001000002000043\n</pre>\n </div> <div class=\"section\" id=\"example-content-request\"> <h3>Example Content Request</h3> <p>Please see the serializer documentation for request information: <a class=\"reference internal\" href=\"../serializers/index\"><em>HTTP Serializers</em></a>. The following examples pertain to the default JSON serializer.</p> <pre data-language=\"javascript\">{\n  \"start\": 1356998400,\n  \"end\": 1356998460,\n  \"queries\": [\n    {\n      \"aggregator\": \"sum\",\n      \"metric\": \"sys.cpu.0\",\n      \"rate\": \"true\",\n      \"tags\": {\n        \"host\": \"*\",\n        \"dc\": \"lga\"\n      }\n    },\n    {\n      \"aggregator\": \"sum\",\n      \"tsuids\": [\n        \"000001000002000042\",\n        \"000001000002000043\"\n        ]\n      }\n    }\n  ]\n}\n</pre>\n <p>2.2 query with filters</p> <pre data-language=\"javascript\">{\n  \"start\": 1356998400,\n  \"end\": 1356998460,\n  \"queries\": [\n    {\n      \"aggregator\": \"sum\",\n      \"metric\": \"sys.cpu.0\",\n      \"rate\": \"true\",\n      \"filters\": [\n        {\n           \"type\":\"wildcard\",\n           \"tagk\":\"host\",\n           \"filter\":\"*\",\n           \"groupBy\":true\n        },\n        {\n           \"type\":\"literal_or\",\n           \"tagk\":\"dc\",\n           \"filter\":\"lga|lga1|lga2\",\n           \"groupBy\":false\n        },\n      ]\n    },\n    {\n      \"aggregator\": \"sum\",\n      \"tsuids\": [\n        \"000001000002000042\",\n        \"000001000002000043\"\n        ]\n      }\n    }\n  ]\n}\n</pre>\n </div>   <h2>Response</h2> <p>The output generated for a query depends heavily on the chosen serializer <a class=\"reference internal\" href=\"../serializers/index\"><em>HTTP Serializers</em></a>. A request may result in multiple sets of data returned, particularly if the request included multiple queries or grouping was requested. Some common fields included with each data set in the response will be:</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"80%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>metric</td> <td>Name of the metric retrieved for the time series</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>A list of tags only returned when the results are for a single time series. If results are aggregated, this value may be null or an empty map</td> </tr> <tr class=\"row-even\">\n<td>aggregatedTags</td> <td>If more than one timeseries were included in the result set, i.e. they were aggregated, this will display a list of tag names that were found in common across all time series.</td> </tr> <tr class=\"row-odd\">\n<td>dps</td> <td>Retrieved data points after being processed by the aggregators. Each data point consists of a timestamp and a value, the format determined by the serializer.</td> </tr> <tr class=\"row-even\">\n<td>annotations</td> <td>If the query retrieved annotations for timeseries over the requested timespan, they will be returned in this group. Annotations for every timeseries will be merged into one set and sorted by <code class=\"docutils literal\"><span class=\"pre\">start_time</span></code>. Aggregator functions do not affect annotations, all annotations will be returned for the span.</td> </tr> <tr class=\"row-odd\">\n<td>globalAnnotations</td> <td>If requested by the user, the query will scan for global annotations during the timespan and the results returned in this group</td> </tr> </tbody> </table> <p>Unless there was an error with the query, you will generally receive a <code class=\"docutils literal\"><span class=\"pre\">200</span></code> status with content. However if your query couldn't find any data, it will return an empty result set. In the case of the JSON serializer, the result will be an empty array:</p> <pre data-language=\"javascript\">[]\n</pre>\n <p>For the JSON serializer, the timestamp will always be a Unix epoch style integer followed by the value as an integer or a floating point. For example, the default output is <code class=\"docutils literal\"><span class=\"pre\">\"dps\"{\"&lt;timestamp&gt;\":&lt;value&gt;}</span></code>. By default the timestamps will be in seconds. If the <code class=\"docutils literal\"><span class=\"pre\">msResolution</span></code> flag is set, then the timestamps will be in milliseconds.</p> <div class=\"section\" id=\"example-aggregated-default-response\"> <h3>Example Aggregated Default Response</h3> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"tsd.hbase.puts\",\n    \"tags\": {},\n    \"aggregatedTags\": [\n      \"host\"\n    ],\n    \"annotations\": [\n      {\n        \"tsuid\": \"00001C0000FB0000FB\",\n        \"description\": \"Testing Annotations\",\n        \"notes\": \"These would be details about the event, the description is just a summary\",\n        \"custom\": {\n          \"owner\": \"jdoe\",\n          \"dept\": \"ops\"\n        },\n        \"endTime\": 0,\n        \"startTime\": 1365966062\n      }\n    ],\n    \"globalAnnotations\": [\n      {\n        \"description\": \"Notice\",\n        \"notes\": \"DAL was down during this period\",\n        \"custom\": null,\n        \"endTime\": 1365966164,\n        \"startTime\": 1365966064\n      }\n    ],\n    \"tsuids\": [\n      \"0023E3000002000008000006000001\"\n    ],\n    \"dps\": {\n      \"1365966001\": 25595461080,\n      \"1365966061\": 25595542522,\n      \"1365966062\": 25595543979,\n...\n      \"1365973801\": 25717417859\n    }\n  }\n]\n</pre>\n </div> <div class=\"section\" id=\"example-aggregated-array-response\"> <h3>Example Aggregated Array Response</h3> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"tsd.hbase.puts\",\n    \"tags\": {},\n    \"aggregatedTags\": [\n      \"host\"\n    ],\n    \"dps\": [\n      [\n        1365966001,\n        25595461080\n      ],\n      [\n        1365966061,\n        25595542522\n      ],\n...\n      [\n        1365974221,\n        25722266376\n      ]\n    ]\n  }\n]\n</pre>\n </div> <div class=\"section\" id=\"example-multi-set-response\"> <h3>Example Multi-Set Response</h3> <p>For the following example, two TSDs were running and the query was: <code class=\"docutils literal\"><span class=\"pre\">http://localhost:4242/api/query?start=1h-ago&amp;m=sum:tsd.hbase.puts{host=*}</span></code>. This returns two explicit time series.</p> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"tsd.hbase.puts\",\n    \"tags\": {\n      \"host\": \"tsdb-1.mysite.com\"\n    },\n    \"aggregatedTags\": [],\n    \"dps\": {\n      \"1365966001\": 3758788892,\n      \"1365966061\": 3758804070,\n...\n      \"1365974281\": 3778141673\n    }\n  },\n  {\n    \"metric\": \"tsd.hbase.puts\",\n    \"tags\": {\n      \"host\": \"tsdb-2.mysite.com\"\n    },\n    \"aggregatedTags\": [],\n    \"dps\": {\n      \"1365966001\": 3902179270,\n      \"1365966062\": 3902197769,\n...\n      \"1365974281\": 3922266478\n    }\n  }\n]\n</pre>\n </div> <div class=\"section\" id=\"example-with-show-summary-and-query\"> <h3>Example With Show Summary and Query</h3> <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"tsd.hbase.puts\",\n    \"tags\": {},\n    \"aggregatedTags\": [\n      \"host\"\n    ],\n    \"query\": {\n      \"aggregator\": \"sum\",\n      \"metric\": \"tsd.hbase.puts\",\n      \"tsuids\": null,\n      \"downsample\": null,\n      \"rate\": true,\n      \"explicitTags\": false,\n      \"filters\": [\n        {\n          \"tagk\": \"host\",\n          \"filter\": \"*\",\n          \"group_by\": true,\n          \"type\": \"wildcard\"\n        }\n      ],\n      \"rateOptions\": null,\n      \"tags\": { }\n    },\n    \"dps\": {\n      \"1365966001\": 25595461080,\n      \"1365966061\": 25595542522,\n      \"1365966062\": 25595543979,\n...\n      \"1365973801\": 25717417859\n    }\n  },\n  {\n    \"statsSummary\": {\n      \"datapoints\": 0,\n      \"rawDatapoints\": 56,\n      \"aggregationTime\": 0,\n      \"serializationTime\": 20,\n      \"storageTime\": 6,\n      \"timeTotal\": 26\n    }\n  }\n]\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/query/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/query/index.html</a>\n  </p>\n</div>\n","api_http/search/index":"<h1>/api/search</h1> <p>This endpoint provides a basic means of searching OpenTSDB meta data. Lookups can be performed against the <code class=\"docutils literal\"><span class=\"pre\">tsdb-meta</span></code> table when enabled. Optionally, a search plugin can be installed to send and retreive information from an external search indexing service such as Elastic Search. It is up to each search plugin to implement various parts of this endpoint and return data in a consistent format. The type of object searched and returned depends on the endpoint chosen.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If the plugin is not configured or enabled, endpoints other than <code class=\"docutils literal\"><span class=\"pre\">/api/search/lookup</span></code> will return an exception.</p> </div>  <h2>Search API Endpoints</h2> <ul class=\"simple\"> <li><a class=\"reference internal\" href=\"lookup\"><em>/api/search/lookup</em></a></li> <li>/api/search/tsmeta - <a class=\"reference internal\" href=\"#tsmeta-endpoint\"><span>TSMETA Response</span></a>\n</li> <li>/api/search/tsmeta_summary - <a class=\"reference internal\" href=\"#tsmeta-summary-endpoint\"><span>TSMETA_SUMMARY Response</span></a>\n</li> <li>/api/search/tsuids - <a class=\"reference internal\" href=\"#tsuids-endpoint\"><span>TSUIDS Response</span></a>\n</li> <li>/api/search/uidmeta - <a class=\"reference internal\" href=\"#uidmeta-endpoint\"><span>UIDMETA Response</span></a>\n</li> <li>/api/search/annotation - <a class=\"reference internal\" href=\"#annotation-endpoint\"><span>Annotation Response</span></a>\n</li> </ul>   <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>Parameters used by the search endpoint include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>query</td> <td>String</td> <td>Optional</td> <td>The string based query to pass to the search engine. This will be parsed by the engine or plugin to perform the actual search. Allowable values depends on the plugin. Ignored for lookups.</td> <td> </td> <td>query</td> <td> </td> <td>name:sys.cpu.*</td> </tr> <tr class=\"row-odd\">\n<td>limit</td> <td>Integer</td> <td>Optional</td> <td>Limits the number of results returned per query so as not to override the TSD or search engine. Allowable values depends on the plugin. Ignored for lookups.</td> <td>25</td> <td>limit</td> <td> </td> <td>100</td> </tr> <tr class=\"row-even\">\n<td>startIndex</td> <td>Integer</td> <td>Optional</td> <td>Used in combination with the <code class=\"docutils literal\"><span class=\"pre\">limit</span></code> value to page through results. Allowable values depends on the plugin. Ignored for lookups.</td> <td>0</td> <td>start_index</td> <td> </td> <td>42</td> </tr> <tr class=\"row-odd\">\n<td>metric</td> <td>String</td> <td>Optional</td> <td>The name of a metric or a wildcard for lookup queries</td> <td>*</td> <td>metric</td> <td> </td> <td>tsd.hbase.rpcs</td> </tr> <tr class=\"row-even\">\n<td>tags</td> <td>Array</td> <td>Optional</td> <td>One or more key/value objects with tag names and/or tag values for lookup queries. See <a class=\"reference internal\" href=\"lookup\"><em>/api/search/lookup</em></a>\n</td> <td> </td> <td>tags</td> <td> </td> <td>See <a class=\"reference internal\" href=\"lookup\"><em>/api/search/lookup</em></a>\n</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p>Query String:</p> <pre data-language=\"python\">http://localhost:4242/api/search/tsmeta?query=name:*&amp;limit=3&amp;start_index=0\n</pre>\n <p>POST:</p> <pre data-language=\"javascript\">{\n  \"query\": \"name:*\",\n  \"limit\": 4,\n  \"startIndex\": 5\n}\n</pre>\n </div>   <h2>Response</h2> <p>Depending on the endpoint called, the output will change slightly. However common fields include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>type</td> <td>String</td> <td>The type of query submitted, i.e. the endpoint called. Will be one of the endpoints listed above.</td> <td>TSMETA</td> </tr> <tr class=\"row-odd\">\n<td>query</td> <td>String</td> <td>The query string submitted. May be altered by the plugin</td> <td>name:sys.cpu.*</td> </tr> <tr class=\"row-even\">\n<td>limit</td> <td>Integer</td> <td>The maximum number of items returned in the result set. Note that the actual number returned may be less than the limit.</td> <td>25</td> </tr> <tr class=\"row-odd\">\n<td>startIndex</td> <td>Integer</td> <td>The starting index for the current result set as provided in the query</td> <td>0</td> </tr> <tr class=\"row-even\">\n<td>metric</td> <td>String</td> <td>The metric used for the lookup</td> <td>\n<ul class=\"first last simple\"> <li> </ul> </td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Array</td> <td>The list of tag pairs used for lookup queries. May be an empty list.</td> <td>[ ]</td> </tr> <tr class=\"row-even\">\n<td>time</td> <td>Integer</td> <td>The amount of time it took, in milliseconds, to complete the query</td> <td>120</td> </tr> <tr class=\"row-odd\">\n<td>totalResults</td> <td>Integer</td> <td>The total number of results matched by the query</td> <td>1024</td> </tr> <tr class=\"row-even\">\n<td>results</td> <td>Array</td> <td>The result set. The format depends on the endpoint requested.</td> <td><em>See Below</em></td> </tr> </tbody> </table> <p>This endpoint will almost always return a <code class=\"docutils literal\"><span class=\"pre\">200</span></code> with content body. If the query doesn't match any results, the <code class=\"docutils literal\"><span class=\"pre\">results</span></code> field will be an empty array and <code class=\"docutils literal\"><span class=\"pre\">totalResults</span></code> will be 0. If an error occurs, such as the plugin being disabled or not configured, an exception will be returned.</p>   <h2>TSMETA Response</h2> <p>The TSMeta endpoint returns a list of matching TSMeta objects.</p> <pre data-language=\"javascript\">{\n  \"type\": \"TSMETA\",\n  \"query\": \"name:*\",\n  \"metric\": \"*\",\n  \"tags\": [],\n  \"limit\": 2,\n  \"time\": 675,\n  \"results\": [\n    {\n      \"tsuid\": \"0000150000070010D0\",\n      \"metric\": {\n        \"uid\": \"000015\",\n        \"type\": \"METRIC\",\n        \"name\": \"app.apache.connections\",\n        \"description\": \"\",\n        \"notes\": \"\",\n        \"created\": 1362655264,\n        \"custom\": null,\n        \"displayName\": \"\"\n      },\n      \"tags\": [\n        {\n          \"uid\": \"000007\",\n          \"type\": \"TAGK\",\n          \"name\": \"fqdn\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1362655264,\n          \"custom\": null,\n          \"displayName\": \"\"\n        },\n        {\n          \"uid\": \"0010D0\",\n          \"type\": \"TAGV\",\n          \"name\": \"web01.mysite.com\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1362720007,\n          \"custom\": null,\n          \"displayName\": \"\"\n        }\n      ],\n      \"description\": \"\",\n      \"notes\": \"\",\n      \"created\": 1362740528,\n      \"units\": \"\",\n      \"retention\": 0,\n      \"max\": 0,\n      \"min\": 0,\n      \"displayName\": \"\",\n      \"dataType\": \"\",\n      \"lastReceived\": 0,\n      \"totalDatapoints\": 0\n    },\n    {\n      \"tsuid\": \"0000150000070010D5\",\n      \"metric\": {\n        \"uid\": \"000015\",\n        \"type\": \"METRIC\",\n        \"name\": \"app.apache.connections\",\n        \"description\": \"\",\n        \"notes\": \"\",\n        \"created\": 1362655264,\n        \"custom\": null,\n        \"displayName\": \"\"\n      },\n      \"tags\": [\n        {\n          \"uid\": \"000007\",\n          \"type\": \"TAGK\",\n          \"name\": \"fqdn\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1362655264,\n          \"custom\": null,\n          \"displayName\": \"\"\n        },\n        {\n          \"uid\": \"0010D5\",\n          \"type\": \"TAGV\",\n          \"name\": \"web02.mysite.com\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1362720007,\n          \"custom\": null,\n          \"displayName\": \"\"\n        }\n      ],\n      \"description\": \"\",\n      \"notes\": \"\",\n      \"created\": 1362882263,\n      \"units\": \"\",\n      \"retention\": 0,\n      \"max\": 0,\n      \"min\": 0,\n      \"displayName\": \"\",\n      \"dataType\": \"\",\n      \"lastReceived\": 0,\n      \"totalDatapoints\": 0\n    }\n  ],\n  \"startIndex\": 0,\n  \"totalResults\": 9688066\n}\n</pre>\n   <h2>TSMETA_SUMMARY Response</h2> <p>The TSMeta Summary endpoint returns just the basic information associated with a timeseries including the TSUID, the metric name and tags. The search is run against the same index as the TSMeta query but returns a subset of the data.</p> <pre data-language=\"javascript\">{\n  \"type\": \"TSMETA_SUMMARY\",\n  \"query\": \"name:*\",\n  \"metric\": \"*\",\n  \"tags\": [],\n  \"limit\": 3,\n  \"time\": 565,\n  \"results\": [\n    {\n      \"tags\": {\n        \"fqdn\": \"web01.mysite.com\"\n      },\n      \"metric\": \"app.apache.connections\",\n      \"tsuid\": \"0000150000070010D0\"\n    },\n    {\n      \"tags\": {\n        \"fqdn\": \"web02.mysite.com\"\n      },\n      \"metric\": \"app.apache.connections\",\n      \"tsuid\": \"0000150000070010D5\"\n    },\n    {\n      \"tags\": {\n        \"fqdn\": \"web03.mysite.com\"\n      },\n      \"metric\": \"app.apache.connections\",\n      \"tsuid\": \"0000150000070010D6\"\n    }\n  ],\n  \"startIndex\": 0,\n  \"totalResults\": 9688066\n}\n</pre>\n   <h2>TSUIDS Response</h2> <p>The TSUIDs endpoint returns a list of TSUIDS that match the query. The search is run against the same index as the TSMeta query but returns a subset of the data.</p> <pre data-language=\"javascript\">{\n  \"type\": \"TSUIDS\",\n  \"query\": \"name:*\",\n  \"metric\": \"*\",\n  \"tags\": [],\n  \"limit\": 3,\n  \"time\": 517,\n  \"results\": [\n    \"0000150000070010D0\",\n    \"0000150000070010D5\",\n    \"0000150000070010D6\"\n  ],\n  \"startIndex\": 0,\n  \"totalResults\": 9688066\n}\n</pre>\n   <h2>UIDMETA Response</h2> <p>The UIDMeta endpoint returns a list of UIDMeta objects that match the query.</p> <pre data-language=\"javascript\">{\n  \"type\": \"UIDMETA\",\n  \"query\": \"name:*\",\n  \"metric\": \"*\",\n  \"tags\": [],\n  \"limit\": 3,\n  \"time\": 517,\n  \"results\": [\n    {\n      \"uid\": \"000007\",\n      \"type\": \"TAGK\",\n      \"name\": \"fqdn\",\n      \"description\": \"\",\n      \"notes\": \"\",\n      \"created\": 1362655264,\n      \"custom\": null,\n      \"displayName\": \"\"\n    },\n    {\n      \"uid\": \"0010D0\",\n      \"type\": \"TAGV\",\n      \"name\": \"web01.mysite.com\",\n      \"description\": \"\",\n      \"notes\": \"\",\n      \"created\": 1362720007,\n      \"custom\": null,\n      \"displayName\": \"\"\n    },\n    {\n      \"uid\": \"0010D5\",\n      \"type\": \"TAGV\",\n      \"name\": \"web02.mysite.com\",\n      \"description\": \"\",\n      \"notes\": \"\",\n      \"created\": 1362720007,\n      \"custom\": null,\n      \"displayName\": \"\"\n    }\n  ],\n  \"startIndex\": 0,\n  \"totalResults\": 9688066\n}\n</pre>\n   <h2>Annotation Response</h2> <p>The Annotation endpoint returns a list of Annotation objects that match the query.</p> <pre data-language=\"javascript\">{\n  \"type\": \"ANNOTATION\",\n  \"query\": \"description:*\",\n  \"metric\": \"*\",\n  \"tags\": [],\n  \"limit\": 25,\n  \"time\": 80,\n  \"results\": [\n    {\n      \"tsuid\": \"000001000001000001\",\n      \"description\": \"Testing Annotations\",\n      \"notes\": \"These would be details about the event, the description is just a summary\",\n      \"custom\": {\n        \"owner\": \"jdoe\",\n        \"dept\": \"ops\"\n      },\n      \"endTime\": 0,\n      \"startTime\": 1369141261\n    }\n  ],\n  \"startIndex\": 0,\n  \"totalResults\": 1\n}\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/search/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/search/index.html</a>\n  </p>\n</div>\n","api_http/tree/index":"<h1>/api/tree</h1> <p>Trees are meta data used to organize time series in a heirarchical structure for browsing similar to a typical file system. A number of endpoints under the <code class=\"docutils literal\"><span class=\"pre\">/tree</span></code> root allow working with various tree related data:</p>  <h2>Tree API Endpoints</h2> <div class=\"toctree-wrapper compound\"> <ul> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"branch\">/api/tree/branch</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"collisions\">/api/tree/collisions</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"notmatched\">/api/tree/notmatched</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"rule\">/api/tree/rule</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"rules\">/api/tree/rules</a></li> <li class=\"toctree-l1\"><a class=\"reference internal\" href=\"test\">/api/tree/test</a></li> </ul> </div> <p>The <code class=\"docutils literal\"><span class=\"pre\">/tree</span></code> endpoint allows for creating or modifying a tree definition. Tree definitions include configuration and meta data accessible via this endpoint, as well as the rule set accessiable via <code class=\"docutils literal\"><span class=\"pre\">/tree/rule</span></code> or <code class=\"docutils literal\"><span class=\"pre\">/tree/rules</span></code>.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">When creating a tree it will have the <code class=\"docutils literal\"><span class=\"pre\">enabled</span></code> field set to <code class=\"docutils literal\"><span class=\"pre\">false</span></code> by default. After creating a tree you should add rules then use the <code class=\"docutils literal\"><span class=\"pre\">tree/test</span></code> endpoint with a few TSUIDs to make sure the resulting tree will be what you expected. After you have verified the results, you can set the <code class=\"docutils literal\"><span class=\"pre\">enabled</span></code> field to <code class=\"docutils literal\"><span class=\"pre\">true</span></code> and new TSMeta objects or a tree synchronization will start to populate branches.</p> </div>   <h2>Verbs</h2> <ul class=\"simple\"> <li>GET - Retrieve one or more tree definitions</li> <li>POST - Edit tree fields</li> <li>PUT - Replace tree fields</li> <li>DELETE - Delete the results of a tree and/or the tree definition</li> </ul>   <h2>Requests</h2> <p>The following fields can be used for all tree endpoint requests:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>treeId</td> <td>Integer</td> <td>Required*</td> <td>Used to fetch or modify a specific tree. <a href=\"#id1\"><span class=\"problematic\" id=\"id2\">*</span></a>When creating a new tree, the <code class=\"docutils literal\"><span class=\"pre\">tree</span></code> value must not be present.</td> <td> </td> <td>treeid</td> <td>RO</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>name</td> <td>String</td> <td>Required*</td> <td>A brief, descriptive name for the tree. <a href=\"#id3\"><span class=\"problematic\" id=\"id4\">*</span></a>Required only when creating a tree.</td> <td> </td> <td>name</td> <td>RW</td> <td>Network Infrastructure</td> </tr> <tr class=\"row-even\">\n<td>description</td> <td>String</td> <td>Optional</td> <td>A longer description of what the tree contains</td> <td> </td> <td>description</td> <td>RW</td> <td>Tree containing all network gear</td> </tr> <tr class=\"row-odd\">\n<td>notes</td> <td>String</td> <td>Optional</td> <td>Detailed notes about the tree</td> <td> </td> <td>notes</td> <td>RW</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>strictMatch</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not timeseries should be included in the tree if they fail to match one or more rule levels.</td> <td>false</td> <td>strict_match</td> <td>RW</td> <td>true</td> </tr> <tr class=\"row-odd\">\n<td>enabled</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not TSMeta should be processed through the tree. By default this is set to <code class=\"docutils literal\"><span class=\"pre\">false</span></code> so that you can setup rules and test some objects before building branches.</td> <td>false</td> <td>enabled</td> <td>RW</td> <td>true</td> </tr> <tr class=\"row-even\">\n<td>storeFailures</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not collisions and 'not matched' TSUIDs should be recorded. This can create very wide rows.</td> <td>false</td> <td>store_failures</td> <td>RW</td> <td>true</td> </tr> <tr class=\"row-odd\">\n<td>definition</td> <td>Boolean</td> <td>Optional</td> <td>Used only when <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> ing a tree, if this flag is set to true, then the entire tree definition will be deleted along with all branches, collisions and not matched entries</td> <td>false</td> <td>definition</td> <td> </td> <td>true</td> </tr> </tbody> </table>   <h2>Response</h2> <p>A successful response to a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code>, <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> request will return tree objects with optinally requested changes. Successful <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> calls will return with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no body content. When modifying data, if no changes were present, i.e. the call did not provide any data to store, the resposne will be a <code class=\"docutils literal\"><span class=\"pre\">304</span></code> without any body content. If the requested tree did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied an <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned.</p> <p>All <strong>Request</strong> fields will be present in the response in addition to others:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>rules</td> <td>Map</td> <td>A map or dictionary with rules defined for the tree organized by <code class=\"docutils literal\"><span class=\"pre\">level</span></code> and <code class=\"docutils literal\"><span class=\"pre\">order</span></code>. If no rules have been defined yet, the value will be <code class=\"docutils literal\"><span class=\"pre\">null</span></code>\n</td> <td><em>See Examples</em></td> </tr> <tr class=\"row-odd\">\n<td>created</td> <td>Integer</td> <td>A Unix Epoch timestamp in seconds when the tree was originally created.</td> <td>1350425579</td> </tr> </tbody> </table>   <h2>GET</h2> <p>A <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> request to <code class=\"docutils literal\"><span class=\"pre\">/api/tree</span></code> without a tree ID will return a list of all of the trees configured in the system. The results will include configured rules for each tree. If no trees have been configured yet, the list will be empty.</p> <div class=\"section\" id=\"example-get-all-trees-query\"> <h3>Example GET All Trees Query</h3> <pre data-language=\"python\">http://localhost:4242/api/tree\n</pre>\n </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">[\n  {\n    \"name\": \"Test Tree\",\n    \"description\": \"My Description\",\n    \"notes\": \"Details\",\n    \"rules\": {\n      \"0\": {\n        \"0\": {\n          \"type\": \"TAGK\",\n          \"field\": \"host\",\n          \"regex\": \"\",\n          \"separator\": \"\",\n          \"description\": \"Hostname rule\",\n          \"notes\": \"\",\n          \"level\": 0,\n          \"order\": 0,\n          \"treeId\": 1,\n          \"customField\": \"\",\n          \"regexGroupIdx\": 0,\n          \"displayFormat\": \"\"\n        }\n      },\n      \"1\": {\n        \"0\": {\n          \"type\": \"METRIC\",\n          \"field\": \"\",\n          \"regex\": \"\",\n          \"separator\": \"\",\n          \"description\": \"\",\n          \"notes\": \"Metric rule\",\n          \"level\": 1,\n          \"order\": 0,\n          \"treeId\": 1,\n          \"customField\": \"\",\n          \"regexGroupIdx\": 0,\n          \"displayFormat\": \"\"\n        }\n      }\n    },\n    \"created\": 1356998400,\n    \"treeId\": 1,\n    \"strictMatch\": false,\n    \"storeFailures\": false,\n    \"enabled\": true\n  },\n  {\n    \"name\": \"2nd Tree\",\n    \"description\": \"Other Tree\",\n    \"notes\": \"\",\n    \"rules\": {\n      \"0\": {\n        \"0\": {\n          \"type\": \"TAGK\",\n          \"field\": \"host\",\n          \"regex\": \"\",\n          \"separator\": \"\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"level\": 0,\n          \"order\": 0,\n          \"treeId\": 2,\n          \"customField\": \"\",\n          \"regexGroupIdx\": 0,\n          \"displayFormat\": \"\"\n        }\n      },\n      \"1\": {\n        \"0\": {\n          \"type\": \"METRIC\",\n          \"field\": \"\",\n          \"regex\": \"\",\n          \"separator\": \"\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"level\": 1,\n          \"order\": 0,\n          \"treeId\": 2,\n          \"customField\": \"\",\n          \"regexGroupIdx\": 0,\n          \"displayFormat\": \"\"\n        }\n      }\n    },\n    \"created\": 1368964815,\n    \"treeId\": 2,\n    \"strictMatch\": false,\n    \"storeFailures\": false,\n    \"enabled\": false\n  }\n]\n</pre>\n <p>To fetch a specific tree, supply a <a href=\"#id5\"><span class=\"problematic\" id=\"id6\">``</span></a>treeId' value. The response will include the tree object if found. If the requested tree does not exist, a 404 exception will be returned.</p> </div> <div class=\"section\" id=\"example-get-single-tree\"> <h3>Example GET Single Tree</h3> <pre data-language=\"python\">http://localhost:4242/api/treeId?tree=1\n</pre>\n </div> <div class=\"section\" id=\"id7\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"name\": \"2nd Tree\",\n  \"description\": \"Other Tree\",\n  \"notes\": \"\",\n  \"rules\": {\n    \"0\": {\n      \"0\": {\n        \"type\": \"TAGK\",\n        \"field\": \"host\",\n        \"regex\": \"\",\n        \"separator\": \"\",\n        \"description\": \"\",\n        \"notes\": \"\",\n        \"level\": 0,\n        \"order\": 0,\n        \"treeId\": 2,\n        \"customField\": \"\",\n        \"regexGroupIdx\": 0,\n        \"displayFormat\": \"\"\n      }\n    },\n    \"1\": {\n      \"0\": {\n        \"type\": \"METRIC\",\n        \"field\": \"\",\n        \"regex\": \"\",\n        \"separator\": \"\",\n        \"description\": \"\",\n        \"notes\": \"\",\n        \"level\": 1,\n        \"order\": 0,\n        \"treeId\": 2,\n        \"customField\": \"\",\n        \"regexGroupIdx\": 0,\n        \"displayFormat\": \"\"\n      }\n    }\n  },\n  \"created\": 1368964815,\n  \"treeId\": 2,\n  \"strictMatch\": false,\n  \"storeFailures\": false,\n  \"enabled\": false\n}\n</pre>\n </div>   <h2>POST/PUT</h2> <p>Using the <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> methods, you can create a new tree or edit most of the fields for an existing tree. New trees require a <code class=\"docutils literal\"><span class=\"pre\">name</span></code> value and for the <code class=\"docutils literal\"><span class=\"pre\">treeId'</span> <span class=\"pre\">value</span> <span class=\"pre\">to</span> <span class=\"pre\">be</span> <span class=\"pre\">empty.</span> <span class=\"pre\">Existing</span> <span class=\"pre\">trees</span> <span class=\"pre\">require</span> <span class=\"pre\">a</span> <span class=\"pre\">valid</span> <span class=\"pre\">``treeId</span></code> ID and any fields that require modification. A successful request will return the modified tree object.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">A new tree will not have any rules. Your next call should probably be to <code class=\"docutils literal\"><span class=\"pre\">/tree/rule</span></code> or <code class=\"docutils literal\"><span class=\"pre\">/tree/rules</span></code>.</p> </div> <div class=\"section\" id=\"example-post-create-request\"> <h3>Example POST Create Request</h3> <pre data-language=\"python\">http://localhost:4242/api/tree?name=Network%20Tree&amp;method_override=post\n</pre>\n </div> <div class=\"section\" id=\"id8\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"name\": \"Network\",\n  \"description\": \"\",\n  \"notes\": \"\",\n  \"rules\": null,\n  \"created\": 1368964815,\n  \"treeId\": 3,\n  \"strictMatch\": false,\n  \"storeFailures\": false,\n  \"enabled\": false\n}\n</pre>\n </div> <div class=\"section\" id=\"example-post-edit-request\"> <h3>Example POST Edit Request</h3> <pre data-language=\"python\">http://localhost:4242/api/tree?treeId=3&amp;description=Network%20Device%20Information&amp;method_override=post\n</pre>\n </div> <div class=\"section\" id=\"id9\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"name\": \"Network\",\n  \"description\": \"Network Device Information\",\n  \"notes\": \"\",\n  \"rules\": null,\n  \"created\": 1368964815,\n  \"treeId\": 3,\n  \"strictMatch\": false,\n  \"storeFailures\": false,\n  \"enabled\": false\n}\n</pre>\n </div>   <h2>DELETE</h2> <p>Using the <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> method will remove only collisions, not matched entries and branches for the given tree from storage. This endpoint starts a delete. Because the delete can take some time, the endpoint will return a successful 204 response without data if the delete completed. If the tree was not found, it will return a 404. If you want to delete the tree definition itself, you can supply the <code class=\"docutils literal\"><span class=\"pre\">defintion</span></code> flag in the query string with a value of <code class=\"docutils literal\"><span class=\"pre\">true</span></code> and the tree and rule definitions will be removed as well.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">This method cannot be undone. Once executed, the purge will continue running unless the TSD is shutdown.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Before executing a <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> query, you should make sure that a manual tree syncronization is not running somehwere on your data. If it is, there may be some orphaned branches or leaves stored during the purge. Use the _____ CLi tool sometime after the delete to cleanup left over branches or leaves.</p> </div> <div class=\"section\" id=\"example-delete-request\"> <h3>Example DELETE Request</h3> <pre data-language=\"python\">http://localhost:4242/api/tree?tree=1&amp;method_override=delete\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/tree/index.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/tree/index.html</a>\n  </p>\n</div>\n","user_guide/query/aggregators":"<h1>Aggregators</h1> <p>OpenTSDB was designed to efficiently combine multiple, distinct time series during query execution. But how do you merge individual time series into a single series of data? Aggregation functions provide the means of mathematically merging the different data series into one, giving you a choice of various mathematical operations. Since OpenTSDB doesn't know whether or not a query will return multiple time series, an aggregation function is always required just in case.</p> <p>Aggregators have two methods of operation:</p>  <h2>Aggregation</h2> <p>Since OpenTSDB doesn't know whether a query will return multiple time series until it scans through all of the data, an aggregation function must be specified for every query just in case. When more than one series is found, the two series are <strong>aggregated</strong> together into a single time series. For each timestamp in the different time series, the aggregator will perform it's computation for each value in every time series at that timestamp. That is, the aggregator will work <em>across</em> all of the time series at each timestamp. The following table illustrates the <code class=\"docutils literal\"><span class=\"pre\">sum</span></code> aggregator as it works across time series <code class=\"docutils literal\"><span class=\"pre\">A</span></code> and <code class=\"docutils literal\"><span class=\"pre\">B</span></code> to produce series <code class=\"docutils literal\"><span class=\"pre\">Output</span></code>.</p> <table class=\"docutils\"> <colgroup> <col width=\"40%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">series</th> <th class=\"head\">ts0</th> <th class=\"head\">ts0+10s</th> <th class=\"head\">ts0+20s</th> <th class=\"head\">ts0+30s</th> <th class=\"head\">ts0+40s</th> <th class=\"head\">ts0+50s</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>A</td> <td>5</td> <td>5</td> <td>10</td> <td>15</td> <td>20</td> <td>5</td> </tr> <tr class=\"row-odd\">\n<td>B</td> <td>10</td> <td>5</td> <td>20</td> <td>15</td> <td>10</td> <td>0</td> </tr> <tr class=\"row-even\">\n<td>Output</td> <td>15</td> <td>10</td> <td>30</td> <td>30</td> <td>30</td> <td>5</td> </tr> </tbody> </table> <p>For timestamp <code class=\"docutils literal\"><span class=\"pre\">ts0</span></code> the data points for <code class=\"docutils literal\"><span class=\"pre\">A</span></code> and <code class=\"docutils literal\"><span class=\"pre\">B</span></code> are summed, i.e. <code class=\"docutils literal\"><span class=\"pre\">5</span> <span class=\"pre\">+</span> <span class=\"pre\">10</span> <span class=\"pre\">==</span> <span class=\"pre\">15</span></code>. Next, the two values for <code class=\"docutils literal\"><span class=\"pre\">ts1</span></code> are summed together to get <code class=\"docutils literal\"><span class=\"pre\">10</span></code> and so on. Each aggregation function will perform a different mathematical operation.</p> <div class=\"section\" id=\"interpolation\"> <h3>Interpolation</h3> <p>In the example above, both time series <code class=\"docutils literal\"><span class=\"pre\">A</span></code> and <code class=\"docutils literal\"><span class=\"pre\">B</span></code> had data points at every time stamp, they lined up neatly. However what happens when two series do not line up? It can be difficult, and sometimes undesired, to synchronize all sources of data to write at the exact same time. For example, if we have 10,000 servers sending 100 system metrics every 5 minutes, that would be a burst of 10M data points in a single second. We would need a pretty beefy network and cluster to accommodate that traffic. Not to mention the system would be sitting idle for the rest of 5 minutes. Instead it makes much more sense to splay the writes over time so that we have an average of 3,333 writes per second to reduce our hardware and network requirements.</p> <div class=\"sidebar\"> <p class=\"first sidebar-title\">Missing Data</p> <p class=\"last\">By \"missing\" we simply mean that a time series does not have a data point for the timestamp requested. Usually the data is simply time shifted before or after the requested timestamp, but it could actually be missing if the source or the TSD encountered an error and the data wasn't recorded.</p> </div> <p>How do you <em>sum</em> or find the <em>avg</em> of a number and something that doesn't exist? One option is to simply ignore the data points for all time series at the time stamp where any series is missing data. But if you have two time series and they are simply miss-aligned, your query would return an empty data set even though there is good data in storage, so that's not very useful.</p> <p>Another option is to define a scalar value (e.g. <code class=\"docutils literal\"><span class=\"pre\">0</span></code> or the maximum value for a Long) to use whenever a data point is missing. OpenTSDB 2.0 provides a few aggregation methods that substitute a scalar value for missing data points. These are useful when working with distinct value time series such as the number of sales in at a given time.</p> <p>However sometimes it doesn't make sense to define a scalar for missing data. Often you may be recording a monotonically increasing counter such as the number of bytes transmitted from a network interface. With a counter, we can use <strong>interpolation</strong> to make a guess as to what the value would be at that point in time. Interpolation takes two points and the time span between them to calculate a <em>best guess</em> value at the time stamp requested.</p> <p>Take a look at these two time series where the data is simply offset by 10 seconds:</p> <table class=\"docutils\"> <colgroup> <col width=\"30%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">series</th> <th class=\"head\">ts0</th> <th class=\"head\">ts0+10s</th> <th class=\"head\">ts0+20s</th> <th class=\"head\">ts0+30s</th> <th class=\"head\">ts0+40s</th> <th class=\"head\">ts0+50s</th> <th class=\"head\">ts0+60s</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>A</td> <td>na</td> <td>5</td> <td>na</td> <td>15</td> <td>na</td> <td>5</td> <td>na</td> </tr> <tr class=\"row-odd\">\n<td>B</td> <td>10</td> <td>na</td> <td>20</td> <td>na</td> <td>10</td> <td>na</td> <td>20</td> </tr> </tbody> </table> <p>When OpenTSDB is calculating an aggregation it starts at the first data point found for any series, in this case it will be the data for <code class=\"docutils literal\"><span class=\"pre\">B</span></code> at <code class=\"docutils literal\"><span class=\"pre\">ts0</span></code>. We request a value for <code class=\"docutils literal\"><span class=\"pre\">A</span></code> at <code class=\"docutils literal\"><span class=\"pre\">ts0</span></code> but there isn't any data there. We know that there is data for <code class=\"docutils literal\"><span class=\"pre\">A</span></code> at <code class=\"docutils literal\"><span class=\"pre\">ts0+10s</span></code> but since we don't have any value before that, we can't make a guess as to what it would be. Thus we simply return the value for <code class=\"docutils literal\"><span class=\"pre\">B</span></code>.</p> <p>Next we run across a value for <code class=\"docutils literal\"><span class=\"pre\">A</span></code> at time <code class=\"docutils literal\"><span class=\"pre\">ts0+10s</span></code>. We request a value for <code class=\"docutils literal\"><span class=\"pre\">ts0+10s</span></code> from time series <code class=\"docutils literal\"><span class=\"pre\">B</span></code> but there isn't one. But <code class=\"docutils literal\"><span class=\"pre\">B</span></code> knows there is a value at <code class=\"docutils literal\"><span class=\"pre\">ts0+20s</span></code> and we had a value at <code class=\"docutils literal\"><span class=\"pre\">ts0</span></code> so we can now calculate a guess for <code class=\"docutils literal\"><span class=\"pre\">ts0+10s</span></code>. The formula for linear interpolation is <code class=\"docutils literal\"><span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">y0</span> <span class=\"pre\">+</span> <span class=\"pre\">(y1</span> <span class=\"pre\">-</span> <span class=\"pre\">y0)</span> <span class=\"pre\">*</span> <span class=\"pre\">((x</span> <span class=\"pre\">-</span> <span class=\"pre\">x0)</span> <span class=\"pre\">/</span> <span class=\"pre\">(x1</span> <span class=\"pre\">-</span> <span class=\"pre\">x0))</span></code> where, for series <code class=\"docutils literal\"><span class=\"pre\">B</span></code>, <code class=\"docutils literal\"><span class=\"pre\">y0</span> <span class=\"pre\">=</span> <span class=\"pre\">10</span></code>, <code class=\"docutils literal\"><span class=\"pre\">y1</span> <span class=\"pre\">=</span> <span class=\"pre\">20</span></code>, <code class=\"docutils literal\"><span class=\"pre\">x</span> <span class=\"pre\">=</span> <span class=\"pre\">ts0+10s</span> <span class=\"pre\">(or</span> <span class=\"pre\">10)</span></code>, <code class=\"docutils literal\"><span class=\"pre\">x0</span> <span class=\"pre\">=</span> <span class=\"pre\">ts0</span> <span class=\"pre\">(or</span> <span class=\"pre\">0)</span></code> and <code class=\"docutils literal\"><span class=\"pre\">x1</span> <span class=\"pre\">=</span> <span class=\"pre\">ts0+20s</span> <span class=\"pre\">(or</span> <span class=\"pre\">20)</span></code>. Thus we have <code class=\"docutils literal\"><span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">10</span> <span class=\"pre\">+</span> <span class=\"pre\">(20</span> <span class=\"pre\">-</span> <span class=\"pre\">10)</span> <span class=\"pre\">*</span> <span class=\"pre\">((10</span> <span class=\"pre\">-</span> <span class=\"pre\">0)</span> <span class=\"pre\">/</span> <span class=\"pre\">(20</span> <span class=\"pre\">-</span> <span class=\"pre\">0)</span></code> which will reduce to <code class=\"docutils literal\"><span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">10</span> <span class=\"pre\">+</span> <span class=\"pre\">10</span> <span class=\"pre\">*</span> <span class=\"pre\">(10</span> <span class=\"pre\">/</span> <span class=\"pre\">20)</span></code> further reducing to <code class=\"docutils literal\"><span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">10</span> <span class=\"pre\">+</span> <span class=\"pre\">10</span> <span class=\"pre\">*</span> <span class=\"pre\">.5</span></code> and <code class=\"docutils literal\"><span class=\"pre\">y</span> <span class=\"pre\">=</span> <span class=\"pre\">10</span> <span class=\"pre\">+</span> <span class=\"pre\">5</span></code>. Therefore <code class=\"docutils literal\"><span class=\"pre\">B</span></code> will give us a <em>guestimated</em> value of <code class=\"docutils literal\"><span class=\"pre\">15</span></code> at <code class=\"docutils literal\"><span class=\"pre\">ts0+10s</span></code>.</p> <p>Iteration continues over every timestamp for which a data point is found for every series returned as a part of the query. The resulting series, using the <strong>sum</strong> aggregator, will look like this:</p> <table class=\"docutils\"> <colgroup> <col width=\"30%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">series</th> <th class=\"head\">ts0</th> <th class=\"head\">ts0+10s</th> <th class=\"head\">ts0+20s</th> <th class=\"head\">ts0+30s</th> <th class=\"head\">ts0+40s</th> <th class=\"head\">ts0+50s</th> <th class=\"head\">ts0+60s</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>A</td> <td>na</td> <td>5</td> <td>na</td> <td>15</td> <td>na</td> <td>5</td> <td>na</td> </tr> <tr class=\"row-odd\">\n<td>B</td> <td>10</td> <td>na</td> <td>20</td> <td>na</td> <td>10</td> <td>na</td> <td>20</td> </tr> <tr class=\"row-even\">\n<td>Interpolated A</td> <td>na</td> <td> </td> <td>10</td> <td> </td> <td>10</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>Interpolated B</td> <td> </td> <td>15</td> <td> </td> <td>15</td> <td> </td> <td>15</td> <td>na</td> </tr> <tr class=\"row-even\">\n<td>Summed Result</td> <td>10</td> <td>20</td> <td>30</td> <td>25</td> <td>20</td> <td>20</td> <td>20</td> </tr> </tbody> </table> <p><strong>More Examples:</strong> For the graphically inclined we have the following examples. An imaginary metric named <code class=\"docutils literal\"><span class=\"pre\">m</span></code> is recorded in OpenTSDB. The \"sum of m\" is the blue line at the top resulting from a query like <code class=\"docutils literal\"><span class=\"pre\">start=1h-ago&amp;m=sum:m</span></code>. It's made of the sum of the red line for <code class=\"docutils literal\"><span class=\"pre\">host=foo</span></code> and the green line for <code class=\"docutils literal\"><span class=\"pre\">host=bar</span></code>:</p> <img alt=\"../../_images/with-lerp.png\" src=\"http://opentsdb.net/docs/build/html/_images/with-lerp.png\"> <p>It seems intuitive from the image above that if you \"stack up\" the red line and the green line, you'd get the blue line. At any discrete point in time, the blue line has a value that is equal to the sum of the value of the red line and the value of the green line at that time. Without interpolation, you get something rather unintuitive that is harder to make sense of, and which is also a lot less meaningful and useful:</p> <img alt=\"../../_images/without-lerp.png\" src=\"http://opentsdb.net/docs/build/html/_images/without-lerp.png\"> <p>Notice how the blue line drops down to the green data point at 18:46:48. No need to be a mathematician or to have taken advanced maths classes to see that interpolation is needed to properly aggregate multiple time series together and get meaningful results.</p> <p>At the moment OpenTSDB only supports <strong>`linear interpolation &lt;http://en.wikipedia.org/wiki/Linear_interpolation&gt;`_</strong> (sometimes shortened \"lerp\") for sake of simplicity. Patches are welcome for those who would like to add other interpolation methods.</p> <p>Interpolation is only performed at query time when more than one time series are found to match a query. Many metrics collection systems interpolate on <em>write</em> so that you original value is never recorded. OpenTSDB stores your original value and lets you retrieve it at any time.</p> <p>Here is another slightly more complicated example that came from the mailing list, depicting how multiple time series are aggregated by average:</p> <a class=\"reference external image-reference\" href=\"../../_images/aggregation_average.png\"><img alt=\"Click the image to enlarge.\" src=\"http://opentsdb.net/docs/build/html/_images/aggregation-average_sm.png\"></a> <p>The thick blue line with triangles is the an aggregation with the <code class=\"docutils literal\"><span class=\"pre\">avg</span></code> function of multiple time series as per the query <code class=\"docutils literal\"><span class=\"pre\">start=1h-ago&amp;m=avg:duration_seconds</span></code>. As we can see, the resulting time series has one data point at each timestamp of all the underlying time series it aggregates, and that data point is computed by taking the average of the values of all the time series at that timestamp. This is also true for the lonely data point of the squared-purple time series, that temporarily boosted the average until the next data point.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Aggregation functions return integer or double values based on the input data points. If both source values are integers in storage, the resulting calculations will be integers. This means any fractional values resulting from the computation will be lopped off, no rounding will occur. If either data point is a floating point value, the result will be a floating point. However if downsampling or rates are enabled, the result will always be a float.</p> </div> </div>   <h2>Downsampling</h2> <p>The second method of operation for aggregation functions is <code class=\"docutils literal\"><span class=\"pre\">downsampling</span></code>. Since OpenTSDB stores data at the original resolution indefinitely, requesting data for a long time span can return millions of points. This can cause a burden on bandwidth or graphing libraries so it's common to request data at a lower resolution for longer spans. Downsampling breaks the long span of data into smaller spans and merges the data for the smaller span into a single data point. Aggregation functions will perform the same calculation as for an aggregation process but instead of working across data points for multiple time series at a single time stamp, downsampling works across multiple data points within a single time series over a given time span.</p> <p>For example, take series <code class=\"docutils literal\"><span class=\"pre\">A</span></code> and <code class=\"docutils literal\"><span class=\"pre\">B</span></code> in the first table under <strong>Aggregation</strong>. The data points cover a 50 second time span. Let's say we want to downsample that to 30 seconds. This will give us two data points for each series:</p> <table class=\"docutils\"> <colgroup> <col width=\"40%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">series</th> <th class=\"head\">ts0</th> <th class=\"head\">ts0+10s</th> <th class=\"head\">ts0+20s</th> <th class=\"head\">ts0+30s</th> <th class=\"head\">ts0+40s</th> <th class=\"head\">ts0+50s</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>A</td> <td>5</td> <td>5</td> <td>10</td> <td>15</td> <td>20</td> <td>5</td> </tr> <tr class=\"row-odd\">\n<td>A Downsampled</td> <td> </td> <td> </td> <td> </td> <td>35</td> <td> </td> <td>25</td> </tr> <tr class=\"row-even\">\n<td>B</td> <td>10</td> <td>5</td> <td>20</td> <td>15</td> <td>10</td> <td>0</td> </tr> <tr class=\"row-odd\">\n<td>B Downsampled</td> <td> </td> <td> </td> <td> </td> <td>50</td> <td> </td> <td>10</td> </tr> <tr class=\"row-even\">\n<td>Aggregated Result</td> <td> </td> <td> </td> <td> </td> <td>85</td> <td> </td> <td>35</td> </tr> </tbody> </table> <p>For early versions of OpenTSDB, the actual time stamps for the new data points will be an average of the time stamps for each data point in the time span. As of 2.1 and later, the timestamp for each point is aligned to the start of a time bucket based on a modulo of the current time and the downsample interval.</p> <p>Note that when a query specifies a down sampling function and multiple time series are returned, downsampling occurs <strong>before</strong> aggregation. I.e. now that we have <code class=\"docutils literal\"><span class=\"pre\">A</span> <span class=\"pre\">Downsampled</span></code> and <code class=\"docutils literal\"><span class=\"pre\">B</span> <span class=\"pre\">Downsampled</span></code> we can aggregate the two series to come up with the aggregated result on the bottom line.</p>   <h2>Fill Policies</h2> <p>With version 2.2 you can specify a fill policy when downsampling to substitute values for use in cross-series aggregations when data points are \"missing\". Because OpenTSDB does not impose constraints on time alignment or when values are supposed to exist, such constraints must be specified at query time. At serialization time, if all series are missing values for an expected timestamp, nothing is emitted. For example, if a series is writing data every minute from T0 to T4, but for some reason the source fails to write data at T3, only 4 values will be serialized when the user may expect 5. With fill policies you can now choose what value is emitted for T3.</p> <p>When aggregating multiple series OpenTSDB generally performs linear interpolation when a series is missing a value at a timestamp present in one or more other series. Some aggregators substitute specific values such as zero, min or max values. With fill policies you can modify aggregation behavior by flagging a missing value as a NaN or a scalar such as zero. When a NaN is emitted for a series, it is skipped for all calculations. For example, if a query asks for the average of a metric and one or more series are missing values, substituting a 0 would drive down the average and lerping introduces non-extant values. However with NaNs we can flag the value as missing and skip it in the calculation.</p> <p>Available polices include:</p> <ul class=\"simple\"> <li>None (<code class=\"docutils literal\"><span class=\"pre\">none</span></code>) - The default behavior that does not emit missing values during serialization and performs linear interpolation (or otherwise specified interpolation) when aggregating series.</li> <li>NaN (<code class=\"docutils literal\"><span class=\"pre\">nan</span></code>) - Emits a <code class=\"docutils literal\"><span class=\"pre\">NaN</span></code> in the serialization output when all values are missing in a series. Skips series in aggregations when the value is missing.</li> <li>Null (<code class=\"docutils literal\"><span class=\"pre\">null</span></code>) - Same behavior as NaN except that during serialization it emits a <code class=\"docutils literal\"><span class=\"pre\">null</span></code> instead of a <code class=\"docutils literal\"><span class=\"pre\">NaN</span></code>.</li> <li>Zero (<code class=\"docutils literal\"><span class=\"pre\">zero</span></code>) - Substitutes a zero when a timestamp is missing. The zero value will be incorporated in aggregated results.</li> </ul> <p>(The terms in parentheses can be used in downsampling specifications, e.g. <code class=\"docutils literal\"><span class=\"pre\">1h-sum-nan</span></code>)</p> <p>An example with the NaN fill policy and downsampling on 10 seconds:</p> <table class=\"docutils\"> <colgroup> <col width=\"30%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> <col width=\"10%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">series</th> <th class=\"head\">ts0</th> <th class=\"head\">ts0+10s</th> <th class=\"head\">ts0+20s</th> <th class=\"head\">ts0+30s</th> <th class=\"head\">ts0+40s</th> <th class=\"head\">ts0+50s</th> <th class=\"head\">ts0+60s</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>A</td> <td>na</td> <td>na</td> <td>na</td> <td>15</td> <td>na</td> <td>5</td> <td>na</td> </tr> <tr class=\"row-odd\">\n<td>B</td> <td>10</td> <td>na</td> <td>20</td> <td>na</td> <td>na</td> <td>na</td> <td>20</td> </tr> <tr class=\"row-even\">\n<td>Interpolated A</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td> </td> <td>NaN</td> <td> </td> <td>NaN</td> </tr> <tr class=\"row-odd\">\n<td>Interpolated B</td> <td> </td> <td>NaN</td> <td> </td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>Summed Result</td> <td>10</td> <td>NaN</td> <td>20</td> <td>15</td> <td>NaN</td> <td>5</td> <td>20</td> </tr> </tbody> </table>   <h2>Available Aggregators</h2> <p>The following is a description of the aggregation functions available in OpenTSDB.</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"40%\"> <col width=\"40%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Aggregator</th> <th class=\"head\">Description</th> <th class=\"head\">Interpolation</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>avg</td> <td>Averages the data points</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>count</td> <td>The number of raw data points in the set</td> <td>Zero if missing</td> </tr> <tr class=\"row-even\">\n<td>dev</td> <td>Calculates the standard deviation</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>ep50r3</td> <td>Calculates the estimated 50th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>ep50r7</td> <td>Calculates the estimated 50th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>ep75r3</td> <td>Calculates the estimated 75th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>ep75r7</td> <td>Calculates the estimated 75th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>ep90r3</td> <td>Calculates the estimated 90th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>ep90r7</td> <td>Calculates the estimated 90th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>ep95r3</td> <td>Calculates the estimated 95th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>ep95r7</td> <td>Calculates the estimated 95th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>ep99r3</td> <td>Calculates the estimated 99th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>ep99r7</td> <td>Calculates the estimated 99th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>ep999r3</td> <td>Calculates the estimated 999th percentile with the R-3 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>ep999r7</td> <td>Calculates the estimated 999th percentile with the R-7 method *</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>mimmin</td> <td>Selects the smallest data point</td> <td>Maximum if missing</td> </tr> <tr class=\"row-even\">\n<td>mimmax</td> <td>Selects the largest data point</td> <td>Minimum if missing</td> </tr> <tr class=\"row-odd\">\n<td>min</td> <td>Selects the smallest data point</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>max</td> <td>Selects the largest data point</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>none</td> <td>Skips group by aggregation of all time series. (2.3)</td> <td>Zero if missing</td> </tr> <tr class=\"row-even\">\n<td>p50</td> <td>Calculates the 50th percentile</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>p75</td> <td>Calculates the 75th percentile</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>p90</td> <td>Calculates the 90th percentile</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>p95</td> <td>Calculates the 95th percentile</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>p99</td> <td>Calculates the 99th percentile</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>p999</td> <td>Calculates the 999th percentile</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-even\">\n<td>sum</td> <td>Adds the data points together</td> <td>Linear Interpolation</td> </tr> <tr class=\"row-odd\">\n<td>zimsum</td> <td>Adds the data points together</td> <td>Zero if missing</td> </tr> </tbody> </table> <p>* For percentile calculations, see the <a class=\"reference external\" href=\"http://en.wikipedia.org/wiki/Quantile\">Wikipedia</a> article. For high cardinality calculations, using the estimated percentiles may be more performant.</p> <div class=\"section\" id=\"avg\"> <h3>Avg</h3> <p>Calculates the average of all values across the time span or across multiple time series. This function will perform linear interpolation across time series. It's useful for looking at gauge metrics. Note that even though the calculation will usually result in a float, if the data points are recorded as integers, an integer will be returned losing some precision.</p> </div> <div class=\"section\" id=\"count\"> <h3>Count</h3> <p>Returns the number of data points stored in the series or range. When used to aggregate multiple series, zeros will be substituted. It's best to use this when downsampling.</p> </div> <div class=\"section\" id=\"dev\"> <h3>Dev</h3> <p>Calculates the <a class=\"reference external\" href=\"http://en.wikipedia.org/wiki/Standard_deviation\">standard deviation</a> across a span or time series. This function will perform linear interpolation across time series. It's useful for looking at gauge metrics. Note that even though the calculation will usually result in a float, if the data points are recorded as integers, an integer will be returned losing some precision.</p> </div> <div class=\"section\" id=\"estimated-percentiles\"> <h3>Estimated Percentiles</h3> <p>Calculates various percentiles using a choice of algorithms. These are useful for series with many data points as some data may be kicked out of the calculation. When used to aggregate multiple series, the function will perform linear interpolation. See <a class=\"reference external\" href=\"http://en.wikipedia.org/wiki/Quantile\">Wikipedia</a> for details. Implementation is through the <a class=\"reference external\" href=\"http://commons.apache.org/proper/commons-math/\">Apache Math library.</a></p> </div> <div class=\"section\" id=\"max\"> <h3>Max</h3> <p>The inverse of <code class=\"docutils literal\"><span class=\"pre\">min</span></code>, it returns the largest data point from all of the time series or within a time span. This function will perform linear interpolation across time series. It's useful for looking at the upper bounds of gauge metrics.</p> </div> <div class=\"section\" id=\"mimmin\"> <h3>MimMin</h3> <p>The \"maximum if missing minimum\" function returns only the smallest data point from all of the time series or within the time span. This function will <em>not</em> perform interpolation, instead it will return the maximum value for the type of data specified if the value is missing. This will return the Long.MaxValue for integer points or Double.MaxValue for floating point values. See <a class=\"reference external\" href=\"http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html\">Primitive Data Types</a> for details. It's useful for looking at the lower bounds of gauge metrics.</p> </div> <div class=\"section\" id=\"mimmax\"> <h3>MimMax</h3> <p>The \"minimum if missing maximum\" function returns only the largest data point from all of the time series or within the time span. This function will <em>not</em> perform interpolation, instead it will return the minimum value for the type of data specified if the value is missing. This will return the Long.MinValue for integer points or Double.MinValue for floating point values. See <a class=\"reference external\" href=\"http://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html\">Primitive Data Types</a> for details. It's useful for looking at the upper bounds of gauge metrics.</p> </div> <div class=\"section\" id=\"min\"> <h3>Min</h3> <p>Returns only the smallest data point from all of the time series or within the time span. This function will perform linear interpolation across time series. It's useful for looking at the lower bounds of gauge metrics.</p> </div> <div class=\"section\" id=\"none\"> <h3>None</h3> <p>(2.3) Skips group by aggregation. This aggregator is useful for fetching the <em>raw</em> data from storage as it will return a result set for every time series matching the filters. Note that the query will throw an exception if used with a downsampler.</p> </div> <div class=\"section\" id=\"percentiles\"> <h3>Percentiles</h3> <p>Calculates various percentiles. When used to aggregate multiple series, the function will perform linear interpolation. Implementation is through the <a class=\"reference external\" href=\"http://commons.apache.org/proper/commons-math/\">Apache Math library.</a></p> </div> <div class=\"section\" id=\"sum\"> <h3>Sum</h3> <p>Calculates the sum of all data points from all of the time series or within the time span if down sampling. This is the default aggregation function for the GUI as it's often the most useful when combining multiple time series such as gauges or counters. It performs linear interpolation when data points fail to line up. If you have a distinct series of values that you want to sum and you do not need interpolation, look at <code class=\"docutils literal\"><span class=\"pre\">zimsum</span></code></p> </div> <div class=\"section\" id=\"zimsum\"> <h3>ZimSum</h3> <p>Calculates the sum of all data points at the specified timestamp from all of the time series or within the time span. This function does <em>not</em> perform interpolation, instead it substitues a <code class=\"docutils literal\"><span class=\"pre\">0</span></code> for missing data points. This can be useful when working with discrete values.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/query/aggregators.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/query/aggregators.html</a>\n  </p>\n</div>\n","api_http/uid/uidmeta":"<h1>/api/uid/uidmeta</h1> <p>This endpoint enables editing or deleting UID meta data information, that is meta data associated with <em>metrics</em>, <em>tag names</em> and <em>tag values</em>. Some fields are set by the TSD but others can be set by the user. When using the <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> method, only the fields supplied with the request will be stored. Existing fields that are not included will be left alone. Using the <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> method will overwrite all user mutable fields with given values or defaults if a given field is not provided.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Deleting a meta data entry will not delete the UID assignment nor will it delete any data points or associated timeseries information. Deletion only removes the specified meta data object, not the actual value. If you query for the same UID, you'll see the default meta data with empty fields.</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET - Query string only</li> <li>POST - Updates only the fields provided</li> <li>PUT - Overwrites all user configurable meta data fields</li> <li>DELETE - Deletes the UID meta data</li> </ul>   <h2>Requests</h2> <p>Fields that can be supplied with a request include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>uid</td> <td>String</td> <td>Required</td> <td>A hexadecimal representation of the UID</td> <td> </td> <td>uid</td> <td>RO</td> <td>00002A</td> </tr> <tr class=\"row-odd\">\n<td>type</td> <td>String</td> <td>Required</td> <td>The type of UID, must be <code class=\"docutils literal\"><span class=\"pre\">metric</span></code>, <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code>\n</td> <td> </td> <td>type</td> <td>RO</td> <td>metric</td> </tr> <tr class=\"row-even\">\n<td>description</td> <td>String</td> <td>Optional</td> <td>A brief description of what the UID represents</td> <td> </td> <td>description</td> <td>RW</td> <td>System processor time</td> </tr> <tr class=\"row-odd\">\n<td>displayName</td> <td>String</td> <td>Optional</td> <td>A short name that can be displayed in GUIs instead of the default name</td> <td> </td> <td>display_name</td> <td>RW</td> <td>System CPU Time</td> </tr> <tr class=\"row-even\">\n<td>notes</td> <td>String</td> <td>Optional</td> <td>Detailed notes about what the UID represents</td> <td> </td> <td>notes</td> <td>RW</td> <td>Details</td> </tr> <tr class=\"row-odd\">\n<td>custom</td> <td>Map</td> <td>Optional</td> <td>A key/value map to store custom fields and values</td> <td>null</td> <td> </td> <td>RW</td> <td><em>See Below</em></td> </tr> </tbody> </table> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Custom fields cannot be passed via query string. You must use the <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> verbs.</p> </div> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">If your request uses <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code>, any fields that you do not supply with the request will be overwritten with their default values. For example, the <code class=\"docutils literal\"><span class=\"pre\">description</span></code> field will be set to an emtpy string and the <code class=\"docutils literal\"><span class=\"pre\">custom</span></code> field will be reset to <code class=\"docutils literal\"><span class=\"pre\">null</span></code>.</p> </div> <div class=\"section\" id=\"example-get-request\"> <h3>Example GET Request</h3> <pre data-language=\"python\">http://localhost:4242/api/uid/uidmeta?uid=00002A&amp;type=metric\n</pre>\n </div> <div class=\"section\" id=\"example-post-or-put-request\"> <h3>Example POST or PUT Request</h3> <p><em>Query String:</em></p> <pre data-language=\"python\">http://localhost:4242/api/uid/uidmeta?uid=00002A&amp;type=metric&amp;method=post&amp;display_name=System%20CPU%20Time\n</pre>\n <p><em>JSON Content:</em></p> <pre data-language=\"javascript\">{\n  \"uid\":\"00002A\",\n  \"type\":\"metric\",\n  \"displayName\":\"System CPU Time\",\n  \"custom\": {\n    \"owner\": \"Jane Doe\",\n    \"department\": \"Operations\",\n    \"assetTag\": \"12345\"\n  }\n}\n</pre>\n </div> <div class=\"section\" id=\"example-delete-request\"> <h3>Example DELETE Request</h3> <p><em>Query String:</em></p> <pre data-language=\"python\">http://localhost:4242/api/uid/uidmeta?uid=00002A&amp;type=metric&amp;method=delete\n</pre>\n <p><em>JSON Content:</em></p> <pre data-language=\"javascript\">{\n  \"uid\":\"00002A\",\n  \"type\":\"metric\"\n}\n</pre>\n </div>   <h2>Response</h2> <p>A successful response to a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code>, <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> request will return the full UID meta data object with any given changes. Successful <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> calls will return with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no body content. When modifying data, if no changes were present, i.e. the call did not provide any data to store, the response will be a <code class=\"docutils literal\"><span class=\"pre\">304</span></code> without any body content. If the requested UID did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied an error will be returned.</p> <p>All <strong>Request</strong> fields will be present in the response in addition to a couple of others:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>name</td> <td>String</td> <td>The name of the UID as given when the data point was stored or the UID assigned</td> <td>sys.cpu.0</td> </tr> <tr class=\"row-odd\">\n<td>created</td> <td>Integer</td> <td>A Unix epoch timestamp in seconds when the UID was first created. If the meta data was not stored when the UID was assigned, this value may be 0.</td> <td>1350425579</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"uid\": \"00002A\",\n  \"type\": \"TAGV\",\n  \"name\": \"web01.mysite.com\",\n  \"description\": \"Website hosting server\",\n  \"notes\": \"This server needs a new boot disk\",\n  \"created\": 1350425579,\n  \"custom\": {\n    \"owner\": \"Jane Doe\",\n    \"department\": \"Operations\",\n    \"assetTag\": \"12345\"\n  },\n  \"displayName\": \"Webserver 01\"\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/uid/uidmeta.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/uid/uidmeta.html</a>\n  </p>\n</div>\n","api_http/uid/tsmeta":"<h1>/api/uid/tsmeta</h1> <p>This endpoint enables searching, editing or deleting timeseries meta data information, that is meta data associated with a specific timeseries associated with a <em>metric</em> and one or more <em>tag name/value</em> pairs. Some fields are set by the TSD but others can be set by the user. When using the <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> method, only the fields supplied with the request will be stored. Existing fields that are not included will be left alone. Using the <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> method will overwrite all user mutable fields with given values or defaults if a given field is not provided.</p> <p>Please note that deleting a meta data entry will not delete the data points stored for the timeseries. Neither will it remove the UID assignments or associated UID meta objects.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET - Lookup one or more TS meta data</li> <li>POST - Updates only the fields provided</li> <li>PUT - Overwrites all user configurable meta data fields</li> <li>DELETE - Deletes the TS meta data</li> </ul>   <h2>GET Requests</h2> <p>A GET request can lookup the TS meta objects for one or more time series if they exist in the storage system. Two types of queries are supported:</p> <ul class=\"simple\"> <li>\n<strong>tsuid</strong> - A single hexadecimal TSUID may be supplied and a meta data object will be returned if located. The results will include a single object.</li> <li>\n<strong>metric</strong> - <em>(Version 2.1)</em> Similar to a data point query, you can supply a metric and one or more tag pairs. Any TS meta data matching the query will be returned. The results will be an array of one or more objects. Only one metric query may be supplied per call and wild cards or grouping operators are not supported.</li> </ul> <div class=\"section\" id=\"example-tsuid-get-request\"> <h3>Example TSUID GET Request</h3> <pre data-language=\"python\">http://localhost:4242/api/uid/tsmeta?tsuid=00002A000001000001\n</pre>\n </div> <div class=\"section\" id=\"example-metric-get-request\"> <h3>Example Metric GET Request</h3> <pre data-language=\"python\">http://localhost:4242/api/uid/tsmeta?m=sys.cpu.nice&amp;dc=lga\n</pre>\n </div>   <h2>POST/PUT Requests</h2> <p>By default, you may only write data to a TS meta object if it already exists. TS meta data is created via the meta sync CLI command or in real-time as data points are written. If you attempt to write data to the tsmeta endpoint for a TSUID that does not exist, an error will be returned and no data will be saved.</p> <p>Fields that can be supplied with a request include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>tsuid</td> <td>String</td> <td>Required</td> <td>A hexadecimal representation of the timeseries UID</td> <td> </td> <td>tsuid</td> <td>RO</td> <td>00002A000001000001</td> </tr> <tr class=\"row-odd\">\n<td>description</td> <td>String</td> <td>Optional</td> <td>A brief description of what the UID represents</td> <td> </td> <td>description</td> <td>RW</td> <td>System processor time</td> </tr> <tr class=\"row-even\">\n<td>displayName</td> <td>String</td> <td>Optional</td> <td>A short name that can be displayed in GUIs instead of the default name</td> <td> </td> <td>display_name</td> <td>RW</td> <td>System CPU Time</td> </tr> <tr class=\"row-odd\">\n<td>notes</td> <td>String</td> <td>Optional</td> <td>Detailed notes about what the UID represents</td> <td> </td> <td>notes</td> <td>RW</td> <td>Details</td> </tr> <tr class=\"row-even\">\n<td>custom</td> <td>Map</td> <td>Optional</td> <td>A key/value map to store custom fields and values</td> <td>null</td> <td> </td> <td>RW</td> <td><em>See Below</em></td> </tr> <tr class=\"row-odd\">\n<td>units</td> <td>String</td> <td>Optional</td> <td>Units reflective of the data stored in the timeseries, may be used in GUIs or calculations</td> <td> </td> <td>units</td> <td>RW</td> <td>Mbps</td> </tr> <tr class=\"row-even\">\n<td>dataType</td> <td>String</td> <td>Optional</td> <td>The kind of data stored in the timeseries such as <code class=\"docutils literal\"><span class=\"pre\">counter</span></code>, <code class=\"docutils literal\"><span class=\"pre\">gauge</span></code>, <code class=\"docutils literal\"><span class=\"pre\">absolute</span></code>, etc. These may be defined later but they should be similar to Data Source Types in an <a class=\"reference external\" href=\"http://oss.oetiker.ch/rrdtool\">RRD</a>\n</td> <td> </td> <td>data_type</td> <td>RW</td> <td>counter</td> </tr> <tr class=\"row-odd\">\n<td>retention</td> <td>Integer</td> <td>Optional</td> <td>The number of days of data points to retain for the given timeseries. <strong>Not Implemented</strong>. When set to 0, the default, data is retained indefinitely.</td> <td>0</td> <td>retention</td> <td>RW</td> <td>365</td> </tr> <tr class=\"row-even\">\n<td>max</td> <td>Float</td> <td>Optional</td> <td>An optional maximum value for this timeseries that may be used in calculations such as percent of maximum. If the default of <code class=\"docutils literal\"><span class=\"pre\">NaN</span></code> is present, the value is ignored.</td> <td>NaN</td> <td>max</td> <td>RW</td> <td>1024</td> </tr> <tr class=\"row-odd\">\n<td>min</td> <td>Float</td> <td>Optional</td> <td>An optional minimum value for this timeseries that may be used in calculations such as percent of minimum. If the default of <code class=\"docutils literal\"><span class=\"pre\">NaN</span></code> is present, the value is ignored.</td> <td>NaN</td> <td>min</td> <td>RW</td> <td>0</td> </tr> </tbody> </table> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Custom fields cannot be passed via query string. You must use the <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> verbs.</p> </div> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">If your request uses <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code>, any fields that you do not supply with the request will be overwritten with their default values. For example, the <code class=\"docutils literal\"><span class=\"pre\">description</span></code> field will be set to an emtpy string and the <code class=\"docutils literal\"><span class=\"pre\">custom</span></code> field will be reset to <code class=\"docutils literal\"><span class=\"pre\">null</span></code>.</p> </div> <p>With OpenTSDB 2.1 you may supply a metric style query and, if UIDs exist for the given metric and tags, a new TS meta object will be stored. Data may be supplied via POST for the fields above as per a normal request, however the <code class=\"docutils literal\"><span class=\"pre\">tsuid</span></code> field must be left empty. Additionally two query string parameters must be supplied:</p> <ul class=\"simple\"> <li>\n<strong>m</strong> - A metric and tags similar to a GET request or data point query</li> <li>\n<strong>create</strong> - A flag with a value of <code class=\"docutils literal\"><span class=\"pre\">true</span></code>\n</li> </ul> <p>For example:</p> <pre data-language=\"python\">http://localhost:4242/api/uid/tsmeta?display_name=Testing&amp;m=sys.cpu.nice{host=web01,dc=lga}&amp;create=true&amp;method_override=post\n</pre>\n <p>If a TS meta object already exists in storage for the given metric and tags, the fields will be updated or overwritten.</p> <div class=\"section\" id=\"example-post-or-put-request\"> <h3>Example POST or PUT Request</h3> <p><em>Query String:</em></p> <pre data-language=\"python\">http://localhost:4242/api/uid/tsmeta?tsuid=00002A000001000001&amp;method_override=post&amp;display_name=System%20CPU%20Time\n</pre>\n <p><em>JSON Content:</em></p> <pre data-language=\"javascript\">{\n  \"tsuid\":\"00002A000001000001\",\n  \"displayName\":\"System CPU Time for Webserver 01\",\n  \"custom\": {\n    \"owner\": \"Jane Doe\",\n    \"department\": \"Operations\",\n    \"assetTag\": \"12345\"\n  }\n}\n</pre>\n </div> <div class=\"section\" id=\"example-delete-request\"> <h3>Example DELETE Request</h3> <p><em>Query String:</em></p> <pre data-language=\"python\">http://localhost:4242/api/uid/tsmeta?tsuid=00002A000001000001&amp;method_override=delete\n</pre>\n <p><em>JSON Content:</em></p> <pre data-language=\"javascript\">{\n  \"tsuid\":\"00002A000001000001\"\n}\n</pre>\n </div>   <h2>Response</h2> <p>A successful response to a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code>, <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> request will return the full TS meta data object with any given changes. Successful <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> calls will return with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no body content. When modifying data, if no changes were present, i.e. the call did not provide any data to store, the resposne will be a <code class=\"docutils literal\"><span class=\"pre\">304</span></code> without any body content. If the requested TSUID did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied an error will be returned.</p> <p>All <strong>Request</strong> fields will be present in the response in addition to others:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>metric</td> <td>UIDMeta</td> <td>A UID meta data object representing information about the UID</td> <td><em>See Below</em></td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Array of UIDMeta</td> <td>A list of tag name / tag value UID meta data objects associated with the timeseries. The <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> UID will be first followed by it's corresponding <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> object.</td> <td><em>See Below</em></td> </tr> <tr class=\"row-even\">\n<td>created</td> <td>Integer</td> <td>A Unix epoch timestamp, in seconds, when the timeseries was first recorded in the system. Note that if the TSD was upgraded or meta data recently enabled, this value may not be accurate. Run the <a class=\"reference internal\" href=\"../../user_guide/cli/uid\"><em>uid</em></a> utility to synchronize meta data.</td> <td>1350425579</td> </tr> <tr class=\"row-odd\">\n<td>lastReceived</td> <td>Integer</td> <td>A Unix epoch timestamp, in seconds, when a data point was last recieved. This is only updated on TSDs where meta data is enabled and it is not updated for every data point so there may be some lag.</td> <td>1350425579</td> </tr> <tr class=\"row-even\">\n<td>totalDatapoints</td> <td>Integer</td> <td>The total number of data points recorded for the timeseries. NOTE: This may not be accurate unless you have enabled metadata tracking since creating the TSDB tables.</td> <td>3242322</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"tsuid\": \"00002A000001000001\",\n  \"metric\": {\n    \"uid\": \"00002A\",\n    \"type\": \"METRIC\",\n    \"name\": \"sys.cpu.0\",\n    \"description\": \"System CPU Time\",\n    \"notes\": \"\",\n    \"created\": 1350425579,\n    \"custom\": null,\n    \"displayName\": \"\"\n  },\n  \"tags\": [\n    {\n      \"uid\": \"000001\",\n      \"type\": \"TAGK\",\n      \"name\": \"host\",\n      \"description\": \"Server Hostname\",\n      \"notes\": \"\",\n      \"created\": 1350425579,\n      \"custom\": null,\n      \"displayName\": \"Hostname\"\n    },\n    {\n      \"uid\": \"000001\",\n      \"type\": \"TAGV\",\n      \"name\": \"web01.mysite.com\",\n      \"description\": \"Website hosting server\",\n      \"notes\": \"\",\n      \"created\": 1350425579,\n      \"custom\": null,\n      \"displayName\": \"Web Server 01\"\n    }\n  ],\n  \"description\": \"Measures CPU activity\",\n  \"notes\": \"\",\n  \"created\": 1350425579,\n  \"units\": \"\",\n  \"retention\": 0,\n  \"max\": \"NaN\",\n  \"min\": \"NaN\",\n  \"custom\": {\n    \"owner\": \"Jane Doe\",\n    \"department\": \"Operations\",\n    \"assetTag\": \"12345\"\n  },\n  \"displayName\": \"\",\n  \"dataType\": \"absolute\",\n  \"lastReceived\": 1350425590,\n  \"totalDatapoints\", 12532\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/uid/tsmeta.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/uid/tsmeta.html</a>\n  </p>\n</div>\n","api_http/search/lookup":"<h1>/api/search/lookup</h1> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Available in 2.1</p> </div> <p>Lookup queries use either the meta data table or the main data table to determine what time series are associated with a given metric, tag name, tag value, tag pair or combination thereof. For example, if you want to know what metrics are available for a tag pair <code class=\"docutils literal\"><span class=\"pre\">host=web01</span></code> you can execute a lookup to find out. Lookups do not require a search plugin to be installed.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Lookups are performed against the <code class=\"docutils literal\"><span class=\"pre\">tsdb-meta</span></code> table. You must enable real-time meta data creation or perform a <code class=\"docutils literal\"><span class=\"pre\">metasync</span></code> using the <code class=\"docutils literal\"><span class=\"pre\">uid</span></code> command in order to retreive data from a lookup. Lookups can be executed against the raw data table using the CLI command only: <a class=\"reference internal\" href=\"../../user_guide/cli/search\"><em>search</em></a></p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>Parameters used by the lookup endpoint include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>query</td> <td>String</td> <td>Required</td> <td>A lookup query as defined below.</td> <td> </td> <td>m</td> <td> </td> <td>tsd.hbase.rpcs{type=*}</td> </tr> <tr class=\"row-odd\">\n<td>useMeta</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to use the meta data table or the raw data table. The raw table will be much slower.</td> <td>False</td> <td>use_meta</td> <td> </td> <td>True</td> </tr> </tbody> </table> <div class=\"section\" id=\"lookup-queries\"> <h3>Lookup Queries</h3> <p>A lookup query consists of at least one metric, tag name (tagk) or tag value (tagv). Each value must be a literal name in the UID table. If a given name cannot be resolved to a UID, an exception will be returned. Only one metric can be supplied per query but multiple tagk, tagv or tag pairs may be provided.</p> <p>Normally, tags a provided in the format <code class=\"docutils literal\"><span class=\"pre\">&lt;tagk&gt;=&lt;tagv&gt;</span></code> and a value is required on either side of the equals sign. However for lookups, one value may an asterisk <code class=\"docutils literal\"><span class=\"pre\">*</span></code>, i.e. <code class=\"docutils literal\"><span class=\"pre\">&lt;tagk&gt;=*</span></code> or <code class=\"docutils literal\"><span class=\"pre\">*=&lt;tagv&gt;</span></code>. In these cases, the asterisk acts as a wildcard meaning any time series with the given tagk or tagv will be returned. For example, if we issue a query for <code class=\"docutils literal\"><span class=\"pre\">host=*</span></code> then we will get all of the time series with a <code class=\"docutils literal\"><span class=\"pre\">host</span></code> tagk such as <code class=\"docutils literal\"><span class=\"pre\">host=web01</span></code> and <code class=\"docutils literal\"><span class=\"pre\">host=web02</span></code>.</p> <p>For complex queries with multiple values, each type is <code class=\"docutils literal\"><span class=\"pre\">AND</span></code>'d with the other types and <code class=\"docutils literal\"><span class=\"pre\">OR</span></code>'d with it's own type.</p> <pre data-language=\"python\">&lt;metric&gt; AND (&lt;tagk1&gt;=[&lt;tagv1&gt;] OR &lt;tagk1&gt;=[&lt;tagv2&gt;]) AND ([&lt;tagk2&gt;]=&lt;tagv3&gt; OR [&lt;tagk2&gt;]=&lt;tagv4&gt;)\n</pre>\n <p>For example, the query <code class=\"docutils literal\"><span class=\"pre\">tsd.hbase.rpcs{type=*,host=tsd1,host=tsd2,host=tsd3}</span></code> would return only the time series with the metric <code class=\"docutils literal\"><span class=\"pre\">tsd.hbase.rpcs</span></code> and the <code class=\"docutils literal\"><span class=\"pre\">type</span></code> tagk with any value and a <code class=\"docutils literal\"><span class=\"pre\">host</span></code> tag with either <code class=\"docutils literal\"><span class=\"pre\">tsd1</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tsd2</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tsd3</span></code>. Unlike a data query, you may supply multiple tagks with the same name as seen in the example above. Wildcards always take priority so if your query looked like <code class=\"docutils literal\"><span class=\"pre\">tsd.hbase.rpcs{type=*,host=tsd1,host=tsd2,host=*}</span></code>, then the query would effectively be treated as <code class=\"docutils literal\"><span class=\"pre\">tsd.hbase.rpcs{type=*,host=*}</span></code>.</p> <p>To retreive a list of all time series with a specific tag value, e.g. a particular host, you could issue a query like <code class=\"docutils literal\"><span class=\"pre\">{*=web01}</span></code> that will return all time series with a tag value of <code class=\"docutils literal\"><span class=\"pre\">web01</span></code>. This can be useful in debugging tag name issues such as some series having <code class=\"docutils literal\"><span class=\"pre\">host=web01</span></code> or <code class=\"docutils literal\"><span class=\"pre\">server=web01</span></code>.</p> </div> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p>Query String:</p> <pre data-language=\"python\">http://localhost:4242/api/search/lookup?m=tsd.hbase.rpcs{type=*}\n</pre>\n <p>POST:</p> <p>JSON requests follow the search query format on the <a class=\"reference internal\" href=\"index\"><em>/api/search</em></a> page. Limits and startNote that tags are supplied as a list of objects. The value for the <code class=\"docutils literal\"><span class=\"pre\">key</span></code> should be a <code class=\"docutils literal\"><span class=\"pre\">tagk</span></code> and the value for <code class=\"docutils literal\"><span class=\"pre\">value</span></code> should be a <code class=\"docutils literal\"><span class=\"pre\">tagv</span></code> or wildcard.</p> <pre data-language=\"javascript\">{\n  \"metric\": \"tsd.hbase.rpcs\",\n  \"tags\":[\n    {\n      \"key\": \"type\",\n      \"value\": \"*\"\n    }\n  ]\n}\n</pre>\n </div>   <h2>Response</h2> <p>Depending on the endpoint called, the output will change slightly. However common fields include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>type</td> <td>String</td> <td>The type of query submitted, i.e. the endpoint called.</td> <td>LOOKUP</td> </tr> <tr class=\"row-odd\">\n<td>query</td> <td>String</td> <td>Ignored for lookup queries.</td> <td> </td> </tr> <tr class=\"row-even\">\n<td>limit</td> <td>Integer</td> <td>The maximum number of items returned in the result set. Currently the limit is ignored for lookup queries</td> <td>25</td> </tr> <tr class=\"row-odd\">\n<td>startIndex</td> <td>Integer</td> <td>Ignored for lookup queries, always the default.</td> <td>0</td> </tr> <tr class=\"row-even\">\n<td>metric</td> <td>String</td> <td>The metric used for the lookup</td> <td>*</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Array</td> <td>The list of tag pairs used for the lookup. May be an empty list.</td> <td>[ ]</td> </tr> <tr class=\"row-even\">\n<td>time</td> <td>Integer</td> <td>The amount of time it took, in milliseconds, to complete the query</td> <td>120</td> </tr> <tr class=\"row-odd\">\n<td>totalResults</td> <td>Integer</td> <td>The total number of results matched by the query</td> <td>1024</td> </tr> <tr class=\"row-even\">\n<td>results</td> <td>Array</td> <td>The result set with the TSUID, metric and tags for each series.</td> <td><em>See Below</em></td> </tr> </tbody> </table> <p>This endpoint will almost always return a <code class=\"docutils literal\"><span class=\"pre\">200</span></code> with content body. If the query doesn't match any results, the <code class=\"docutils literal\"><span class=\"pre\">results</span></code> field will be an empty array and <code class=\"docutils literal\"><span class=\"pre\">totalResults</span></code> will be 0. If an error occurs, such as a failure to resolve a metric or tag name to a UID, an exception will be returned.</p>   <h2>Example Response</h2> <pre data-language=\"javascript\">{\n  \"type\": \"LOOKUP\",\n  \"metric\": \"tsd.hbase.rpcs\",\n  \"tags\":[\n    {\n      \"key\": \"type\",\n      \"value\": \"*\"\n    }\n  ]\n  \"limit\": 3,\n  \"time\": 565,\n  \"results\": [\n    {\n      \"tags\": {\n        \"fqdn\": \"web01.mysite.com\"\n      },\n      \"metric\": \"app.apache.connections\",\n      \"tsuid\": \"0000150000070010D0\"\n    },\n    {\n      \"tags\": {\n        \"fqdn\": \"web02.mysite.com\"\n      },\n      \"metric\": \"app.apache.connections\",\n      \"tsuid\": \"0000150000070010D5\"\n    },\n    {\n      \"tags\": {\n        \"fqdn\": \"web03.mysite.com\"\n      },\n      \"metric\": \"app.apache.connections\",\n      \"tsuid\": \"0000150000070010D6\"\n    }\n  ],\n  \"startIndex\": 0,\n  \"totalResults\": 9688066\n}\n</pre>\n<div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/search/lookup.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/search/lookup.html</a>\n  </p>\n</div>\n","api_http/stats/jvm":"<h1>/api/stats/jvm</h1> <p>The threads endpoint is used for debugging the TSD's JVM process and includes stats about the garbage collector, system load and memory usage. (v2.2)</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The information printed will change depending on the JVM you are running the TSD under. In particular, the pools and GC sections will differ quite a bit.</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>No parameters available.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/stats/jvm\n</pre>\n </div>   <h2>Response</h2> <p>The response is an object with multiple sub objects. Top level objects include</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"80%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>os</td> <td>Object</td> <td>Information about the system</td> </tr> <tr class=\"row-odd\">\n<td>gc</td> <td>Object</td> <td>Information about the various garbage collectors such as how many times GC occurred and how long the process spent collecting.</td> </tr> <tr class=\"row-even\">\n<td>runtime</td> <td>Object</td> <td>Details about the JVM including version and vendor, start timestamp (in millieconds) and the uptime.</td> </tr> <tr class=\"row-odd\">\n<td>pools</td> <td>Object</td> <td>Details about each of the memory pools, particularly when used with a generational collector.</td> </tr> <tr class=\"row-even\">\n<td>memory</td> <td>Object</td> <td>Information about the JVM's memory usage.</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"os\": {\n    \"systemLoadAverage\": 4.85\n  },\n  \"gc\": {\n    \"parNew\": {\n      \"collectionTime\": 26027510,\n      \"collectionCount\": 361039\n    },\n    \"concurrentMarkSweep\": {\n      \"collectionTime\": 333710,\n      \"collectionCount\": 396\n    }\n  },\n  \"runtime\": {\n    \"startTime\": 1441069233346,\n    \"vmVersion\": \"24.60-b09\",\n    \"uptime\": 1033439220,\n    \"vmVendor\": \"Oracle Corporation\",\n    \"vmName\": \"Java HotSpot(TM) 64-Bit Server VM\"\n  },\n  \"pools\": {\n    \"cMSPermGen\": {\n      \"collectionUsage\": {\n        \"init\": 21757952,\n        \"used\": 30044544,\n        \"committed\": 50077696,\n        \"max\": 85983232\n      },\n      \"usage\": {\n        \"init\": 21757952,\n        \"used\": 30045408,\n        \"committed\": 50077696,\n        \"max\": 85983232\n      },\n      \"type\": \"NON_HEAP\",\n      \"peakUsage\": {\n        \"init\": 21757952,\n        \"used\": 30045408,\n        \"committed\": 50077696,\n        \"max\": 85983232\n      }\n    },\n    \"parSurvivorSpace\": {\n      \"collectionUsage\": {\n        \"init\": 157024256,\n        \"used\": 32838400,\n        \"committed\": 157024256,\n        \"max\": 157024256\n      },\n      \"usage\": {\n        \"init\": 157024256,\n        \"used\": 32838400,\n        \"committed\": 157024256,\n        \"max\": 157024256\n      },\n      \"type\": \"HEAP\",\n      \"peakUsage\": {\n        \"init\": 157024256,\n        \"used\": 157024256,\n        \"committed\": 157024256,\n        \"max\": 157024256\n      }\n    },\n    \"codeCache\": {\n      \"collectionUsage\": null,\n      \"usage\": {\n        \"init\": 2555904,\n        \"used\": 8754368,\n        \"committed\": 8978432,\n        \"max\": 50331648\n      },\n      \"type\": \"NON_HEAP\",\n      \"peakUsage\": {\n        \"init\": 2555904,\n        \"used\": 8767040,\n        \"committed\": 8978432,\n        \"max\": 50331648\n      }\n    },\n    \"cMSOldGen\": {\n      \"collectionUsage\": {\n        \"init\": 15609561088,\n        \"used\": 1886862056,\n        \"committed\": 15609561088,\n        \"max\": 15609561088\n      },\n      \"usage\": {\n        \"init\": 15609561088,\n        \"used\": 5504187904,\n        \"committed\": 15609561088,\n        \"max\": 15609561088\n      },\n      \"type\": \"HEAP\",\n      \"peakUsage\": {\n        \"init\": 15609561088,\n        \"used\": 11849865176,\n        \"committed\": 15609561088,\n        \"max\": 15609561088\n      }\n    },\n    \"parEdenSpace\": {\n      \"collectionUsage\": {\n        \"init\": 1256259584,\n        \"used\": 0,\n        \"committed\": 1256259584,\n        \"max\": 1256259584\n      },\n      \"usage\": {\n        \"init\": 1256259584,\n        \"used\": 825272064,\n        \"committed\": 1256259584,\n        \"max\": 1256259584\n      },\n      \"type\": \"HEAP\",\n      \"peakUsage\": {\n        \"init\": 1256259584,\n        \"used\": 1256259584,\n        \"committed\": 1256259584,\n        \"max\": 1256259584\n      }\n    }\n  },\n  \"memory\": {\n    \"objectsPendingFinalization\": 0,\n    \"nonHeapMemoryUsage\": {\n      \"init\": 24313856,\n      \"used\": 38798912,\n      \"committed\": 59056128,\n      \"max\": 136314880\n    },\n    \"heapMemoryUsage\": {\n      \"init\": 17179869184,\n      \"used\": 6351794296,\n      \"committed\": 17022844928,\n      \"max\": 17022844928\n    }\n  }\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/stats/jvm.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/stats/jvm.html</a>\n  </p>\n</div>\n","api_http/stats/query":"<h1>/api/stats/query</h1> <p>This endpoint can be used for tracking and troubleshooting queries executed against a TSD. It maintains an unbounded list of currently executing queries as well as a list of up to 256 completed queries (rotating the oldest queries out of memory). Information about each query includes the original query, request headers, response code, timing and an exception if thrown. (v2.2)</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>No parameters available.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/stats/query\n</pre>\n </div>   <h2>Response</h2> <p>The response includes two arrays. <code class=\"docutils literal\"><span class=\"pre\">completed</span></code> lists the 256 most recent queries that have finished execution, whether successfully or with an error. The <code class=\"docutils literal\"><span class=\"pre\">running</span></code> array contains a list of queries currently executing. If this list is growing, the TSD is under heavy load. Note that the running list will not contain an exception, response code or timing details.</p> <p>For information on the various sections and data from the stats endpoint, see <a class=\"reference internal\" href=\"../../user_guide/query/stats\"><em>Query Details and Stats</em></a>.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n    \"completed\": [{\n        \"query\": {\n            \"start\": \"1455531250181\",\n            \"end\": null,\n            \"timezone\": null,\n            \"options\": null,\n            \"padding\": false,\n            \"queries\": [{\n                \"aggregator\": \"zimsum\",\n                \"metric\": \"tsd.connectionmgr.bytes.written\",\n                \"tsuids\": null,\n                \"downsample\": \"1m-avg\",\n                \"rate\": true,\n                \"filters\": [{\n                    \"tagk\": \"colo\",\n                    \"filter\": \"*\",\n                    \"group_by\": true,\n                    \"type\": \"wildcard\"\n                }, {\n                    \"tagk\": \"env\",\n                    \"filter\": \"prod\",\n                    \"group_by\": true,\n                    \"type\": \"literal_or\"\n                }, {\n                    \"tagk\": \"role\",\n                    \"filter\": \"frontend\",\n                    \"group_by\": true,\n                    \"type\": \"literal_or\"\n                }],\n                \"rateOptions\": {\n                    \"counter\": true,\n                    \"counterMax\": 9223372036854775807,\n                    \"resetValue\": 1,\n                    \"dropResets\": false\n                },\n                \"tags\": {\n                    \"role\": \"literal_or(frontend)\",\n                    \"env\": \"literal_or(prod)\",\n                    \"colo\": \"wildcard(*)\"\n                }\n            }, {\n                \"aggregator\": \"zimsum\",\n                \"metric\": \"tsd.hbase.rpcs.cumulative_bytes_received\",\n                \"tsuids\": null,\n                \"downsample\": \"1m-avg\",\n                \"rate\": true,\n                \"filters\": [{\n                    \"tagk\": \"colo\",\n                    \"filter\": \"*\",\n                    \"group_by\": true,\n                    \"type\": \"wildcard\"\n                }, {\n                    \"tagk\": \"env\",\n                    \"filter\": \"prod\",\n                    \"group_by\": true,\n                    \"type\": \"literal_or\"\n                }, {\n                    \"tagk\": \"role\",\n                    \"filter\": \"frontend\",\n                    \"group_by\": true,\n                    \"type\": \"literal_or\"\n                }],\n                \"rateOptions\": {\n                    \"counter\": true,\n                    \"counterMax\": 9223372036854775807,\n                    \"resetValue\": 1,\n                    \"dropResets\": false\n                },\n                \"tags\": {\n                    \"role\": \"literal_or(frontend)\",\n                    \"env\": \"literal_or(prod)\",\n                    \"colo\": \"wildcard(*)\"\n                }\n            }],\n            \"delete\": false,\n            \"noAnnotations\": false,\n            \"globalAnnotations\": false,\n            \"showTSUIDs\": false,\n            \"msResolution\": false,\n            \"showQuery\": false,\n            \"showStats\": false,\n            \"showSummary\": false\n        },\n        \"exception\": \"null\",\n        \"executed\": 1,\n        \"user\": null,\n        \"requestHeaders\": {\n            \"Accept-Language\": \"en-US,en;q=0.8\",\n            \"Host\": \"tsdhost:4242\",\n            \"Content-Length\": \"440\",\n            \"Referer\": \"http://tsdhost:8080/dashboard/db/tsdfrontend\",\n            \"Accept-Encoding\": \"gzip, deflate\",\n            \"X-Forwarded-For\": \"192.168.0.2\",\n            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.109 Safari/537.36\",\n            \"Origin\": \"http://tsdhost:8080\",\n            \"Content-Type\": \"application/json;charset=UTF-8\",\n            \"Accept\": \"application/json, text/plain, */*\"\n        },\n        \"numRunningQueries\": 0,\n        \"httpResponse\": {\n            \"code\": 200,\n            \"reasonPhrase\": \"OK\"\n        },\n        \"queryStartTimestamp\": 1455552844368,\n        \"queryCompletedTimestamp\": 1455552844621,\n        \"sentToClient\": true,\n        \"stats\": {\n            \"avgAggregationTime\": 2.11416,\n            \"avgHBaseTime\": 200.267711,\n            \"avgQueryScanTime\": 242.037174,\n            \"avgScannerTime\": 200.474122,\n            \"avgScannerUidToStringTime\": 0.0,\n            \"avgSerializationTime\": 2.124153,\n            \"emittedDPs\": 716,\n            \"maxAggregationTime\": 2.093369,\n            \"maxHBaseTime\": 241.708782,\n            \"maxQueryScanTime\": 240.637231,\n            \"maxScannerUidtoStringTime\": 0.0,\n            \"maxSerializationTime\": 2.103411,\n            \"maxUidToStringTime\": 0.059345,\n            \"processingPreWriteTime\": 253.050907,\n            \"successfulScan\": 40,\n            \"totalTime\": 256.568992,\n            \"uidPairsResolved\": 0\n        }\n    }],\n    \"running\": []\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/stats/query.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/stats/query.html</a>\n  </p>\n</div>\n","api_http/stats/threads":"<h1>/api/stats/threads</h1> <p>The threads endpoint is used for debugging the TSD and providing insight into the state and execution of various threads without having to resort to a JStack trace. (v2.2)</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>No parameters available.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/stats/threads\n</pre>\n </div>   <h2>Response</h2> <p>The response is an array of objects. Fields in the response include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>threadID</td> <td>Integer</td> <td>Numeric ID of the thread</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>priority</td> <td>Integer</td> <td>Execution priority for the thread</td> <td>5</td> </tr> <tr class=\"row-even\">\n<td>name</td> <td>String</td> <td>String name of the thread, usually assigned by default</td> <td>New I/O worker #23</td> </tr> <tr class=\"row-odd\">\n<td>interrupted</td> <td>Boolean</td> <td>Whether or not the thread was interrupted</td> <td>false</td> </tr> <tr class=\"row-even\">\n<td>state</td> <td>String</td> <td>One of the valid Java thread states</td> <td>RUNNABLE</td> </tr> <tr class=\"row-odd\">\n<td>stack</td> <td>Array&lt;String&gt;</td> <td>A stack trace showing where execution is currently located</td> <td><em>See Below</em></td> </tr> </tbody> </table> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">[\n  {\n    \"threadID\": 33,\n    \"priority\": 5,\n    \"name\": \"AsyncHBase I/O Worker #23\",\n    \"interrupted\": false,\n    \"state\": \"RUNNABLE\",\n    \"stack\": [\n      \"sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\",\n      \"sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:136)\",\n      \"sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:69)\",\n      \"sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)\",\n      \"sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)\",\n      \"org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:68)\",\n      \"org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:415)\",\n      \"org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:212)\",\n      \"org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\",\n      \"org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\",\n      \"org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\",\n      \"org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\",\n      \"java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\",\n      \"java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\",\n      \"java.lang.Thread.run(Thread.java:695)\"\n    ]\n  },\n  {\n    \"threadID\": 6,\n    \"priority\": 9,\n    \"name\": \"Signal Dispatcher\",\n    \"interrupted\": false,\n    \"state\": \"RUNNABLE\",\n    \"stack\": []\n  },\n  {\n    \"threadID\": 21,\n    \"priority\": 5,\n    \"name\": \"AsyncHBase I/O Worker #11\",\n    \"interrupted\": false,\n    \"state\": \"RUNNABLE\",\n    \"stack\": [\n      \"sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)\",\n      \"sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:136)\",\n      \"sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:69)\",\n      \"sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)\",\n      \"sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)\",\n      \"org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:68)\",\n      \"org.jboss.netty.channel.socket.nio.AbstractNioSelector.select(AbstractNioSelector.java:415)\",\n      \"org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:212)\",\n      \"org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\",\n      \"org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\",\n      \"org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\",\n      \"org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\",\n      \"java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\",\n      \"java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\",\n      \"java.lang.Thread.run(Thread.java:695)\"\n    ]\n  },\n  {\n    \"threadID\": 2,\n    \"priority\": 10,\n    \"name\": \"Reference Handler\",\n    \"interrupted\": false,\n    \"state\": \"WAITING\",\n    \"stack\": [\n      \"java.lang.Object.wait(Native Method)\",\n      \"java.lang.Object.wait(Object.java:485)\",\n      \"java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)\"\n    ]\n  },\n  {\n    \"threadID\": 44,\n    \"priority\": 5,\n    \"name\": \"OpenTSDB Timer TSDB Timer #1\",\n    \"interrupted\": false,\n    \"state\": \"TIMED_WAITING\",\n    \"stack\": [\n      \"java.lang.Thread.sleep(Native Method)\",\n      \"org.jboss.netty.util.HashedWheelTimer$Worker.waitForNextTick(HashedWheelTimer.java:483)\",\n      \"org.jboss.netty.util.HashedWheelTimer$Worker.run(HashedWheelTimer.java:392)\",\n      \"org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\",\n      \"java.lang.Thread.run(Thread.java:695)\"\n    ]\n  }\n]\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/stats/threads.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/stats/threads.html</a>\n  </p>\n</div>\n","api_http/serializers/json":"<h1>JSON Serializer</h1> <p>The default OpenTSDB serializer parses and returns JSON formatted data. Below you'll find details about the serializer and request parameters that affect only the the JSON serializer. If the serializer has extra parameters for a specific endpoint, they'll be listed below.</p>  <h2>Serializer Name</h2> <p><code class=\"docutils literal\"><span class=\"pre\">json</span></code></p>   <h2>Serializer Options</h2> <p>The following options are supported via query string:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"55%\"> <col width=\"10%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Parameter</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>jsonp</td> <td>String</td> <td>Optional</td> <td>Wraps the response in a JavaScript function name passed to the parameter.</td> <td><code class=\"docutils literal\"><span class=\"pre\">empty</span></code></td> <td>jsonp=callback</td> </tr> </tbody> </table>   <h2>JSONP</h2> <p>The JSON formatter can wrap responses in a JavaScript function using the <code class=\"docutils literal\"><span class=\"pre\">jsonp</span></code> query string parameter. Supply the name of the function you wish to use and the result will be wrapped.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <pre data-language=\"python\">http://localhost:4242/api/version?jsonp=callback\n</pre>\n </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">callback({\n  \"timestamp\": \"1362712695\",\n  \"host\": \"DF81QBM1\",\n  \"repo\": \"/c/temp/a/opentsdb/build\",\n  \"full_revision\": \"11c5eefd79f0c800b703ebd29c10e7f924c01572\",\n  \"short_revision\": \"11c5eef\",\n  \"user\": \"df81qbm1_/clarsen\",\n  \"repo_status\": \"MODIFIED\",\n  \"version\": \"2.0.0\"\n})\n</pre>\n </div>   <h2>api/query</h2> <p>The JSON serializer allows some query string parameters that modify the output but have no effect on the data retrieved.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"50%\"> <col width=\"10%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>arrays</td> <td>Boolean</td> <td>Optional</td> <td>Returns the data points formatted as an array of arrays instead of a map of key/value pairs. Each array consists of the timestamp followed by the value.</td> <td>false</td> <td>arrays=true</td> </tr> </tbody> </table><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/serializers/json.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/serializers/json.html</a>\n  </p>\n</div>\n","api_http/config/filters":"<h1>/api/config/filters</h1> <p><strong>(Version 2.2 and later)</strong> This endpoint lists the various filters loaded by the TSD and some information about how to use them.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>This endpoint does not require any parameters via query string or body.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/config/filters\n</pre>\n </div>   <h2>Response</h2> <p>The response is a map of filter names or types and sub maps of examples and descriptions. The examples show how to use them in both URI and JSON queries.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"iliteral_or\": {\n    \"examples\": \"host=iliteral_or(web01),  host=iliteral_or(web01|web02|web03)  {\\\"type\\\":\\\"iliteral_or\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\"web01|web02|web03\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Accepts one or more exact values and matches if the series contains any of them. Multiple values can be included and must be separated by the | (pipe) character. The filter is case insensitive and will not allow characters that TSDB does not allow at write time.\"\n  },\n  \"wildcard\": {\n    \"examples\": \"host=wildcard(web*),  host=wildcard(web*.tsdb.net)  {\\\"type\\\":\\\"wildcard\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\"web*.tsdb.net\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Performs pre, post and in-fix glob matching of values. The globs are case sensitive and multiple wildcards can be used. The wildcard character is the * (asterisk). At least one wildcard must be present in the filter value. A wildcard by itself can be used as well to match on any value for the tag key.\"\n  },\n  \"not_literal_or\": {\n    \"examples\": \"host=not_literal_or(web01),  host=not_literal_or(web01|web02|web03)  {\\\"type\\\":\\\"not_literal_or\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\"web01|web02|web03\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Accepts one or more exact values and matches if the series does NOT contain any of them. Multiple values can be included and must be separated by the | (pipe) character. The filter is case sensitive and will not allow characters that TSDB does not allow at write time.\"\n  },\n  \"not_iliteral_or\": {\n    \"examples\": \"host=not_iliteral_or(web01),  host=not_iliteral_or(web01|web02|web03)  {\\\"type\\\":\\\"not_iliteral_or\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\"web01|web02|web03\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Accepts one or more exact values and matches if the series does NOT contain any of them. Multiple values can be included and must be separated by the | (pipe) character. The filter is case insensitive and will not allow characters that TSDB does not allow at write time.\"\n  },\n  \"not_key\": {\n    \"examples\": \"host=not_key()  {\\\"type\\\":\\\"not_key\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\"\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Skips any time series with the given tag key, regardless of the value. This can be useful for situations where a metric has inconsistent tag sets. NOTE: The filter value must be null or an empty string.\"\n  },\n  \"iwildcard\": {\n    \"examples\": \"host=iwildcard(web*),  host=iwildcard(web*.tsdb.net)  {\\\"type\\\":\\\"iwildcard\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\"web*.tsdb.net\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Performs pre, post and in-fix glob matching of values. The globs are case insensitive and multiple wildcards can be used. The wildcard character is the * (asterisk). Case insensitivity is achieved by dropping all values to lower case. At least one wildcard must be present in the filter value. A wildcard by itself can be used as well to match on any value for the tag key.\"\n  },\n  \"literal_or\": {\n    \"examples\": \"host=literal_or(web01),  host=literal_or(web01|web02|web03)  {\\\"type\\\":\\\"literal_or\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\"web01|web02|web03\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Accepts one or more exact values and matches if the series contains any of them. Multiple values can be included and must be separated by the | (pipe) character. The filter is case sensitive and will not allow characters that TSDB does not allow at write time.\"\n  },\n  \"regexp\": {\n    \"examples\": \"host=regexp(.*)  {\\\"type\\\":\\\"regexp\\\",\\\"tagk\\\":\\\"host\\\",\\\"filter\\\":\\\".*\\\",\\\"groupBy\\\":false}\",\n    \"description\": \"Provides full, POSIX compliant regular expression using the built in Java Pattern class. Note that an expression containing curly braces {} will not parse properly in URLs. If the pattern is not a valid regular expression then an exception will be raised.\"\n  }\n</pre>\n <p>}</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/config/filters.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/config/filters.html</a>\n  </p>\n</div>\n","api_http/uid/assign":"<h1>/api/uid/assign</h1> <p>This endpoint enables assigning UIDs to new metrics, tag names and tag values. Multiple types and names can be provided in a single call and the API will process each name individually, reporting which names were assigned UIDs successfully, along with the UID assigned, and which failed due to invalid characters or had already been assigned. Assignment can be performed via query string or content data.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>Each request must have one or more of the following fields:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>metric</td> <td>String</td> <td>Optional</td> <td>A list of metric names for assignment</td> <td> </td> <td>metric</td> <td>RW</td> <td>sys.cpu.0</td> </tr> <tr class=\"row-odd\">\n<td>tagk</td> <td>String</td> <td>Optional</td> <td>A list of tag names for assignment</td> <td> </td> <td>tagk</td> <td>RW</td> <td>host</td> </tr> <tr class=\"row-even\">\n<td>tagv</td> <td>String</td> <td>Optional</td> <td>A list of tag values for assignment</td> <td> </td> <td>tagv</td> <td>RW</td> <td>web01</td> </tr> </tbody> </table> <p>When making a query string request, multiple names for a given type can be supplied in a comma separated fashion. E.g. <code class=\"docutils literal\"><span class=\"pre\">metric=sys.cpu.0,sys.cpu.1,sys.cpu.2,sys.cpu.3</span></code>. Naming conventions apply: see _______.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <p><strong>Query String</strong></p> <pre data-language=\"python\">http://localhost:4242/api/uid/assign?metric=sys.cpu.0,sys.cpu.1&amp;tagk=host&amp;tagv=web01,web02,web03\n</pre>\n <p><strong>JSON Content</strong></p> <pre data-language=\"javascript\">{\n  \"metric\": [\n    \"sys.cpu.0\",\n    \"sys.cpu.1\",\n    \"illegal!character\"\n  ],\n  \"tagk\": [\n    \"host\"\n  ],\n  \"tagv\": [\n    \"web01\",\n    \"web02\",\n    \"web03\"\n  ]\n}\n</pre>\n </div>   <h2>Response</h2> <p>The response will contain a map of successful assignments along with the hex encoded UID value. If one or more values were not assigned, a separate map will contain a list of the values and the reason why they were not assigned. Maps with the type name and <code class=\"docutils literal\"><span class=\"pre\">&lt;type&gt;_errors</span></code> will be generated only if one or more values for that type were provided.</p> <p>When all values are assigned, the endpoint returns a 200 status code but if any value failed assignment, it will return a 400.</p> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"metric\": {},\n  \"metric_errors\": {\n    \"sys.cpu.0\": \"Name already exists with UID: 000042\",\n    \"sys.cpu.1\": \"Name already exists with UID: 000043\",\n    \"illegal!character\": \"Invalid metric (illegal!character): illegal character: !\",\n  },\n  \"tagv\": {},\n  \"tagk_errors\": {\n    \"host\": \"Name already exists with UID: 0007E5\"\n  },\n  \"tagk\": {\n    \"web01\": \"000012\",\n    \"web02\": \"000013\",\n    \"web03\": \"000014\"\n  }\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/uid/assign.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/uid/assign.html</a>\n  </p>\n</div>\n","api_http/annotation/bulk":"<h1>/api/annotation/bulk</h1> <p><em>NOTE: (Version 2.1)</em> The bulk endpoint enables adding, updating or deleting multiple annotations in a single call. Annotation updates must be sent over PUT or POST as content data. Query string requests are not supported for <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">GET</span></code>. Each annotation is processed individually and synchronized with the backend. If one of the annotations has an error, such as a missing field, an exception will be returned and some of the annotations may not be written to storage. In such an event, the errant annotation should be fixed and all annotations sent again.</p> <p>Annotations may also be deleted in bulk for a specified time span. If you supply a list of of one or more TSUIDs, annotations with a <code class=\"docutils literal\"><span class=\"pre\">start</span> <span class=\"pre\">time</span></code> that falls within the specified timespan and belong to those TSUIDs will be removed. Alternatively the <code class=\"docutils literal\"><span class=\"pre\">global</span></code> flag can be set and any global annotations (those not associated with a time series) will be deleted within the range.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>POST - Create or modify annotations</li> <li>PUT - Create or replace annotations</li> <li>DELETE - Delete annotations within a time range</li> </ul>   <h2>Requests</h2> <p>Fields for posting or updating annotations are documented at <a class=\"reference internal\" href=\"index\"><em>/api/annotation</em></a></p> <p>Fields for a bulk delete request are defined below:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>startTime</td> <td>Integer</td> <td>Required</td> <td>A timestamp for the start of the request. The timestamp may be relative or absolute as per <a class=\"reference internal\" href=\"../../user_guide/query/dates\"><em>Dates and Times</em></a>.</td> <td> </td> <td>start_time</td> <td>RO</td> <td>1369141261</td> </tr> <tr class=\"row-odd\">\n<td>endTime</td> <td>Integer</td> <td>Optional</td> <td>An optional end time for the event if it has completed or been resolved. The timestamp may be relative or absolute as per <a class=\"reference internal\" href=\"../../user_guide/query/dates\"><em>Dates and Times</em></a>.</td> <td> </td> <td>end_time</td> <td>RO</td> <td>1369141262</td> </tr> <tr class=\"row-even\">\n<td>tsuids</td> <td>Array</td> <td>Optional</td> <td>A list of TSUIDs with annotations that should be deleted. This may be empty or null (for JSON) in which case the <code class=\"docutils literal\"><span class=\"pre\">global</span></code> flag should be set. When using the query string, separate TSUIDs with commas.</td> <td> </td> <td>tsuids</td> <td>RO</td> <td>000001000001000001, 000001000001000002</td> </tr> <tr class=\"row-odd\">\n<td>global</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not global annotations should be deleted for the range</td> <td>false</td> <td>global</td> <td>RO</td> <td>true</td> </tr> </tbody> </table> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">If your request uses <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code>, any fields that you do not supply with the request will be overwritten with their default values. For example, the <code class=\"docutils literal\"><span class=\"pre\">description</span></code> field will be set to an empty string and the <code class=\"docutils literal\"><span class=\"pre\">custom</span></code> field will be reset to <code class=\"docutils literal\"><span class=\"pre\">null</span></code>.</p> </div> <div class=\"section\" id=\"example-post-put-request\"> <h3>Example POST/PUT Request</h3> <pre data-language=\"javascript\">[\n  {\n  \"startTime\":\"1369141261\",\n  \"tsuid\":\"000001000001000001\",\n  \"description\": \"Testing Annotations\",\n  \"notes\": \"These would be details about the event, the description is just a summary\",\n  \"custom\": {\n    \"owner\": \"jdoe\",\n    \"dept\": \"ops\"\n  }\n  },\n  {\n  \"startTime\":\"1369141261\",\n  \"tsuid\":\"000001000001000002\",\n  \"description\": \"Second annotation on different TSUID\",\n  \"notes\": \"Additional details\"\n  }\n]\n</pre>\n </div> <div class=\"section\" id=\"example-delete-qs-request\"> <h3>Example DELETE QS Request</h3> <pre data-language=\"python\">/api/annotation/bulk?start_time=1d-ago&amp;end_time=1h-ago&amp;method_override=delete&amp;tsuids=000001000001000001,000001000001000002\n</pre>\n </div> <div class=\"section\" id=\"example-delete-request\"> <h3>Example DELETE Request</h3> <pre data-language=\"javascript\">{\n  \"tsuids\": [\n    \"000001000001000001\",\n    \"000001000001000002\"\n  ],\n  \"global\": false,\n  \"startTime\": 1389740544690,\n  \"endTime\": 1389823344698,\n  \"totalDeleted\": 0\n}\n</pre>\n </div>   <h2>Response</h2> <p>A successful response to a <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> request will return the list of annotations after synchronization (i.e. if issuing a <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> call, existing objects will be merged with the new objects). Delete requests will return an object with the delete query and a <code class=\"docutils literal\"><span class=\"pre\">totalDeleted</span></code> field with an integer number reflecting the total number of annotations deleted. If invalid data was supplied a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned along with the specific annotation that caused the error in the <code class=\"docutils literal\"><span class=\"pre\">details</span></code> field of the error object.</p> <div class=\"section\" id=\"example-post-put-response\"> <h3>Example POST/PUT Response</h3> <pre data-language=\"javascript\">[\n  {\n    \"tsuid\": \"000001000001000001\",\n    \"description\": \"Testing Annotations\",\n    \"notes\": \"These would be details about the event, the description is just a summary\",\n    \"custom\": {\n      \"owner\": \"jdoe\",\n      \"dept\": \"ops\"\n    },\n    \"endTime\": 0,\n    \"startTime\": 1369141261\n  },\n  {\n    \"tsuid\": \"000001000001000002\",\n    \"description\": \"Second annotation on different TSUID\",\n    \"notes\": \"Additional details\",\n    \"custom\": null,\n    \"endTime\": 0,\n    \"startTime\": 1369141261\n  }\n]\n</pre>\n </div> <div class=\"section\" id=\"example-delete-response\"> <h3>Example DELETE Response</h3> <pre data-language=\"javascript\">{\n  \"tsuids\": [\n    \"000001000001000001\",\n    \"000001000001000002\"\n  ],\n  \"global\": false,\n  \"startTime\": 1389740544690,\n  \"endTime\": 1389823344698,\n  \"totalDeleted\": 42\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/annotation/bulk.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/annotation/bulk.html</a>\n  </p>\n</div>\n","api_http/tree/test":"<h1>/api/tree/test</h1> <p>For debugging a rule set, the test endpoint can be used to run a TSMeta object through a tree's rules and determine where in the heirarchy the leaf would appear. Or find out why a timeseries failed to match on a rule set or collided with an existing timeseries. The only method supported is <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> and no changes will be made to the actual tree in storage when using this endpoint.</p> <p>The <code class=\"docutils literal\"><span class=\"pre\">messages</span></code> field of the response contains information about what occurred during processing. If the TSUID did not exist or an error occurred, the reason will be found in this field. During processing, each rule that the TSMeta is processed through will generate a message. If a rule matched on the TSMeta successfully or failed, the reason will be recorded.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>The following fields are required for this endpoint.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>treeId</td> <td>Integer</td> <td>Required</td> <td>The ID of the tree to pass the TSMeta objects through</td> <td> </td> <td>treeid</td> <td> </td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>tsuids</td> <td>String</td> <td>Required</td> <td>A list of one or more TSUIDs to fetch TSMeta for. If requesting testing of more than one TSUID, they should be separted by a comma.</td> <td> </td> <td>tsuids</td> <td> </td> <td>000001000001000001,00000200000200002</td> </tr> </tbody> </table>   <h2>Response</h2> <p>A successful response will return a list of JSON objects with a number of items including the TSMeta object, messages about the processing steps taken and a resulting branch. There will be one object for each TSUID requested with the TSUID as the object name. If the requested tree did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned.</p> <p>Fields found in the response include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>messages</td> <td>Array of Strings</td> <td>A list of messages for each level and rule of the rule set</td> <td><em>See Below</em></td> </tr> <tr class=\"row-odd\">\n<td>meta</td> <td>Object</td> <td>The TSMeta object loaded from storage</td> <td><em>See Below</em></td> </tr> <tr class=\"row-even\">\n<td>branch</td> <td>Object</td> <td>The full tree if successfully parsed</td> <td><em>See Below</em></td> </tr> </tbody> </table> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <blockquote> <div><a class=\"reference external\" href=\"http://localhost:4242/api/tree/test?treeId=1&amp;tsuids=000001000001000001000002000002\">http://localhost:4242/api/tree/test?treeId=1&amp;tsuids=000001000001000001000002000002</a></div>\n</blockquote> </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"000001000001000001000002000002\": {\n    \"messages\": [\n      \"Processing rule: [1:0:0:TAGK]\",\n      \"Matched tagk [host] for rule: [1:0:0:TAGK]\",\n      \"Processing rule: [1:1:0:METRIC]\",\n      \"Depth [3] Adding leaf [name: sys.cpu.0 tsuid: 000001000001000001000002000002] to parent branch [Name: [web-01.lga.mysite.com]]\"\n    ],\n    \"meta\": {\n      \"tsuid\": \"000001000001000001000002000002\",\n      \"metric\": {\n        \"uid\": \"000001\",\n        \"type\": \"METRIC\",\n        \"name\": \"sys.cpu.0\",\n        \"description\": \"\",\n        \"notes\": \"\",\n        \"created\": 1368979404,\n        \"custom\": null,\n        \"displayName\": \"\"\n      },\n      \"tags\": [\n        {\n          \"uid\": \"000001\",\n          \"type\": \"TAGK\",\n          \"name\": \"host\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1368979404,\n          \"custom\": null,\n          \"displayName\": \"\"\n        },\n        {\n          \"uid\": \"000001\",\n          \"type\": \"TAGV\",\n          \"name\": \"web-01.lga.mysite.com\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1368979404,\n          \"custom\": null,\n          \"displayName\": \"\"\n        },\n        {\n          \"uid\": \"000002\",\n          \"type\": \"TAGK\",\n          \"name\": \"type\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1368979404,\n          \"custom\": null,\n          \"displayName\": \"\"\n        },\n        {\n          \"uid\": \"000002\",\n          \"type\": \"TAGV\",\n          \"name\": \"user\",\n          \"description\": \"\",\n          \"notes\": \"\",\n          \"created\": 1368979404,\n          \"custom\": null,\n          \"displayName\": \"\"\n        }\n      ],\n      \"description\": \"\",\n      \"notes\": \"\",\n      \"created\": 0,\n      \"units\": \"\",\n      \"retention\": 0,\n      \"max\": \"NaN\",\n      \"min\": \"NaN\",\n      \"displayName\": \"\",\n      \"lastReceived\": 0,\n      \"totalDatapoints\": 0,\n      \"dataType\": \"\"\n    },\n    \"branch\": {\n      \"leaves\": null,\n      \"branches\": [\n        {\n          \"leaves\": [\n            {\n              \"metric\": \"\",\n              \"tags\": null,\n              \"tsuid\": \"000001000001000001000002000002\",\n              \"displayName\": \"sys.cpu.0\"\n            }\n          ],\n          \"branches\": null,\n          \"path\": {\n            \"0\": \"ROOT\",\n            \"1\": \"web-01.lga.mysite.com\"\n          },\n          \"treeId\": 1,\n          \"displayName\": \"web-01.lga.mysite.com\",\n          \"branchId\": \"0001247F7202\",\n          \"numLeaves\": 1,\n          \"numBranches\": 0,\n          \"depth\": 1\n        }\n      ],\n      \"path\": {\n        \"0\": \"ROOT\"\n      },\n      \"treeId\": 1,\n      \"displayName\": \"ROOT\",\n      \"branchId\": \"0001\",\n      \"numLeaves\": 0,\n      \"numBranches\": 1,\n      \"depth\": 0\n    }\n  }\n}\n</pre>\n </div> <div class=\"section\" id=\"example-error-response\"> <h3>Example Error Response</h3> <pre data-language=\"javascript\">{\n  \"000001000001000001000002000003\": {\n    \"branch\": null,\n    \"messages\": [\n      \"Unable to locate TSUID meta data\"\n    ],\n    \"meta\": null\n  }\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/tree/test.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/tree/test.html</a>\n  </p>\n</div>\n","api_http/query/gexp":"<h1>/api/query/gexp</h1> <p>Graphite is an excellent storage system for time series data with a number of built in functions to manipulate the data. To support transitions from Graphite to OpenTSDB, the <code class=\"docutils literal\"><span class=\"pre\">/api/query/gexp</span></code> endpoint supports URI queries <em>similar</em> but not <em>identical</em> to Graphite`s expressions. Graphite functions are generally formatted as <code class=\"docutils literal\"><span class=\"pre\">func(&lt;series&gt;[,</span> <span class=\"pre\">param1][,</span> <span class=\"pre\">paramN])</span></code> with the ability to nest functions. TSD`s implementation follows the same pattern but uses an <code class=\"docutils literal\"><span class=\"pre\">m</span></code> style query (e.g. <code class=\"docutils literal\"><span class=\"pre\">sum:proc.stat.cpu{host=foo,type=idle}</span></code>) in place of the <code class=\"docutils literal\"><span class=\"pre\">&lt;series&gt;</span></code>. Nested functions are supported.</p> <p>TSDB implements a subset of Graphite functions though we hope to add more in the future. For a list of Graphite functions and descriptions, see the <a class=\"reference external\" href=\"http://graphite.readthedocs.org/en/latest/functions.html\">Documentation</a>. TSD supported functions appear below.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Supported as of version 2.3</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>Queries can only be executed via GET using the URI at this time. (In the future, the <a class=\"reference internal\" href=\"exp\"><em>/api/query/exp</em></a> endpoint will support more flexibility.) This is an extension of the main <a class=\"reference internal\" href=\"index\"><em>/api/query</em></a> endpoint so parameters in the request table are also supported here. Additional parameters include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"55%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>exp</td> <td>String</td> <td>Required</td> <td>The Graphite style expression to execute. The first parameter of a function must either be another function or a URI formatted <strong>Sub Query</strong>\n</td> <td>scale(sum:if.bytes_in{host=*},1024)</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-query-string-requests\"> <h3>Example Query String Requests</h3> <pre data-language=\"python\">http://localhost:4242/api/query/gexp?start=1h-ago&amp;exp=scale(sum:if.bytes_in{host=*},1024)\n</pre>\n </div>   <h2>Response</h2> <p>The output is identical to <a class=\"reference internal\" href=\"index\"><em>/api/query</em></a>.</p>   <h2>Functions</h2> <p>Functions that accept a single metric query will operate across each time series result. E.g. if a query includes a group by on host such as <code class=\"docutils literal\"><span class=\"pre\">scale(sum:if.bytes_in{host=*},1024)</span></code>, and multiple hosts exist with that metric, then a series for each host will be emitted and the function applied. For functions that take multiple metrics, a union is performed across each metric and the function is executed across each resulting series with matching tags. E.g with the query <code class=\"docutils literal\"><span class=\"pre\">sum(sum:if.bytes_in{host=*},sum:if.bytes_out{host=*})</span></code>, assume two hosts exist, <code class=\"docutils literal\"><span class=\"pre\">web01</span></code> and <code class=\"docutils literal\"><span class=\"pre\">web02</span></code>. In this case, the output will be <code class=\"docutils literal\"><span class=\"pre\">if.bytes_in{host=web01}</span> <span class=\"pre\">+</span> <span class=\"pre\">if.bytes_out{host=web01}</span></code> and <code class=\"docutils literal\"><span class=\"pre\">if.bytes_in{host=web02}</span> <span class=\"pre\">+</span> <span class=\"pre\">if.bytes_out{host=web02}</span></code>. Missing series in any metric result set will be filled with the default fill value of the function.</p> <p>Currently supported expressions include:</p> <div class=\"section\" id=\"absolute-metric\"> <h3>absolute(&lt;metric&gt;)</h3> <p>Emits the results as absolute values, converting negative values to positive.</p> </div> <div class=\"section\" id=\"diffseries-metric-metricn\"> <h3>diffSeries(&lt;metric&gt;[,&lt;metricN&gt;])</h3> <p>Returns the difference of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</p> </div> <div class=\"section\" id=\"divideseries-metric-metricn\"> <h3>divideSeries(&lt;metric&gt;[,&lt;metricN&gt;])</h3> <p>Returns the quotient of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</p> </div> <div class=\"section\" id=\"highestcurrent-metric-n\"> <h3>highestCurrent(&lt;metric&gt;,&lt;n&gt;)</h3> <p>Sorts all resulting time series by their most recent value and emits <code class=\"docutils literal\"><span class=\"pre\">n</span></code> number of series with the highest values. <code class=\"docutils literal\"><span class=\"pre\">n</span></code> must be a positive integer value.</p> </div> <div class=\"section\" id=\"highestmax-metric-n\"> <h3>highestMax(&lt;metric&gt;,&lt;n&gt;)</h3> <p>Sorts all resulting time series by the maximum value for the time span and emits <code class=\"docutils literal\"><span class=\"pre\">n</span></code> number of series with the highest values. <code class=\"docutils literal\"><span class=\"pre\">n</span></code> must be a positive integer value.</p> </div> <div class=\"section\" id=\"movingaverage-metric-window\"> <h3>movingAverage(&lt;metric&gt;,&lt;window&gt;)</h3> <p>Emits a sliding window moving average for each data point and series in the metric. The <code class=\"docutils literal\"><span class=\"pre\">window</span></code> parameter may either be a positive integer that reflects the number of data points to maintain in the window (non-timed) or a time span specified by an integer followed by time unit such as <code class=\"docutils literal\"><span class=\"pre\">`60s`</span></code> or <code class=\"docutils literal\"><span class=\"pre\">`60m`</span></code> or <code class=\"docutils literal\"><span class=\"pre\">`24h`</span></code>. Timed windows must be in single quotes.</p> </div> <div class=\"section\" id=\"multiplyseries-metric-metricn\"> <h3>multiplySeries(&lt;metric&gt;[,&lt;metricN&gt;])</h3> <p>Returns the product of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</p> </div> <div class=\"section\" id=\"scale-metric-factor\"> <h3>scale(&lt;metric&gt;,&lt;factor&gt;)</h3> <p>Multiplies each series by the factor where the factor can be a positive or negative floating point or integer value.</p> </div> <div class=\"section\" id=\"sumseries-metric-metricn\"> <h3>sumSeries(&lt;metric&gt;[,&lt;metricN&gt;])</h3> <p>Returns the sum of all series in the list. Performs a UNION across tags in each metric result sets, defaulting to a fill value of zero. A maximum of 26 series are supported at this time.</p> </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/query/gexp.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/query/gexp.html</a>\n  </p>\n</div>\n","api_http/tree/collisions":"<h1>/api/tree/collisions</h1> <p>When processing a TSMeta, if the resulting leaf would overwrite an existing leaf with a different TSUID, a collision will be recorded. This endpoint allows retreiving a list of the TSUIDs that were not included in a tree due to collisions. It is useful for debugging in that if you find a TSUID in this list, you can pass it through the <code class=\"docutils literal\"><span class=\"pre\">/tree/test</span></code> endpoint to get details on why the collision occurred.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Calling this endpoint without a list of one or more TSUIDs will return all collisions in the tree. If you have a large number of timeseries in your system, the response can potentially be very large. Thus it is best to use this endpoint with specific TSUIDs.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If <code class=\"docutils literal\"><span class=\"pre\">storeFailures</span></code> is diabled for the tree, this endpoint will not return any data. Collisions will still appear in the TSD's logs.</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>The following fields are used for this endpoint</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>treeId</td> <td>Integer</td> <td>Required</td> <td>The ID of the tree to pass the TSMeta objects through</td> <td> </td> <td>treeid</td> <td> </td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>tsuids</td> <td>String</td> <td>Required</td> <td>A list of one or more TSUIDs to search for collision entries. If requesting testing of more than one TSUID, they should be separted by a comma.</td> <td> </td> <td>tsuids</td> <td> </td> <td>000001000001000001,00000200000200002</td> </tr> </tbody> </table>   <h2>Response</h2> <p>A successful response will return a map of key/value pairs where the unrecorded TSUID as the key and the existing leave's TSUID as the value. The response will only return collisions that were found. If one or more of the TSUIDs requested did not result in a collision, it will not be returned with the result. This may mean that the TSMeta has not been processed yet. Note that if no collisions have occurred or the tree hasn't processed any data yet, the result set will be empty. If the requested tree did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <blockquote> <div><a class=\"reference external\" href=\"http://localhost:4242/api/tree/collisions?treeId=1&amp;tsuids=010101,020202\">http://localhost:4242/api/tree/collisions?treeId=1&amp;tsuids=010101,020202</a></div>\n</blockquote> </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"010101\": \"AAAAAA\",\n  \"020202\": \"BBBBBB\"\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/tree/collisions.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/tree/collisions.html</a>\n  </p>\n</div>\n","api_http/tree/notmatched":"<h1>/api/tree/notmatched</h1> <p>When processing a TSMeta, if the tree has <code class=\"docutils literal\"><span class=\"pre\">strictMatch</span></code> enabled and the meta fails to match on a rule in any level of the set, a <em>not matched</em> entry will be recorded. This endpoint allows for retrieving the list of TSUIDs that failed to match a rule set. It is useful for debugging in that if you find a TSUID in this list, you can pass it through the <code class=\"docutils literal\"><span class=\"pre\">/tree/test</span></code> endpoint to get details on why the meta failed to match.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Calling this endpoint without a list of one or more TSUIDs will return all non-matched TSUIDs in the tree. If you have a large number of timeseries in your system, the response can potentially be very large. Thus it is best to use this endpoint with specific TSUIDs.</p> </div> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If <code class=\"docutils literal\"><span class=\"pre\">storeFailures</span></code> is diabled for the tree, this endpoint will not return any data. Not Matched entries will still appear in the TSD's logs.</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>The following fields are used for this endpoint</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>treeId</td> <td>Integer</td> <td>Required</td> <td>The ID of the tree to pass the TSMeta objects through</td> <td> </td> <td>treeid</td> <td> </td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>tsuids</td> <td>String</td> <td>Required</td> <td>A list of one or more TSUIDs to search for not-matched entries. If requesting testing of more than one TSUID, they should be separted by a comma.</td> <td> </td> <td>tsuids</td> <td> </td> <td>000001000001000001,00000200000200002</td> </tr> </tbody> </table>   <h2>Response</h2> <p>A successful response will return a map of key/value pairs where the unrecorded TSUID as the key and a message about which rule failed to match as the value. The response will only return not matched entries that were found. If one or more of the TSUIDs requested did not result in a not matched entry, it will not be returned with the result. This may mean that the TSMeta has not been processed yet. Note that if no failed matches have occurred or the tree hasn't processed any data yet, the result set will be empty. If the requested tree did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned.</p> <div class=\"section\" id=\"example-request\"> <h3>Example Request</h3> <blockquote> <div><a class=\"reference external\" href=\"http://localhost:4242/api/tree/notmatched?treeId=1&amp;tsuids=010101,020202\">http://localhost:4242/api/tree/notmatched?treeId=1&amp;tsuids=010101,020202</a></div>\n</blockquote> </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"010101\": \"Failed rule 0:0\",\n  \"020202\": \"Failed rule 1:1\"\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/tree/notmatched.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/tree/notmatched.html</a>\n  </p>\n</div>\n","api_http/tree/rules":"<h1>/api/tree/rules</h1> <p>The rules endpoint is used for bulk merging, replacing or deleting the entire ruleset of a tree. Instead of calling the <code class=\"docutils literal\"><span class=\"pre\">tree/rule</span></code> endpoint multiple times for a single rule, you can supply a list of rules that will be merged into, or replace, the current rule set. Note that the <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> verb is not supported for this endpoint. To fetch the ruleset, load the tree via the <code class=\"docutils literal\"><span class=\"pre\">/tree</span></code> endpoint. Also, all data must be provided in request content, query strings are not supported.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>POST - Merge rule sets</li> <li>PUT - Replace the entire rule set</li> <li>DELETE - Delete a rule</li> </ul>   <h2>Requests</h2> <p>A request to store data must be an array of objects in the content of the request. The same fields as required for the <a class=\"reference internal\" href=\"rule\"><em>/api/tree/rule</em></a> endpoint are supported.</p>   <h2>Response</h2> <p>A successful response to a <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> request will return a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> response code without body content. Successful <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> calls will return with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no body content. If a tree does not have any rules, the <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> request will still return a <code class=\"docutils literal\"><span class=\"pre\">204</span></code>. When modifying data, if no changes were present, i.e. the call did not provide any data to store, the response will be a <code class=\"docutils literal\"><span class=\"pre\">304</span></code> without any body content. If the requested tree did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned.</p>   <h2>POST/PUT</h2> <p>Issuing a <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> will merge the given rule set with any that already exist. This means that if a rule already exists for one of the given rules, only the fields given will be modified in the existing rule. Using the <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> method will replace <em>all</em> of the rules for the given tree with the new set. Any existing rules for the tree will be deleted before the new rules are stored.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">All of the rules in the request array must belong to the same <code class=\"docutils literal\"><span class=\"pre\">treeId</span></code> or a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> exception will be returned. Likewise, all of the rules will pass validation and must include the <code class=\"docutils literal\"><span class=\"pre\">level</span></code> and <code class=\"docutils literal\"><span class=\"pre\">order</span></code> fields.</p> </div> <div class=\"section\" id=\"example-post-request\"> <h3>Example POST Request</h3> <pre data-language=\"javascript\">http://localhost:4242/api/tree/rule?treeId=1&amp;level=0&amp;order=0&amp;type=METRIC&amp;separator=.&amp;method_override=post\n</pre>\n </div> <div class=\"section\" id=\"example-content-request\"> <h3>Example Content Request</h3> <pre data-language=\"javascript\">[\n  {\n    \"treeId\": 1,\n    \"level\": 0,\n    \"order\": 0,\n    \"type\": \"METRIC\",\n    \"description\": \"Metric split rule\",\n    \"split\": \"\\\\.\"\n  },\n  {\n    \"treeId\": 1,\n    \"level\": 0,\n    \"order\": 1,\n    \"type\": \"tagk\",\n    \"field\": \"fqdn\",\n    \"description\": \"Hostname for the device\"\n  },\n  {\n    \"treeId\": 1,\n    \"level\": 1,\n    \"order\": 0,\n    \"type\": \"tagk\",\n    \"field\": \"department\"\n    \"description\": \"Department that owns the device\"\n  }\n]\n</pre>\n </div>   <h2>DELETE</h2> <p>Using the <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> method will remove all rules from a tree. A successful deletion will respond with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no content body. If the tree did not exist, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> error will be returned.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">This method cannot be undone.</p> </div> <div class=\"section\" id=\"example-delete-request\"> <h3>Example DELETE Request</h3> <pre data-language=\"python\">http://localhost:4242/api/tree/rules?treeId=1&amp;method_override=delete\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/tree/rules.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/tree/rules.html</a>\n  </p>\n</div>\n","api_http/query/last":"<h1>/api/query/last</h1> <p>This endpoint (2.1 and later) provides support for accessing the latest value of individual time series. It provides an optimization over a regular query when only the last data point is required. Locating the last point can be done with the timestamp of the meta data counter or by scanning backwards from the current system time.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">In order for this endpoint to function with metric string queries by scanning for matching time series, the meta data table must exist and have been populated with counters or TSMeta objects using one of the methods specified in <a class=\"reference internal\" href=\"../../user_guide/metadata\"><em>Metadata</em></a>. You must set either <code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_tsuid_tracking</span></code> or <code class=\"docutils literal\"><span class=\"pre\">tsd.core.meta.enable_realtime_ts</span></code>. Queries with a backscan parameter will skip the meta table.</p> </div> <p>Similar to the standard query endpoint, there are two methods to use in selecting which time series should return data:</p> <ul class=\"simple\"> <li>\n<strong>Metric Query</strong> - Similar to a regular metric query, you can send a metric name and optionally a set of tag pairs. If the real-time meta has been enabled, the TSD will scan the meta data table to see if any time series match the query. For each time series that matches, it will scan for the latest data point and return it. However if meta is disabled, then the TSD will attempt a lookup for the exact set of metric and tags provided as long as a backscan value is given (as of 2.1.1).</li> <li>\n<strong>TSUID Query</strong> - If you know the TSUIDs for the time series that you want to access data for, simply provide a list of TSUIDs.</li> </ul> <p>Additionally there are two ways to find the last data point for each time series located:</p> <ul class=\"simple\"> <li>\n<strong>Counter Method</strong> - If no backscan value is given and meta is enabled, the default is to lookup the data point counter in the meta data table for each time series. This counter records the time when the latest data point was written by a TSD. The endpoint looks up the timestamp and \"gets\" the proper data row, fetching the last point in the row. This will work most of the time, however please be aware that if you backfill older data (via an import or simply putting a data point with an old timestamp) the counter column timestamp may not be accurate. This method is best used for continuously updated data.</li> <li>\n<strong>Back Scan</strong> - Alternatively you can specify a number of hours to scan back in time starting at the current system time of the TSD where the query is being executed. For example, if you specify a back scan time of 24 hours, the TSD will first look for data in the row with the current hour. If that row is empty, it will look for data one hour before that. It will keep doing that until it finds a data point or it exceeds the hour limit. This method is useful if you often write data points out of order in time. Also note that the larger the backscan value, the longer it may take for queries to complete as they may scan further back in time for data.</li> </ul> <p>All queries will return results only for time series that matched the query and for which a data point was found. The results are a list of individual data points per time series. Aggregation cannot be performed on individual data points as the timestamps may not align and the TSD will only return a single point so interpolation is impossible.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> <li>POST</li> </ul>   <h2>Requests</h2> <p>Common parameters include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>queries</td> <td>Array</td> <td>Required</td> <td>A list of one or more queries used to determine which time series to fetch the last data point for.</td> <td> </td> <td>timeseries | tsuids</td> <td> </td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>resolveNames</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to resolve the TSUIDs of results to their metric and tag names.</td> <td>false</td> <td>resolve</td> <td> </td> <td>true</td> </tr> <tr class=\"row-even\">\n<td>backScan</td> <td>Integer</td> <td>Optional</td> <td>A number of hours to search in the past for data. If set to 0 then the timestamp of the meta data counter for the time series is used.</td> <td>0</td> <td>back_scan</td> <td> </td> <td>24</td> </tr> </tbody> </table> <p>Note that you can mix multiple metric and TSUID queries in one request.</p> <div class=\"section\" id=\"metric-query-string-format\"> <h3>Metric Query String Format</h3> <p>The full specification for a metric query string sub query is as follows:</p> <pre data-language=\"python\">timeseries=&lt;metric_name&gt;[{&lt;tag_name1&gt;=&lt;tag_value1&gt;[,...&lt;tag_nameN&gt;=&lt;tag_valueN&gt;]}]\n</pre>\n <p>It is similar to a regular metric query but does not allow for aggregations, rates, down sampling or grouping operators. Note that if you supply a backscan value to avoid the meta table, then you must supply all of the tags and values to match the exact time series you are looking for. Backscan does not currently filter on the metric and tags given but will look for the specific series.</p> </div> <div class=\"section\" id=\"tsuid-query-string-format\"> <h3>TSUID Query String Format</h3> <p>TSUID queries are simpler than Metric queries. Simply pass a list of one or more hexadecimal encoded TSUIDs separated by commas:</p> <pre data-language=\"python\">tsuids=&lt;tsuid1&gt;[,...&lt;tsuidN&gt;]\n</pre>\n </div> <div class=\"section\" id=\"example-query-string-requests\"> <h3>Example Query String Requests</h3> <pre data-language=\"python\">http://localhost:4242/api/query/last?timeseries=proc.stat.cpu{host=foo,type=idle}&amp;timeseries=proc.stat.mem{host=foo,type=idle}\nhttp://localhost:4242/api/query/last?tsuids=000001000002000003,000001000002000004&amp;back_scan=24&amp;resolve=true\n</pre>\n </div> <div class=\"section\" id=\"example-content-request\"> <h3>Example Content Request</h3> <pre data-language=\"javascript\">{\n  \"queries\": [\n    {\n      \"metric\": \"sys.cpu.0\",\n      \"tags\": {\n        \"host\": \"web01\",\n        \"dc\": \"lga\"\n      }\n    },\n    {\n      \"tsuids\": [\n        \"000001000002000042\",\n        \"000001000002000043\"\n        ]\n      }\n    }\n  ],\n  \"resolveNames\":true,\n  \"backScan\":24\n}\n</pre>\n </div>   <h2>Response</h2> <p>The output will be an array of 0 or more data points depending on the data that was found. If a data point for a particular time series was not located within the time specified, it will not appear in the output. Output fields depend on whether or not the <code class=\"docutils literal\"><span class=\"pre\">resolve</span></code> flag was set.</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"80%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>metric</td> <td>Name of the metric for the time series. Only returned if <code class=\"docutils literal\"><span class=\"pre\">resolve</span></code> was set to true.</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>A list of tags for the time series. Only returned if <code class=\"docutils literal\"><span class=\"pre\">resolve</span></code> was set to true.</td> </tr> <tr class=\"row-even\">\n<td>timestamp</td> <td>A Unix epoch timestamp, in milliseconds, when the data point was written</td> </tr> <tr class=\"row-odd\">\n<td>value</td> <td>The value of the data point enclosed in quotation marks as a string</td> </tr> <tr class=\"row-even\">\n<td>tsuid</td> <td>The hexadecimal TSUID for the time series</td> </tr> </tbody> </table> <p>Unless there was an error with the query, you will generally receive a <code class=\"docutils literal\"><span class=\"pre\">200</span></code> status with content. However if your query couldn't find any data, it will return an empty result set. In the case of the JSON serializer, the result will be an empty array:</p> <pre data-language=\"javascript\">[]\n</pre>\n <div class=\"section\" id=\"example-responses\"> <h3>Example Responses</h3> <pre data-language=\"javascript\">[\n  {\n    \"timestamp\": 1377118201000,\n    \"value\": \"1976558550\",\n    \"tsuid\": \"0023E3000002000008000006000001\"\n  },\n  {\n    \"timestamp\": 1377118201000,\n    \"value\": \"1654587485\",\n    \"tsuid\": \"0023E3000002000008000006001656\"\n  }\n]\n</pre>\n <pre data-language=\"javascript\">[\n  {\n    \"metric\": \"tsd.hbase.rpcs\",\n    \"timestamp\": 1377186301000,\n    \"value\": \"2723265185\",\n    \"tags\": {\n      \"type\": \"put\",\n      \"host\": \"tsd1\"\n    },\n    \"tsuid\": \"0023E3000002000008000006000001\"\n  },\n  {\n    \"metric\": \"tsd.hbase.rpcs\",\n    \"timestamp\": 1377186301000,\n    \"value\": \"580720\",\n    \"tags\": {\n      \"type\": \"put\",\n      \"host\": \"tsd2\"\n    },\n    \"tsuid\": \"0023E3000002000008000006017438\"\n  }\n]\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/query/last.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/query/last.html</a>\n  </p>\n</div>\n","api_http/tree/branch":"<h1>/api/tree/branch</h1> <p>A branch represents a level in the tree heirarchy and contains information about child branches and/or leaves. Branches are immutable from an API perspective and can only be created or modified by processing a TSMeta through tree rules via a CLI command or when a new timeseries is encountered or a TSMeta object modified. Therefore the <code class=\"docutils literal\"><span class=\"pre\">branch</span></code> endpoint only supports the <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> verb.</p> <p>A branch is identified by a <code class=\"docutils literal\"><span class=\"pre\">branchId</span></code>, a hexadecimal encoded string that represents the ID of the tree it belongs to as well as the IDs of each parent the branch stems from. All branches stem from the <strong>ROOT</strong> branch of a tree and this is usually the starting place when browsing. To fetch the <strong>ROOT</strong> just call this endpoingt with a valid <code class=\"docutils literal\"><span class=\"pre\">treeId</span></code>. The root branch ID is also a 4 character encoding of the tree ID.</p>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET</li> </ul>   <h2>Requests</h2> <p>The following fields can be used to request a branch. Only one or the other may be used.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>treeId</td> <td>Integer</td> <td>Optional</td> <td>Used to fetch the root branch of the tree. If used in combination with a branchId, the tree ID will be ignored.</td> <td> </td> <td>treeid</td> <td>RO</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>branch</td> <td>String</td> <td>Required</td> <td>A hexadecimal representation of the branch ID, required for all but the root branch request</td> <td> </td> <td>branch</td> <td>RO</td> <td>000183A21C8F</td> </tr> </tbody> </table>   <h2>Response</h2> <p>A successful response to a request will return the branch object using the requested serializer. If the requested tree or branch did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message.</p> <p>Fields returned with the response include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>treeId</td> <td>Integer</td> <td>The ID of the tree the branch belongs to</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>displayName</td> <td>String</td> <td>Name of the branch as determined by the rule set</td> <td>sys</td> </tr> <tr class=\"row-even\">\n<td>branchId</td> <td>String</td> <td>Hexadecimal encoded ID of the branch</td> <td>00010001BECD</td> </tr> <tr class=\"row-odd\">\n<td>depth</td> <td>Integer</td> <td>Depth of the branch within the tree, starting at <em>0</em> for the root branch</td> <td>1</td> </tr> <tr class=\"row-even\">\n<td>path</td> <td>Map</td> <td>List of parent branch names and their depth.</td> <td><em>See Below</em></td> </tr> <tr class=\"row-odd\">\n<td>branches</td> <td>Array</td> <td>An array of child branch objects. May be <code class=\"docutils literal\"><span class=\"pre\">null</span></code>.</td> <td><em>See Below</em></td> </tr> <tr class=\"row-even\">\n<td>leaves</td> <td>Array</td> <td>An array of child leaf objects. May be <code class=\"docutils literal\"><span class=\"pre\">null</span></code>.</td> <td><em>See Leaves Below</em></td> </tr> </tbody> </table> <p><strong>Leaves</strong></p> <p>If a branch contains child leaves, i.e. timeseries stored in OpenTSDB, their metric, tags, TSUID and display name will be contained in the results. Leaf fields are as follows:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"10%\"> <col width=\"60%\"> <col width=\"20%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Description</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>metric</td> <td>String</td> <td>The name of the metric for the timeseries</td> <td>sys.cpu.0</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Map</td> <td>A list of tag names and values representing the timeseries</td> <td><em>See Below</em></td> </tr> <tr class=\"row-even\">\n<td>tsuid</td> <td>String</td> <td>Hexadecimal encoded timeseries ID</td> <td>000001000001000001</td> </tr> <tr class=\"row-odd\">\n<td>displayName</td> <td>String</td> <td>A name as parsed by the rule set</td> <td>user</td> </tr> </tbody> </table>   <h2>GET</h2> <div class=\"section\" id=\"example-root-get-query\"> <h3>Example Root GET Query</h3> <pre data-language=\"python\">http://localhost:4242/api/tree/branch?treeid=1\n</pre>\n </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"leaves\": null,\n  \"branches\": [\n    {\n      \"leaves\": null,\n      \"branches\": null,\n      \"path\": {\n        \"0\": \"ROOT\",\n        \"1\": \"sys\"\n      },\n      \"treeId\": 1,\n      \"displayName\": \"sys\",\n      \"branchId\": \"00010001BECD\",\n      \"depth\": 1\n    }\n  ],\n  \"path\": {\n    \"0\": \"ROOT\"\n  },\n  \"treeId\": 1,\n  \"displayName\": \"ROOT\",\n  \"branchId\": \"0001\",\n  \"depth\": 0\n}\n</pre>\n </div> <div class=\"section\" id=\"example-branch-get-query\"> <h3>Example Branch GET Query</h3> <pre data-language=\"python\">http://localhost:4242/api/tree/branch?branchid=00010001BECD000181A8\n</pre>\n </div> <div class=\"section\" id=\"id1\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"leaves\": [\n    {\n      \"metric\": \"sys.cpu.0.user\",\n      \"tags\": {\n        \"host\": \"web01\"\n      },\n      \"tsuid\": \"000001000001000001\",\n      \"displayName\": \"user\"\n    }\n  ],\n  \"branches\": [\n    {\n      \"leaves\": null,\n      \"branches\": null,\n      \"path\": {\n        \"0\": \"ROOT\",\n        \"1\": \"sys\",\n        \"2\": \"cpu\",\n        \"3\": \"mboard\"\n      },\n      \"treeId\": 1,\n      \"displayName\": \"mboard\",\n      \"branchId\": \"00010001BECD000181A8BF992A99\",\n      \"depth\": 3\n    }\n  ],\n  \"path\": {\n    \"0\": \"ROOT\",\n    \"1\": \"sys\",\n    \"2\": \"cpu\"\n  },\n  \"treeId\": 1,\n  \"displayName\": \"cpu\",\n  \"branchId\": \"00010001BECD000181A8\",\n  \"depth\": 2\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/tree/branch.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/tree/branch.html</a>\n  </p>\n</div>\n","api_http/tree/rule":"<h1>/api/tree/rule</h1> <p>Each rule in a tree is an individual object in storage, thus the <code class=\"docutils literal\"><span class=\"pre\">/api/tree/rule</span></code> endpoint allows for easy modification of a single rule in the set. Rules are addressed by their <code class=\"docutils literal\"><span class=\"pre\">tree</span></code> ID, <code class=\"docutils literal\"><span class=\"pre\">level</span></code> and <code class=\"docutils literal\"><span class=\"pre\">order</span></code> and all requests require these three parameters.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">If a manual tree synchronization is running somewhere or there is a large number of TSMeta objects being created or edited, the tree rule may be cached and modifications to a tree's rule set may take some time to propagate. If you make any modifications to the rule set, other than to meta information such as the <code class=\"docutils literal\"><span class=\"pre\">description</span></code> and <code class=\"docutils literal\"><span class=\"pre\">notes</span></code>, you may want to flush the tree data and perform a manual synchronization so that branches and leaves reflect the new rules.</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>GET - Retrieve one or more rules</li> <li>POST - Create or modify a rule</li> <li>PUT - Create or replace a rule</li> <li>DELETE - Delete a rule</li> </ul>   <h2>Requests</h2> <p>The following fields can be used for all rule endpoint requests:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"15%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">QS</th> <th class=\"head\">RW</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>treeId</td> <td>Integer</td> <td>Required</td> <td>The tree the requested rule belongs to</td> <td> </td> <td>treeid</td> <td>RO</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>level</td> <td>Integer</td> <td>Required</td> <td>The level in the rule heirarchy where the rule resides. Must be 0 or greater.</td> <td>0</td> <td>level</td> <td>RW</td> <td>2</td> </tr> <tr class=\"row-even\">\n<td>order</td> <td>Integer</td> <td>Required</td> <td>The order within a level where the rule resides. Must be 0 or greater.</td> <td>0</td> <td>order</td> <td>RW</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>description</td> <td>String</td> <td>Optional</td> <td>A brief description of the rule's purpose</td> <td> </td> <td>description</td> <td>RW</td> <td>Split the metric by dot</td> </tr> <tr class=\"row-even\">\n<td>notes</td> <td>String</td> <td>Optional</td> <td>Detailed notes about the rule</td> <td> </td> <td>notes</td> <td>RW</td> <td> </td> </tr> <tr class=\"row-odd\">\n<td>type</td> <td>String</td> <td>Required*</td> <td>The type of rule represented. See <a class=\"reference internal\" href=\"../../user_guide/trees\"><em>Trees</em></a>. <a href=\"#id1\"><span class=\"problematic\" id=\"id2\">*</span></a>Required when creating a new rule.</td> <td> </td> <td>type</td> <td>RW</td> <td>METRIC</td> </tr> <tr class=\"row-even\">\n<td>field</td> <td>String</td> <td>Optional</td> <td>The name of a field for the rule to operate on</td> <td> </td> <td>field</td> <td>RW</td> <td>host</td> </tr> <tr class=\"row-odd\">\n<td>customField</td> <td>String</td> <td>Optional</td> <td>The name of a <code class=\"docutils literal\"><span class=\"pre\">TSMeta</span></code> custom field for the rule to operate on. Note that the <code class=\"docutils literal\"><span class=\"pre\">field</span></code> value must also be configured or an exception will be raised.</td> <td> </td> <td>custom_field</td> <td>RW</td> <td>owner</td> </tr> <tr class=\"row-even\">\n<td>regex</td> <td>String</td> <td>Optional</td> <td>A regular expression pattern to process the associated field or custom field value through.</td> <td> </td> <td>regex</td> <td>RW</td> <td>^.*\\.([a-zA-Z]{3,4})[0-9]{0,1}\\..*\\..*$</td> </tr> <tr class=\"row-odd\">\n<td>separator</td> <td>String</td> <td>Optional</td> <td>If the field value should be split into multiple branches, provide the separation character.</td> <td> </td> <td>separator</td> <td>RW</td> <td>\\.</td> </tr> <tr class=\"row-even\">\n<td>regexGroupIdx</td> <td>Integer</td> <td>Optional</td> <td>A group index for extracting a portion of a pattern from the given regular expression pattern. Must be 0 or greater.</td> <td>0</td> <td>regex_group_idx</td> <td>RW</td> <td>1</td> </tr> <tr class=\"row-odd\">\n<td>displayFormat</td> <td>String</td> <td>Optional</td> <td>A display format string to alter the <code class=\"docutils literal\"><span class=\"pre\">display_name</span></code> value of the resulting branch or leaf. See <a class=\"reference internal\" href=\"../../user_guide/trees\"><em>Trees</em></a>\n</td> <td> </td> <td>display_format</td> <td>RW</td> <td>Port: {ovalue}</td> </tr> </tbody> </table> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">When supplying a <code class=\"docutils literal\"><span class=\"pre\">separator</span></code> or a <code class=\"docutils literal\"><span class=\"pre\">regex</span></code> value, you must supply a valid regular expression. For separators, the most common use is to split dotted metrics into branches. E.g. you may want \"sys.cpu.0.user\" to be split into \"sys\", \"cpu\", \"0\" and \"user\" branches. You cannot supply just a \".\" for the separator value as that will not match properly. Instead, escape the period via \".\". Note that if you are supplying JSON via a POST request, you must escape the backslash as well and supply \"\\.\". GET request responses will escape all backslashes.</p> </div>   <h2>Response</h2> <p>A successful response to a <code class=\"docutils literal\"><span class=\"pre\">GET</span></code>, <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> request will return the full rule object with optional requested changes. Successful <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> calls will return with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no body content. When modifying data, if no changes were present, i.e. the call did not provide any data to store, the resposne will be a <code class=\"docutils literal\"><span class=\"pre\">304</span></code> without any body content. If the requested tree or rule did not exist in the system, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> will be returned with an error message. If invalid data was supplied a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> error will be returned.</p>   <h2>GET</h2> <p>A <code class=\"docutils literal\"><span class=\"pre\">GET</span></code> request requires a specific tree ID, rule level and order. Otherwise a <code class=\"docutils literal\"><span class=\"pre\">400</span></code> will be returned. To fetch all of the rules for a tree, use the <code class=\"docutils literal\"><span class=\"pre\">/api/tree</span></code> endpoint with a <a href=\"#id3\"><span class=\"problematic\" id=\"id4\">``</span></a>treeId' value.</p> <div class=\"section\" id=\"example-get-query\"> <h3>Example GET Query</h3> <pre data-language=\"python\">http://localhost:4242/api/tree/rule?treeId=1&amp;level=0&amp;order=0\n</pre>\n </div> <div class=\"section\" id=\"example-response\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"type\": \"METRIC\",\n  \"field\": \"\",\n  \"regex\": \"\",\n  \"separator\": \"\\\\.\",\n  \"description\": \"Split the metric on periods\",\n  \"notes\": \"\",\n  \"level\": 1,\n  \"order\": 0,\n  \"treeId\": 1,\n  \"customField\": \"\",\n  \"regexGroupIdx\": 0,\n  \"displayFormat\": \"\"\n}\n</pre>\n </div>   <h2>POST/PUT</h2> <p>Using the <code class=\"docutils literal\"><span class=\"pre\">POST</span></code> or <code class=\"docutils literal\"><span class=\"pre\">PUT</span></code> methods, you can create a new rule or edit an existing rule. New rules require a <code class=\"docutils literal\"><span class=\"pre\">type</span></code> value. Existing trees require a valid <code class=\"docutils literal\"><span class=\"pre\">treeId</span></code> ID and any fields that require modification. A successful request will return the modified rule object. Note that if a rule exists at the given level and order, any changes will be merged with or overwrite the existing rule.</p> <div class=\"section\" id=\"example-query-string-request\"> <h3>Example Query String Request</h3> <pre data-language=\"python\">http://localhost:4242/api/tree/rule?treeId=1&amp;level=0&amp;order=0&amp;type=METRIC&amp;separator=\\.&amp;method_override=post\n</pre>\n </div> <div class=\"section\" id=\"example-content-request\"> <h3>Example Content Request</h3> <pre data-language=\"javascript\">{\n  \"type\": \"METRIC\",\n  \"separator\": \"\\\\.\",\n  \"description\": \"Split the metric on periods\",\n  \"level\": 1,\n  \"order\": 0,\n  \"treeId\": 1\n}\n</pre>\n </div> <div class=\"section\" id=\"id5\"> <h3>Example Response</h3> <pre data-language=\"javascript\">{\n  \"type\": \"METRIC\",\n  \"field\": \"\",\n  \"regex\": \"\",\n  \"separator\": \"\\\\.\",\n  \"description\": \"Split the metric on periods\",\n  \"notes\": \"\",\n  \"level\": 1,\n  \"order\": 0,\n  \"treeId\": 1,\n  \"customField\": \"\",\n  \"regexGroupIdx\": 0,\n  \"displayFormat\": \"\"\n}\n</pre>\n </div>   <h2>DELETE</h2> <p>Using the <code class=\"docutils literal\"><span class=\"pre\">DELETE</span></code> method will remove a rule from a tree. A successful deletion will respond with a <code class=\"docutils literal\"><span class=\"pre\">204</span></code> status code and no content body. If the rule did not exist, a <code class=\"docutils literal\"><span class=\"pre\">404</span></code> error will be returned.</p> <div class=\"admonition warning\"> <p class=\"first admonition-title\">Warning</p> <p class=\"last\">This method cannot be undone.</p> </div> <div class=\"section\" id=\"example-delete-request\"> <h3>Example DELETE Request</h3> <pre data-language=\"python\">http://localhost:4242/api/tree/rule?treeId=1&amp;level=0&amp;order=0&amp;method_override=delete\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/tree/rule.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/tree/rule.html</a>\n  </p>\n</div>\n","user_guide/query/stats":"<h1>Query Details and Stats</h1> <p>With version 2.2 of OpenTSDB a number of details are now available around queries as we focus on improving flexibility and performance. Query details include who made the request (via headers and socket), what the response was (HTTP status codes and/or exceptions) and timing around the various processes the TSD takes.</p> <p>Each HTTP query can include some of these details such as the original query and the timing information using the <code class=\"docutils literal\"><span class=\"pre\">showSummary</span></code> and <code class=\"docutils literal\"><span class=\"pre\">showQuery</span></code> parameters. Other details can be found in the <code class=\"docutils literal\"><span class=\"pre\">/api/stats/query</span></code> output including headers, status and exceptions. And full details (minus the actual result data) can be logged to disk via the logging config. This page details the various query sections and the information found therein.</p>  <h2>Query</h2> <p>This section is a serialization of the query given by the user. In the logs and stats page this will be the full query with timing and global options. When returned with the query results, only the sub query (metric and filters) are returned with the associated result set for identification purposes (e.g. if you request the same metric twice with two different aggregators, you need to know which data set corresponds to which aggregator).</p> <p>For the fields and what they mean, see <a class=\"reference internal\" href=\"../../api_http/query/index\"><em>/api/query</em></a>. Some notes about the fields:</p> <ul class=\"simple\"> <li>The <code class=\"docutils literal\"><span class=\"pre\">tags</span></code> map should have the same number of entries as the <code class=\"docutils literal\"><span class=\"pre\">filters</span></code> array has <code class=\"docutils literal\"><span class=\"pre\">group_by</span></code> entries. This is due to backwards compatibility with 2.1 and 1.0. Old style queries are converted into filtered queries and function the same way.</li> <li>A number of extra fields may be shown here with their default values such as <code class=\"docutils literal\"><span class=\"pre\">null</span></code>.</li> <li>You can copy and paste the query into a POST client to execute and find out what data was returned.</li> </ul> <div class=\"section\" id=\"example\"> <h3>Example</h3> <pre data-language=\"javascript\">{\n    \"start\": \"1455531250181\",\n    \"end\": null,\n    \"timezone\": null,\n    \"options\": null,\n    \"padding\": false,\n    \"queries\": [{\n        \"aggregator\": \"zimsum\",\n        \"metric\": \"tsd.connectionmgr.bytes.written\",\n        \"tsuids\": null,\n        \"downsample\": \"1m-avg\",\n        \"rate\": true,\n        \"filters\": [{\n            \"tagk\": \"colo\",\n            \"filter\": \"*\",\n            \"group_by\": true,\n            \"type\": \"wildcard\"\n        }, {\n            \"tagk\": \"env\",\n            \"filter\": \"prod\",\n            \"group_by\": true,\n            \"type\": \"literal_or\"\n        }, {\n            \"tagk\": \"role\",\n            \"filter\": \"frontend\",\n            \"group_by\": true,\n            \"type\": \"literal_or\"\n        }],\n        \"rateOptions\": {\n            \"counter\": true,\n            \"counterMax\": 9223372036854775807,\n            \"resetValue\": 1,\n            \"dropResets\": false\n        },\n        \"tags\": {\n            \"role\": \"literal_or(frontend)\",\n            \"env\": \"literal_or(prod)\",\n            \"colo\": \"wildcard(*)\"\n        }\n    }, {\n        \"aggregator\": \"zimsum\",\n        \"metric\": \"tsd.hbase.rpcs.cumulative_bytes_received\",\n        \"tsuids\": null,\n        \"downsample\": \"1m-avg\",\n        \"rate\": true,\n        \"filters\": [{\n            \"tagk\": \"colo\",\n            \"filter\": \"*\",\n            \"group_by\": true,\n            \"type\": \"wildcard\"\n        }, {\n            \"tagk\": \"env\",\n            \"filter\": \"prod\",\n            \"group_by\": true,\n            \"type\": \"literal_or\"\n        }, {\n            \"tagk\": \"role\",\n            \"filter\": \"frontend\",\n            \"group_by\": true,\n            \"type\": \"literal_or\"\n        }],\n        \"rateOptions\": {\n            \"counter\": true,\n            \"counterMax\": 9223372036854775807,\n            \"resetValue\": 1,\n            \"dropResets\": false\n        },\n        \"tags\": {\n            \"role\": \"literal_or(frontend)\",\n            \"env\": \"literal_or(prod)\",\n            \"colo\": \"wildcard(*)\"\n        }\n    }],\n    \"delete\": false,\n    \"noAnnotations\": false,\n    \"globalAnnotations\": false,\n    \"showTSUIDs\": false,\n    \"msResolution\": false,\n    \"showQuery\": false,\n    \"showStats\": false,\n    \"showSummary\": false\n}\n</pre>\n </div>   <h2>Exception</h2> <p>If the query failed, this field will include the message string and the first line of the stack trace for pinpointing. If the query was successful, this field will be null.</p> <div class=\"section\" id=\"id1\"> <h3>Example</h3> <pre data-language=\"javascript\">\"exception\": \"No such name for 'metrics': 'nosuchmetric' net.opentsdb.uid.UniqueId$1GetIdCB.call(UniqueId.java:315)\"\n</pre>\n </div>   <h2>User</h2> <p>For future use, this field can be used to extract user information from queries and help debug who is using a TSD the most. It's fairly easy to modify the TSD code to extract the user from an HTTP header.</p>   <h2>RequestHeaders</h2> <p>This is a map of the headers sent with the HTTP request. In a mediocre effort at security, the <code class=\"docutils literal\"><span class=\"pre\">Cookie</span></code> header field is obfuscated with asterisks in the case that it contains user identifiable or secure information. Each request is different so lookup the headers in the HTTP RFCs or your web browser or clients documentation.</p> <div class=\"section\" id=\"id2\"> <h3>Example</h3> <pre data-language=\"javascript\">\"requestHeaders\": {\n  \"Accept-Language\": \"en-US,en;q=0.8\",\n  \"Host\": \"tsdhost:4242\",\n  \"Content-Length\": \"440\",\n  \"Referer\": \"http://tsdhost:8080/dashboard/db/tsdfrontend\",\n  \"Accept-Encoding\": \"gzip, deflate\",\n  \"X-Forwarded-For\": \"192.168.0.2\",\n  \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.109 Safari/537.36\",\n  \"Origin\": \"http://tsdhost:8080\",\n  \"Content-Type\": \"application/json;charset=UTF-8\",\n  \"Accept\": \"application/json, text/plain, */*\"\n}\n</pre>\n </div>   <h2>HttpResponse</h2> <p>This field contains the numeric HTTP response code and a textual representation of that code.</p> <div class=\"section\" id=\"id3\"> <h3>Example</h3> <pre data-language=\"javascript\">\"httpResponse\": {\n    \"code\": 200,\n    \"reasonPhrase\": \"OK\"\n}\n</pre>\n </div>   <h2>Other Fields</h2> <p>The output for log files and the stats page include other fields with single values as listed below:</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"20%\"> <col width=\"60%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Metric</th> <th class=\"head\">Type</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>executed</td> <td>Counter</td> <td>If the same query was executed multiple times (same times, same agent, etc) then this integer counter will increment. Use this to find out when a client may want to start caching results.</td> </tr> <tr class=\"row-odd\">\n<td>numRunningQueries</td> <td>Gauge</td> <td>How many queries were executing at the time the query was made (note that for the stats page this will always be up-to-date)</td> </tr> <tr class=\"row-even\">\n<td>queryStartTimestamp</td> <td>Timestamp (ms)</td> <td>The timestamp (Unix epoch in milliseconds) when the query was received and started processing.</td> </tr> <tr class=\"row-odd\">\n<td>queryCompletedTimestamp</td> <td>Timestamp (ms)</td> <td>The timestamp (Unix epoch in milliseconds) when the query was finished and sent to the client.</td> </tr> <tr class=\"row-even\">\n<td>sentToClient</td> <td>boolean</td> <td>Whether or not the query was successfully sent to the client. It may be blocked due to a socket exception or full write buffer.</td> </tr> </tbody> </table>   <h2>Stats</h2> <p>A number of statistics are available around each query and more will be added over time. Various levels of detail are measured including:</p> <ul class=\"simple\"> <li>\n<strong>Global</strong> - Metrics pertaining to the entire query including max and average timings of each sub query.</li> <li>\n<strong>Per-Sub Query</strong> - Metrics pertaining to a single sub query (if multiple are present) including max and average timings of scanner.</li> <li>\n<strong>Per-Scanner</strong> - Metrics around each individual scanner (useful when salting is enabled)</li> </ul> <p>Global stats are printed to the standard log, stats page. The full global, sub query and scanner details are available in the query log and via the query API when <code class=\"docutils literal\"><span class=\"pre\">showSummary</span></code> is present. Timing stats at a lower level are aggregated into max and average values at the upper level. Counters at each lower level are also aggregated at each upper level so you'll see the same counter metrics at each level. A table of stats and sections appears below.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">All timings in the table below are in milliseconds. Also note that times can be inflated by JVM GCs so make sure to enable GC logging if something seems off.</p> </div> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"10%\"> <col width=\"20%\"> <col width=\"50%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Metric</th> <th class=\"head\">Type</th> <th class=\"head\">Section</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>compactionTime</td> <td>Float</td> <td>Scanner</td> <td>Cumulative time spent running each row through the compaction code to create a single column and manage duplicate values.</td> </tr> <tr class=\"row-odd\">\n<td>hbaseTime</td> <td>Float</td> <td>Scanner</td> <td>Cumulative time spent waiting on HBase to return data. (Includes AsyncHBase deserialization time).</td> </tr> <tr class=\"row-even\">\n<td>scannerId</td> <td>String</td> <td>Scanner</td> <td>Details about the scanner including the table, start and end keys as well as filters used.</td> </tr> <tr class=\"row-odd\">\n<td>scannerTime</td> <td>Float</td> <td>Scanner</td> <td>The total time from initialization of the scanner to when the scanner completed and closed.</td> </tr> <tr class=\"row-even\">\n<td>scannerUidToStringTime</td> <td>Float</td> <td>Scanner</td> <td>Cumulative time spent resolving UIDs from row keys to strings for use with regex and wildcard filters. If neither filter is used this value should be zero.</td> </tr> <tr class=\"row-odd\">\n<td>successfulScan</td> <td>Integer</td> <td>Scanner, Query, Global</td> <td>How many scanners completed successfully. Per query, this should be equal to the number of salting buckets, or <code class=\"docutils literal\"><span class=\"pre\">1</span></code> if salting is disabled.</td> </tr> <tr class=\"row-even\">\n<td>uidPairsResolved</td> <td>Integer</td> <td>Scanner</td> <td>Total number of row key UIDs resolved to tag values when a regex or wildcard filter is used. If neither filter is used this value should be zero.</td> </tr> <tr class=\"row-odd\">\n<td>aggregationTime</td> <td>Float</td> <td>Query</td> <td>Cumulative time spent aggregating data points including downsampling, multi-series aggregation and rate calculations.</td> </tr> <tr class=\"row-even\">\n<td>groupByTime</td> <td>Float</td> <td>Query</td> <td>Cumulative time spent sorting scanner results into groups for future aggregation.</td> </tr> <tr class=\"row-odd\">\n<td>queryScanTime</td> <td>Float</td> <td>Query</td> <td>Total time spent waiting on the scanners to return results. This includes the <code class=\"docutils literal\"><span class=\"pre\">groupByTime</span></code>.</td> </tr> <tr class=\"row-even\">\n<td>saltScannerMergeTime</td> <td>Float</td> <td>Query</td> <td>Total time spent merging the salt scanner results into a single set prior to group by operations.</td> </tr> <tr class=\"row-odd\">\n<td>serializationTime</td> <td>Float</td> <td>Query</td> <td>Total time spent serializing the query results. This includes <code class=\"docutils literal\"><span class=\"pre\">aggregationTime</span></code> and <code class=\"docutils literal\"><span class=\"pre\">uidToStringTime</span></code>.</td> </tr> <tr class=\"row-even\">\n<td>uidToStringTime</td> <td>Float</td> <td>Query</td> <td>Cumulative time spent resolving UIDs to strings for serialization.</td> </tr> <tr class=\"row-odd\">\n<td>emittedDPs</td> <td>Integer</td> <td>Query, Global</td> <td>The total number of data points serialized in the output. Note that this may include NaNs or Nulls if the query specified such.</td> </tr> <tr class=\"row-even\">\n<td>queryIndex</td> <td>Integer</td> <td>Query</td> <td>The index of the sub query in the original user supplied query list.</td> </tr> <tr class=\"row-odd\">\n<td>processingPreWriteTime</td> <td>Float</td> <td>Global</td> <td>Total time spent processing, fetching data and serializing results for the query until it is written over the wire. This value is sent in the API summary results and used as an estimate of the total time spent processing by the TSD. However it does not include the amount of time it took to send the value over the wire.</td> </tr> <tr class=\"row-even\">\n<td>totalTime</td> <td>Float</td> <td>Global</td> <td>Total time spent on the query including writing to the socket. This is only found in the log files and stats API.</td> </tr> </tbody> </table> <div class=\"section\" id=\"id4\"> <h3>Example</h3> <pre data-language=\"javascript\">{\n    \"statsSummary\": {\n        \"avgAggregationTime\": 3.784976,\n        \"avgHBaseTime\": 8.530751,\n        \"avgQueryScanTime\": 10.964149,\n        \"avgScannerTime\": 8.588306,\n        \"avgScannerUidToStringTime\": 0.0,\n        \"avgSerializationTime\": 3.809661,\n        \"emittedDPs\": 1256,\n        \"maxAggregationTime\": 3.759478,\n        \"maxHBaseTime\": 9.904215,\n        \"maxQueryScanTime\": 10.320964,\n        \"maxScannerUidtoStringTime\": 0.0,\n        \"maxSerializationTime\": 3.779712,\n        \"maxUidToStringTime\": 0.197926,\n        \"processingPreWriteTime\": 20.170205,\n        \"queryIdx_00\": {\n            \"aggregationTime\": 3.784976,\n            \"avgHBaseTime\": 8.849337,\n            \"avgScannerTime\": 8.908597,\n            \"avgScannerUidToStringTime\": 0.0,\n            \"emittedDPs\": 628,\n            \"groupByTime\": 0.0,\n            \"maxHBaseTime\": 9.904215,\n            \"maxScannerUidtoStringTime\": 0.0,\n            \"queryIndex\": 0,\n            \"queryScanTime\": 10.964149,\n            \"saltScannerMergeTime\": 0.128234,\n            \"scannerStats\": {\n                \"scannerIdx_00\": {\n                    \"compactionTime\": 0.048703,\n                    \"hbaseTime\": 8.844783,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[0, 0, 2, 88, 86, -63, -25, -16], stop_key=[0, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.899045,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_01\": {\n                    \"compactionTime\": 0.066892,\n                    \"hbaseTime\": 8.240165,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[1, 0, 2, 88, 86, -63, -25, -16], stop_key=[1, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.314855,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_02\": {\n                    \"compactionTime\": 0.01298,\n                    \"hbaseTime\": 8.462203,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[2, 0, 2, 88, 86, -63, -25, -16], stop_key=[2, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.478315,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_03\": {\n                    \"compactionTime\": 0.036998,\n                    \"hbaseTime\": 9.862741,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[3, 0, 2, 88, 86, -63, -25, -16], stop_key=[3, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.904215,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_04\": {\n                    \"compactionTime\": 0.058698,\n                    \"hbaseTime\": 9.523481,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[4, 0, 2, 88, 86, -63, -25, -16], stop_key=[4, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.587324,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_05\": {\n                    \"compactionTime\": 0.041017,\n                    \"hbaseTime\": 9.757787,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[5, 0, 2, 88, 86, -63, -25, -16], stop_key=[5, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.802395,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_06\": {\n                    \"compactionTime\": 0.062371,\n                    \"hbaseTime\": 9.332585,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[6, 0, 2, 88, 86, -63, -25, -16], stop_key=[6, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.40264,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_07\": {\n                    \"compactionTime\": 0.063974,\n                    \"hbaseTime\": 8.195105,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[7, 0, 2, 88, 86, -63, -25, -16], stop_key=[7, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.265713,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_08\": {\n                    \"compactionTime\": 0.062196,\n                    \"hbaseTime\": 8.21871,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[8, 0, 2, 88, 86, -63, -25, -16], stop_key=[8, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.287582,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_09\": {\n                    \"compactionTime\": 0.051666,\n                    \"hbaseTime\": 7.790636,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[9, 0, 2, 88, 86, -63, -25, -16], stop_key=[9, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 7.849597,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_10\": {\n                    \"compactionTime\": 0.036429,\n                    \"hbaseTime\": 7.6472,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[10, 0, 2, 88, 86, -63, -25, -16], stop_key=[10, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 7.689386,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_11\": {\n                    \"compactionTime\": 0.044493,\n                    \"hbaseTime\": 7.897932,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[11, 0, 2, 88, 86, -63, -25, -16], stop_key=[11, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 7.94793,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_12\": {\n                    \"compactionTime\": 0.025362,\n                    \"hbaseTime\": 9.30409,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[12, 0, 2, 88, 86, -63, -25, -16], stop_key=[12, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.332411,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_13\": {\n                    \"compactionTime\": 0.057429,\n                    \"hbaseTime\": 9.215958,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[13, 0, 2, 88, 86, -63, -25, -16], stop_key=[13, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.278104,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_14\": {\n                    \"compactionTime\": 0.102855,\n                    \"hbaseTime\": 9.598685,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[14, 0, 2, 88, 86, -63, -25, -16], stop_key=[14, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.712258,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_15\": {\n                    \"compactionTime\": 0.0727,\n                    \"hbaseTime\": 9.273193,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[15, 0, 2, 88, 86, -63, -25, -16], stop_key=[15, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.35403,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_16\": {\n                    \"compactionTime\": 0.025867,\n                    \"hbaseTime\": 9.011146,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[16, 0, 2, 88, 86, -63, -25, -16], stop_key=[16, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.039663,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_17\": {\n                    \"compactionTime\": 0.066071,\n                    \"hbaseTime\": 9.175692,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[17, 0, 2, 88, 86, -63, -25, -16], stop_key=[17, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 9.24738,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_18\": {\n                    \"compactionTime\": 0.090249,\n                    \"hbaseTime\": 8.730833,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[18, 0, 2, 88, 86, -63, -25, -16], stop_key=[18, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.831461,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_19\": {\n                    \"compactionTime\": 0.039327,\n                    \"hbaseTime\": 8.903825,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[19, 0, 2, 88, 86, -63, -25, -16], stop_key=[19, 0, 2, 88, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.947639,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                }\n            },\n            \"serializationTime\": 3.809661,\n            \"successfulScan\": 20,\n            \"uidPairsResolved\": 0,\n            \"uidToStringTime\": 0.197926\n        },\n        \"queryIdx_01\": {\n            \"aggregationTime\": 3.73398,\n            \"avgHBaseTime\": 8.212164,\n            \"avgScannerTime\": 8.268015,\n            \"avgScannerUidToStringTime\": 0.0,\n            \"emittedDPs\": 628,\n            \"groupByTime\": 0.0,\n            \"maxHBaseTime\": 8.986041,\n            \"maxScannerUidtoStringTime\": 0.0,\n            \"queryIndex\": 1,\n            \"queryScanTime\": 9.67778,\n            \"saltScannerMergeTime\": 0.095797,\n            \"scannerStats\": {\n                \"scannerIdx_00\": {\n                    \"compactionTime\": 0.054894,\n                    \"hbaseTime\": 8.708179,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[0, 0, 2, 76, 86, -63, -25, -16], stop_key=[0, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.770252,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_01\": {\n                    \"compactionTime\": 0.055956,\n                    \"hbaseTime\": 8.666615,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[1, 0, 2, 76, 86, -63, -25, -16], stop_key=[1, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.730629,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_02\": {\n                    \"compactionTime\": 0.011224,\n                    \"hbaseTime\": 8.474637,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[2, 0, 2, 76, 86, -63, -25, -16], stop_key=[2, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.487582,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_03\": {\n                    \"compactionTime\": 0.081926,\n                    \"hbaseTime\": 8.894951,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[3, 0, 2, 76, 86, -63, -25, -16], stop_key=[3, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.986041,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_04\": {\n                    \"compactionTime\": 0.01882,\n                    \"hbaseTime\": 8.209866,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[4, 0, 2, 76, 86, -63, -25, -16], stop_key=[4, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.231502,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_05\": {\n                    \"compactionTime\": 0.056902,\n                    \"hbaseTime\": 8.709846,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[5, 0, 2, 76, 86, -63, -25, -16], stop_key=[5, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.772216,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_06\": {\n                    \"compactionTime\": 0.131424,\n                    \"hbaseTime\": 8.033916,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[6, 0, 2, 76, 86, -63, -25, -16], stop_key=[6, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.181117,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_07\": {\n                    \"compactionTime\": 0.022517,\n                    \"hbaseTime\": 8.006976,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[7, 0, 2, 76, 86, -63, -25, -16], stop_key=[7, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.032073,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_08\": {\n                    \"compactionTime\": 0.011527,\n                    \"hbaseTime\": 8.591358,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[8, 0, 2, 76, 86, -63, -25, -16], stop_key=[8, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.604491,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_09\": {\n                    \"compactionTime\": 0.162222,\n                    \"hbaseTime\": 8.25452,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[9, 0, 2, 76, 86, -63, -25, -16], stop_key=[9, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.435525,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_10\": {\n                    \"compactionTime\": 0.033886,\n                    \"hbaseTime\": 7.973254,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[10, 0, 2, 76, 86, -63, -25, -16], stop_key=[10, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.011236,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_11\": {\n                    \"compactionTime\": 0.039491,\n                    \"hbaseTime\": 7.959601,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[11, 0, 2, 76, 86, -63, -25, -16], stop_key=[11, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.003249,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_12\": {\n                    \"compactionTime\": 0.107793,\n                    \"hbaseTime\": 8.177353,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[12, 0, 2, 76, 86, -63, -25, -16], stop_key=[12, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.298284,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_13\": {\n                    \"compactionTime\": 0.020697,\n                    \"hbaseTime\": 8.124243,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[13, 0, 2, 76, 86, -63, -25, -16], stop_key=[13, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.147879,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_14\": {\n                    \"compactionTime\": 0.033261,\n                    \"hbaseTime\": 8.145149,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[14, 0, 2, 76, 86, -63, -25, -16], stop_key=[14, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.182331,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_15\": {\n                    \"compactionTime\": 0.057804,\n                    \"hbaseTime\": 8.17854,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[15, 0, 2, 76, 86, -63, -25, -16], stop_key=[15, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.243458,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_16\": {\n                    \"compactionTime\": 0.01212,\n                    \"hbaseTime\": 8.070582,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[16, 0, 2, 76, 86, -63, -25, -16], stop_key=[16, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 8.084813,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_17\": {\n                    \"compactionTime\": 0.036777,\n                    \"hbaseTime\": 7.919167,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[17, 0, 2, 76, 86, -63, -25, -16], stop_key=[17, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 7.959645,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_18\": {\n                    \"compactionTime\": 0.048097,\n                    \"hbaseTime\": 7.87351,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[18, 0, 2, 76, 86, -63, -25, -16], stop_key=[18, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 7.926318,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                },\n                \"scannerIdx_19\": {\n                    \"compactionTime\": 0.0,\n                    \"hbaseTime\": 7.271033,\n                    \"scannerId\": \"Scanner(table=\\\"tsdb\\\", start_key=[19, 0, 2, 76, 86, -63, -25, -16], stop_key=[19, 0, 2, 76, 86, -62, 4, 16], columns={\\\"t\\\"}, populate_blockcache=true, max_num_rows=128, max_num_kvs=4096, region=null, filter=KeyRegexpFilter(\\\"(?s)^.{8}(?:.{7})*\\\\Q\\u0000\\u0000\\u0005\\\\E(?:\\\\Q\\u0000\\u0000\\u00006\\\\E)(?:.{7})*$\\\", ISO-8859-1), scanner_id=0x0000000000000000)\",\n                    \"scannerTime\": 7.271664,\n                    \"scannerUidToStringTime\": 0.0,\n                    \"successfulScan\": 1,\n                    \"uidPairsResolved\": 0\n                }\n            },\n            \"serializationTime\": 3.749764,\n            \"successfulScan\": 20,\n            \"uidPairsResolved\": 0,\n            \"uidToStringTime\": 0.162088\n        },\n        \"successfulScan\": 40,\n        \"uidPairsResolved\": 0\n    }\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/user_guide/query/stats.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/user_guide/query/stats.html</a>\n  </p>\n</div>\n","api_http/query/exp":"<h1>/api/query/exp</h1> <p>This endpoint allows for querying data using expressions. The query is broken up into different sections.</p> <p>Two set operations (or Joins) are allowed. The union of all time series ore the intersection.</p> <p>For example we can compute \"a + b\" with a group by on the host field. Both metrics queried alone would emit a time series per host, e.g. maybe one for \"web01\", \"web02\" and \"web03\". Lets say metric \"a\" has values for all 3 hosts but metric \"b\" is missing \"web03\".</p> <p>With the intersection operator, the expression will effectively add \"a.web01 + b.web01\" and \"a.web02 + b.web02\" but will skip emitting anything for \"web03\". Be aware of this if you see fewer outputs that you expected or you see errors about no series available after intersection.</p> <p>With the union operator the expression will add the <code class=\"docutils literal\"><span class=\"pre\">web01</span></code> and <code class=\"docutils literal\"><span class=\"pre\">web02</span></code> series but for metric \"b\", it will substitute the metric's fill policy value for the results.</p> <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">Supported as of version 2.3</p> </div>  <h2>Verbs</h2> <ul class=\"simple\"> <li>POST</li> </ul>   <h2>Requests</h2> <p>The various sections implemented include:</p> <div class=\"section\" id=\"time\"> <h3>\"time\"</h3> <p>The time section is required and is a single JSON object. This affects the time range and optional reductions for all metrics requested.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>start</td> <td>Integer</td> <td>Required</td> <td>The start time for the query. This may be relative, absolute human readable or absolute Unix Epoch.</td> <td> </td> <td>1h-ago, 2015/05/05-00:00:00</td> </tr> <tr class=\"row-odd\">\n<td>aggregator</td> <td>String</td> <td>Required</td> <td>The global aggregation function to use for all metrics. It may be overridden on a per metric basis.</td> <td> </td> <td>sum</td> </tr> <tr class=\"row-even\">\n<td>end</td> <td>Integer</td> <td>Optional</td> <td>The end time for the query. If left out, the end is <em>now</em>\n</td> <td>now</td> <td>1h-ago, 2015/05/05-00:00:00</td> </tr> <tr class=\"row-odd\">\n<td>downsampler</td> <td>Object</td> <td>Optional</td> <td>Reduces the number of data points returned. The format is defined below</td> <td>None</td> <td>See below</td> </tr> <tr class=\"row-even\">\n<td>rate</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to calculate all metrics as rates, i.e. value per second. This is computed before expressions.</td> <td>false</td> <td>true</td> </tr> </tbody> </table> <p>E.g.</p> <pre data-language=\"javascript\">\"time\":{ \"start\":\"1h-ago\", \"end\":\"10m-ago\", \"downsampler\":{\"interval\":\"15m\",\"aggregator\":\"max\"}\n</pre>\n <p><strong>Downsampler</strong></p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>interval</td> <td>String</td> <td>Required</td> <td>A downsampling interval, i.e. what time span to rollup raw values into. The format is <code class=\"docutils literal\"><span class=\"pre\">&lt;#&gt;&lt;unit&gt;</span></code>, e.g. <code class=\"docutils literal\"><span class=\"pre\">15m</span></code>\n</td> <td> </td> <td>1h</td> </tr> <tr class=\"row-odd\">\n<td>aggregator</td> <td>String</td> <td>Required</td> <td>The aggregation function to use for reducing the data points</td> <td> </td> <td>avg</td> </tr> <tr class=\"row-even\">\n<td>fillPolicy</td> <td>Object</td> <td>Optional</td> <td>A policy to use for filling buckets that are missing data points</td> <td>None</td> <td>See Below</td> </tr> </tbody> </table> <p><strong>Fill Policies</strong></p> <p>These are used to replace \"missing\" values, i.e. when a data point was expected but couldn't be found in storage.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>policy</td> <td>String</td> <td>Required</td> <td>The name of a policy to use. The values are listed in the table below</td> <td> </td> <td>zero</td> </tr> <tr class=\"row-odd\">\n<td>value</td> <td>Double</td> <td>Optional</td> <td>For scalar fills, an optional value that can be used during substitution</td> <td>NaN</td> <td>42</td> </tr> </tbody> </table> <table class=\"docutils\"> <colgroup> <col width=\"25%\"> <col width=\"75%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>nan</td> <td>Emits a NaN if all values in the aggregation function were NaN or \"missing\". For aggregators, NaNs are treated as \"sentinel\" values that cause the function to skip over the values. Note that if a series emits a NaN in an expression, the NaN is infectious and will cause the output of that expression to be NaN. At serialization the NaN will be emitted.</td> </tr> <tr class=\"row-odd\">\n<td>null</td> <td>Emits a Null at serialization time. During computation the values are treated as NaNs.</td> </tr> <tr class=\"row-even\">\n<td>zero</td> <td>Emits a zero when the value is missing</td> </tr> <tr class=\"row-odd\">\n<td>scalar</td> <td>Emits a user defined value when a data point is missing. Must specify the value with <code class=\"docutils literal\"><span class=\"pre\">value</span></code>. The value can be an integer or floating point.</td> </tr> </tbody> </table> <p>Note that if you try to supply a value that is incompatible with the type the query will throw an exception. E.g. supplying a value with the NaN that isn't NaN will throw an error.</p> <p>E.g.</p> <pre data-language=\"javascript\">{\"policy\":\"scalar\",\"value\":\"1\"}\n</pre>\n </div> <div class=\"section\" id=\"filters\"> <h3>\"filters\"</h3> <p>Filters are for selecting various time series based on the tag keys and values. At least one filter must be specified (for now) with at least an aggregation function supplied. Fields include:</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>id</td> <td>String</td> <td>Required</td> <td>A unique ID for the filter. Cannot be the same as any metric or expression ID</td> <td> </td> <td>f1</td> </tr> <tr class=\"row-odd\">\n<td>tags</td> <td>Array</td> <td>Optional</td> <td>A list of filters on tag values</td> <td>None</td> <td>See below</td> </tr> </tbody> </table> <p>E.g.</p> <pre data-language=\"javascript\">\"filters\":[\n  \"id\":\"f1\",\n  \"tags\":[\n  {\n    \"type\":\"wildcard\",\n    \"tagk\":\"host\",\n    \"filter\":\"*\",\n    \"groupBy\":true\n  },\n  {\n    \"type\":\"literal_or\",\n    \"tagk\":\"colo\",\n    \"filter\":\"lga\",\n    \"groupBy\":false\n  }\n   ]\n  ]\n</pre>\n <p><strong>Filter Fields</strong></p> <p>Within the \"tags\" field you can have one or more filter. The list of filters can be found via the <a class=\"reference internal\" href=\"../config/filters\"><em>/api/config/filters</em></a> endpoint.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>type</td> <td>String</td> <td>Required</td> <td>The name of the filter from the API</td> <td> </td> <td>regexp</td> </tr> <tr class=\"row-odd\">\n<td>tagk</td> <td>String</td> <td>Required</td> <td>The tag key name such as <em>host</em> or <em>colo</em> that we filter on</td> <td> </td> <td>host</td> </tr> <tr class=\"row-even\">\n<td>filter</td> <td>String</td> <td>Required</td> <td>The value to filter on. This depends on the filter in use. See the API for details</td> <td> </td> <td>web.*mysite.com</td> </tr> <tr class=\"row-odd\">\n<td>groupBy</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to group results by the tag values matching this filter. E.g. grouping by host will return one result per host. Not grouping by host would aggregate (using the aggregation function) all results for the metric into one series</td> <td>false</td> <td>true</td> </tr> </tbody> </table> </div> <div class=\"section\" id=\"metrics\"> <h3>\"metrics\"</h3> <p>The metrics list determines which metrics are included in the expression. There must be at least one metric.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>id</td> <td>String</td> <td>Required</td> <td>A unique ID for the metric. This MUST be a simple string, no punctuation or spaces</td> <td> </td> <td>cpunice</td> </tr> <tr class=\"row-odd\">\n<td>filter</td> <td>String</td> <td>Required</td> <td>The filter to use when fetching this metric. It must match a filter in the filters array</td> <td> </td> <td>f1</td> </tr> <tr class=\"row-even\">\n<td>metric</td> <td>String</td> <td>Required</td> <td>The name of a metric in OpenTSDB</td> <td> </td> <td>system.cpu.nice</td> </tr> <tr class=\"row-odd\">\n<td>aggregator</td> <td>String</td> <td>Optional</td> <td>An optional aggregation function to overload the global function in <code class=\"docutils literal\"><span class=\"pre\">time</span></code> for just this metric</td> <td>\n<code class=\"docutils literal\"><span class=\"pre\">time</span></code>'s aggregator</td> <td>count</td> </tr> <tr class=\"row-even\">\n<td>fillPolicy</td> <td>Object</td> <td>Optional</td> <td>If downsampling is not used, this can be included to determine what to emit in calculations. It will also override the downsampling policy</td> <td>zero fill</td> <td>See above</td> </tr> </tbody> </table> <p>E.g.</p> <pre data-language=\"javascript\">{\"id\":\"cpunice\", \"filter\":\"f1\", \"metric\":\"system.cpu.nice\"}\n</pre>\n </div> <div class=\"section\" id=\"expressions\"> <h3>\"expressions\"</h3> <p>A list of one or more expressions over the metrics. The variables in an expression <strong>MUST</strong> refer to either a metric ID field or an expression ID field. Nested expressions are supported but exceptions will be thrown if a self reference or circular dependency is detected. So far only basic operations are supported such as addition, subtraction, multiplication, division, modulo</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>id</td> <td>String</td> <td>Required</td> <td>A unique ID for the expression</td> <td> </td> <td>cpubusy</td> </tr> <tr class=\"row-odd\">\n<td>expr</td> <td>String</td> <td>Required</td> <td>The expression to execute</td> <td> </td> <td>a + b / 1024</td> </tr> <tr class=\"row-even\">\n<td>join</td> <td>Object</td> <td>Optional</td> <td>The set operation or \"join\" to perform for series across sets.</td> <td>union</td> <td>See below</td> </tr> <tr class=\"row-odd\">\n<td>fillPolicy</td> <td>Object</td> <td>Optional</td> <td>An optional fill policy for the expression when it is used in a nested expression and doesn't have a value</td> <td>NaN</td> <td>See above</td> </tr> </tbody> </table> <p>E.g.</p> <pre data-language=\"javascript\">{\n  \"id\": \"cpubusy\",\n  \"expr\": \"(((a + b + c + d + e + f + g) - g) / (a + b + c + d + e + f + g)) * 100\",\n  \"join\": {\n    \"operator\": \"intersection\",\n    \"useQueryTags\": true,\n    \"includeAggTags\": false\n  }\n}\n</pre>\n <p><strong>Joins</strong></p> <p>The join object controls how the various time series for a given metric are merged within an expression. The two basic operations supported at this time are the union and intersection operators. Additional flags control join behavior.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>operator</td> <td>String</td> <td>Required</td> <td>The operator to use, either union or intersection</td> <td> </td> <td>intersection</td> </tr> <tr class=\"row-odd\">\n<td>useQueryTags</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to use just the tags explicitly defined in the filters when computing the join keys</td> <td>false</td> <td>true</td> </tr> <tr class=\"row-even\">\n<td>includeAggTags</td> <td>Boolean</td> <td>Optional</td> <td>Whether or not to include the tag keys that were aggregated out of a series in the join key</td> <td>true</td> <td>false</td> </tr> </tbody> </table> </div> <div class=\"section\" id=\"outputs\"> <h3>\"outputs\"</h3> <p>These determine the output behavior and allow you to eliminate some expressions from the results or include the raw metrics. By default, if this section is missing, all expressions and only the expressions will be serialized. The field is a list of one or more output objects. More fields will be added later with flags to affect the output.</p> <table class=\"docutils\"> <colgroup> <col width=\"10%\"> <col width=\"5%\"> <col width=\"5%\"> <col width=\"45%\"> <col width=\"10%\"> <col width=\"25%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Data Type</th> <th class=\"head\">Required</th> <th class=\"head\">Description</th> <th class=\"head\">Default</th> <th class=\"head\">Example</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>id</td> <td>String</td> <td>Required</td> <td>The ID of the metric or expression</td> <td> </td> <td>e</td> </tr> <tr class=\"row-odd\">\n<td>alias</td> <td>String</td> <td>Optional</td> <td>An optional descriptive name for series</td> <td> </td> <td>System Busy</td> </tr> </tbody> </table> <p>E.g.</p> <pre data-language=\"javascript\">{\"id\":\"e\", \"alias\":\"System Busy\"}\n</pre>\n <div class=\"admonition note\"> <p class=\"first admonition-title\">Note</p> <p class=\"last\">The <code class=\"docutils literal\"><span class=\"pre\">id</span></code> field for all objects can not contain spaces, special characters or periods at this time.</p> </div> <p><strong>Complete Example</strong></p> <pre data-language=\"javascript\">{\n   \"time\": {\n     \"start\": \"1y-ago\",\n     \"aggregator\":\"sum\"\n   },\n   \"filters\": [\n     {\n       \"tags\": [\n         {\n           \"type\": \"wildcard\",\n           \"tagk\": \"host\",\n           \"filter\": \"web*\",\n           \"groupBy\": true\n         }\n       ],\n       \"id\": \"f1\"\n     }\n   ],\n   \"metrics\": [\n     {\n       \"id\": \"a\",\n       \"metric\": \"sys.cpu.user\",\n       \"filter\": \"f1\",\n       \"fillPolicy\":{\"policy\":\"nan\"}\n     },\n     {\n       \"id\": \"b\",\n       \"metric\": \"sys.cpu.iowait\",\n       \"filter\": \"f1\",\n       \"fillPolicy\":{\"policy\":\"nan\"}\n     }\n   ],\n   \"expressions\": [\n     {\n       \"id\": \"e\",\n       \"expr\": \"a + b\"\n     },\n     {\n     \"id\":\"e2\",\n     \"expr\": \"e * 2\"\n     },\n     {\n     \"id\":\"e3\",\n     \"expr\": \"e2 * 2\"\n     },\n     {\n     \"id\":\"e4\",\n     \"expr\": \"e3 * 2\"\n     },\n     {\n     \"id\":\"e5\",\n     \"expr\": \"e4 + e2\"\n     }\n  ],\n  \"outputs\":[\n    {\"id\":\"e5\", \"alias\":\"Mega expression\"},\n    {\"id\":\"a\", \"alias\":\"CPU User\"}\n  ]\n }\n</pre>\n </div>   <h2>Response</h2> <p>The output will contain a list of objects in the <code class=\"docutils literal\"><span class=\"pre\">outputs</span></code> array with the results in an array of arrays representing each time series followed by meta data for each series and the query overall. Also included is the original query and some summary statistics. The fields include:</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"80%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>id</td> <td>The expression ID the output matches</td> </tr> <tr class=\"row-odd\">\n<td>dps</td> <td>The array of results. Each sub array starts with the timestamp in ms as the first (offset 0) value. The remaining values are the results for each series when a group by was applied.</td> </tr> <tr class=\"row-even\">\n<td>dpsMeta</td> <td>Meta data around the query including the first and last timestamps, number of result \"sets\", or sub arrays, and the number of series represented.</td> </tr> <tr class=\"row-odd\">\n<td>datapoints</td> <td>The total number of data points returned to the user after aggregation</td> </tr> <tr class=\"row-even\">\n<td>meta</td> <td>Data about each time series in the result set. The fields are below</td> </tr> </tbody> </table> <p>The meta section contains ordered information about each time series in the output arrays. The first element in the array will always have a <code class=\"docutils literal\"><span class=\"pre\">metrics</span></code> value of <code class=\"docutils literal\"><span class=\"pre\">timestamp</span></code> and no other data.</p> <table class=\"docutils\"> <colgroup> <col width=\"20%\"> <col width=\"80%\"> </colgroup> <thead valign=\"bottom\"> <tr class=\"row-odd\">\n<th class=\"head\">Name</th> <th class=\"head\">Description</th> </tr> </thead> <tbody valign=\"top\"> <tr class=\"row-even\">\n<td>index</td> <td>The index in the data point arrays that the meta refers to</td> </tr> <tr class=\"row-odd\">\n<td>metrics</td> <td>The different metric names included in the expression</td> </tr> <tr class=\"row-even\">\n<td>commonTags</td> <td>Tag keys and values that were common across all time series that were aggregated in the resulting series</td> </tr> <tr class=\"row-odd\">\n<td>aggregatedTags</td> <td>Tag keys that appeared in all series in the resulting series but had different values</td> </tr> <tr class=\"row-even\">\n<td>dps</td> <td>The number of data points emitted</td> </tr> <tr class=\"row-odd\">\n<td>rawDps</td> <td>The number of raw values wrapped into the result</td> </tr> </tbody> </table> <div class=\"section\" id=\"example-responses\"> <h3>Example Responses</h3> <pre data-language=\"javascript\">{\n  \"outputs\": [\n    {\n      \"id\": \"Mega expression\",\n      \"dps\": [\n        [\n          1431561600000,\n          1010,\n          1030\n        ],\n        [\n          1431561660000,\n          \"NaN\",\n          \"NaN\"\n        ],\n        [\n          1431561720000,\n          \"NaN\",\n          \"NaN\"\n        ],\n        [\n          1431561780000,\n          1120,\n          1140\n        ]\n      ],\n      \"dpsMeta\": {\n        \"firstTimestamp\": 1431561600000,\n        \"lastTimestamp\": 1431561780000,\n        \"setCount\": 4,\n        \"series\": 2\n      },\n      \"meta\": [\n        {\n          \"index\": 0,\n          \"metrics\": [\n            \"timestamp\"\n          ]\n        },\n        {\n          \"index\": 1,\n          \"metrics\": [\n            \"sys.cpu\",\n            \"sys.iowait\"\n          ],\n          \"commonTags\": {\n            \"host\": \"web01\"\n          },\n          \"aggregatedTags\": []\n        },\n        {\n          \"index\": 2,\n          \"metrics\": [\n            \"sys.cpu\",\n            \"sys.iowait\"\n          ],\n          \"commonTags\": {\n            \"host\": \"web02\"\n          },\n          \"aggregatedTags\": []\n        }\n      ]\n    },\n    {\n      \"id\": \"sys.cpu\",\n      \"dps\": [\n        [\n          1431561600000,\n          1,\n          2\n        ],\n        [\n          1431561660000,\n          3,\n          0\n        ],\n        [\n          1431561720000,\n          5,\n          0\n        ],\n        [\n          1431561780000,\n          7,\n          8\n        ]\n      ],\n      \"dpsMeta\": {\n        \"firstTimestamp\": 1431561600000,\n        \"lastTimestamp\": 1431561780000,\n        \"setCount\": 4,\n        \"series\": 2\n      },\n      \"meta\": [\n        {\n          \"index\": 0,\n          \"metrics\": [\n            \"timestamp\"\n          ]\n        },\n        {\n          \"index\": 1,\n          \"metrics\": [\n            \"sys.cpu\"\n          ],\n          \"commonTags\": {\n            \"host\": \"web01\"\n          },\n          \"aggregatedTags\": []\n        },\n        {\n          \"index\": 2,\n          \"metrics\": [\n            \"sys.cpu\"\n          ],\n          \"commonTags\": {\n            \"host\": \"web02\"\n          },\n          \"aggregatedTags\": []\n        }\n      ]\n    }\n  ],\n  \"statsSummary\": {\n    \"datapoints\": 0,\n    \"rawDatapoints\": 0,\n    \"aggregationTime\": 0,\n    \"serializationTime\": 33,\n    \"storageTime\": 77,\n    \"timeTotal\": 148.63\n  },\n  \"query\": {\n    \"name\": null,\n    \"time\": {\n      \"start\": \"1y-ago\",\n      \"end\": null,\n      \"timezone\": null,\n      \"downsampler\": null,\n      \"aggregator\": \"sum\"\n    },\n    \"filters\": [\n      {\n        \"id\": \"f1\",\n        \"tags\": [\n          {\n            \"tagk\": \"host\",\n            \"filter\": \"web*\",\n            \"group_by\": true,\n            \"type\": \"wildcard\"\n          }\n        ]\n      }\n    ],\n    \"metrics\": [\n      {\n        \"metric\": \"sys.cpu\",\n        \"id\": \"a\",\n        \"filter\": \"f1\",\n        \"aggregator\": null,\n        \"fillPolicy\": {\n          \"policy\": \"nan\",\n          \"value\": \"NaN\"\n        },\n        \"timeOffset\": null\n      },\n      {\n        \"metric\": \"sys.iowait\",\n        \"id\": \"b\",\n        \"filter\": \"f1\",\n        \"aggregator\": null,\n        \"fillPolicy\": {\n          \"policy\": \"nan\",\n          \"value\": \"NaN\"\n        },\n        \"timeOffset\": null\n      }\n    ],\n    \"expressions\": [\n      {\n        \"id\": \"e\",\n        \"expr\": \"a + b\"\n      },\n      {\n        \"id\": \"e2\",\n        \"expr\": \"e * 2\"\n      },\n      {\n        \"id\": \"e3\",\n        \"expr\": \"e2 * 2\"\n      },\n      {\n        \"id\": \"e4\",\n        \"expr\": \"e3 * 2\"\n      },\n      {\n        \"id\": \"e5\",\n        \"expr\": \"e4 + e2\"\n      }\n    ],\n    \"outputs\": [\n      {\n        \"id\": \"e5\",\n        \"alias\": \"Woot!\"\n      },\n      {\n        \"id\": \"a\",\n        \"alias\": \"Woot!2\"\n      }\n    ]\n   }\n}\n</pre>\n </div><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2010&ndash;2016 The OpenTSDB Authors<br>Licensed under the GNU LGPLv2.1+ and GPLv3+ licenses.<br>\n    <a href=\"http://opentsdb.net/docs/build/html/api_http/query/exp.html\" class=\"_attribution-link\">http://opentsdb.net/docs/build/html/api_http/query/exp.html</a>\n  </p>\n</div>\n"}