{"index":"<h1 id=\"tensorflow-c-session-api-reference-documentation\">TensorFlow C++ Session API reference documentation</h1> <p>TensorFlow's public C++ API includes only the API for executing graphs, as of version 0.5. To control the execution of a graph from C++:</p> <ol> <li>Build the computation graph using the <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/python/\">Python API</a>.</li> <li>Use <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#write_graph\"><code>tf.train.write_graph()</code></a> to write the graph to a file.</li> <li>\n<p>Load the graph using the C++ Session API. For example:</p> <pre class=\"lang-c++ no-auto-prettify\" data-language=\"cpp\">// Reads a model graph definition from disk, and creates a session object you\n// can use to run it.\nStatus LoadGraph(string graph_file_name, Session** session) {\n  GraphDef graph_def;\n  TF_RETURN_IF_ERROR(\n      ReadBinaryProto(Env::Default(), graph_file_name, &amp;graph_def));\n  TF_RETURN_IF_ERROR(NewSession(SessionOptions(), session));\n  TF_RETURN_IF_ERROR((*session)-&gt;Create(graph_def));\n  return Status::OK();\n}\n</pre>\n</li> <li><p>Run the graph with a call to <code>session-&gt;Run()</code></p></li> </ol> <h2 id=\"env\">Env</h2> <ul> <li><a href=\"classenv\">tensorflow::Env</a></li> <li><a href=\"classrandomaccessfile\">tensorflow::RandomAccessFile</a></li> <li><a href=\"classwritablefile\">tensorflow::WritableFile</a></li> <li><a href=\"classenvwrapper\">tensorflow::EnvWrapper</a></li> </ul> <h2 id=\"session\">Session</h2> <ul> <li><a href=\"classsession\">tensorflow::Session</a></li> <li><a href=\"structsessionoptions\">tensorflow::SessionOptions</a></li> </ul> <h2 id=\"status\">Status</h2> <ul> <li><a href=\"classstatus\">tensorflow::Status</a></li> <li><a href=\"structstate\">tensorflow::Status::State</a></li> </ul> <h2 id=\"tensor\">Tensor</h2> <ul> <li><a href=\"classtensor\">tensorflow::Tensor</a></li> <li><a href=\"classtensorshape\">tensorflow::TensorShape</a></li> <li><a href=\"structtensorshapedim\">tensorflow::TensorShapeDim</a></li> <li><a href=\"classtensorshapeutils\">tensorflow::TensorShapeUtils</a></li> <li><a href=\"classpartialtensorshape\">tensorflow::PartialTensorShape</a></li> <li><a href=\"classpartialtensorshapeutils\">tensorflow::PartialTensorShapeUtils</a></li> <li><a href=\"structtf_buffer\">TF_Buffer</a></li> </ul> <h2 id=\"thread\">Thread</h2> <ul> <li><a href=\"classthread\">tensorflow::Thread</a></li> <li><a href=\"structthreadoptions\">tensorflow::ThreadOptions</a></li> </ul><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/</a>\n  </p>\n</div>\n","classenv":"<h1 id=\"class-tensorflowenv\"><code>class tensorflow::Env</code></h1> <p>An interface used by the tensorflow implementation to access operating system functionality like the filesystem etc.</p> <p>Callers may wish to provide a custom Env object to get fine grain control.</p> <p>All Env implementations are safe for concurrent access from multiple threads without any external synchronization.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_Env_Env\"><code>tensorflow::Env::Env()</code></h4> <h4 id=\"virtual_tensorflow_Env_Env\"><code>virtual tensorflow::Env::~Env()=default</code></h4> <h4 id=\"Status_tensorflow_Env_GetFileSystemForFile\"><code>Status tensorflow::Env::GetFileSystemForFile(const string &amp;fname, FileSystem **result)</code></h4> <p>Returns the FileSystem object to handle operations on the file specified by 'fname'. The FileSystem object is used as the implementation for the file system related (non-virtual) functions that follow. Returned FileSystem object is still owned by the Env object and will.</p> <h4 id=\"Status_tensorflow_Env_GetRegisteredFileSystemSchemes\"><code>Status tensorflow::Env::GetRegisteredFileSystemSchemes(std::vector&lt; string &gt; *schemes)</code></h4> <p>Returns the file system schemes registered for this Env .</p> <h4 id=\"Status_tensorflow_Env_RegisterFileSystem\"><code>Status tensorflow::Env::RegisterFileSystem(const string &amp;scheme, FileSystemRegistry::Factory factory)</code></h4> <h4 id=\"Status_tensorflow_Env_NewRandomAccessFile\"><code>Status tensorflow::Env::NewRandomAccessFile(const string &amp;fname, std::unique_ptr&lt; RandomAccessFile &gt; *result)</code></h4> <p>Creates a brand new random access read-only file with the specified name.</p> <p>On success, stores a pointer to the new file in *result and returns OK. On failure stores NULL in *result and returns non-OK. If the file does not exist, returns a non-OK status.</p> <p>The returned file may be concurrently accessed by multiple threads.</p> <p>The ownership of the returned RandomAccessFile is passed to the caller and the object should be deleted when is not used. The file object shouldn't live longer than the Env object.</p> <h4 id=\"Status_tensorflow_Env_NewWritableFile\"><code>Status tensorflow::Env::NewWritableFile(const string &amp;fname, std::unique_ptr&lt; WritableFile &gt; *result)</code></h4> <p>Creates an object that writes to a new file with the specified name.</p> <p>Deletes any existing file with the same name and creates a new file. On success, stores a pointer to the new file in *result and returns OK. On failure stores NULL in *result and returns non-OK.</p> <p>The returned file will only be accessed by one thread at a time.</p> <p>The ownership of the returned WritableFile is passed to the caller and the object should be deleted when is not used. The file object shouldn't live longer than the Env object.</p> <h4 id=\"Status_tensorflow_Env_NewAppendableFile\"><code>Status tensorflow::Env::NewAppendableFile(const string &amp;fname, std::unique_ptr&lt; WritableFile &gt; *result)</code></h4> <p>Creates an object that either appends to an existing file, or writes to a new file (if the file does not exist to begin with).</p> <p>On success, stores a pointer to the new file in *result and returns OK. On failure stores NULL in *result and returns non-OK.</p> <p>The returned file will only be accessed by one thread at a time.</p> <p>The ownership of the returned WritableFile is passed to the caller and the object should be deleted when is not used. The file object shouldn't live longer than the Env object.</p> <h4 id=\"Status_tensorflow_Env_NewReadOnlyMemoryRegionFromFile\"><code>Status tensorflow::Env::NewReadOnlyMemoryRegionFromFile(const string &amp;fname, std::unique_ptr&lt; ReadOnlyMemoryRegion &gt; *result)</code></h4> <p>Creates a readonly region of memory with the file context.</p> <p>On success, it returns a pointer to read-only memory region from the content of file fname. The ownership of the region is passed to the caller. On failure stores nullptr in *result and returns non-OK.</p> <p>The returned memory region can be accessed from many threads in parallel.</p> <p>The ownership of the returned ReadOnlyMemoryRegion is passed to the caller and the object should be deleted when is not used. The memory region object shouldn't live longer than the Env object.</p> <h4 id=\"bool_tensorflow_Env_FileExists\"><code>bool tensorflow::Env::FileExists(const string &amp;fname)</code></h4> <p>Returns true iff the named file exists.</p> <h4 id=\"Status_tensorflow_Env_GetChildren\"><code>Status tensorflow::Env::GetChildren(const string &amp;dir, std::vector&lt; string &gt; *result)</code></h4> <p>Stores in *result the names of the children of the specified directory. The names are relative to \"dir\".</p> <p>Original contents of *results are dropped.</p> <h4 id=\"Status_tensorflow_Env_DeleteFile\"><code>Status tensorflow::Env::DeleteFile(const string &amp;fname)</code></h4> <p>Deletes the named file.</p> <h4 id=\"Status_tensorflow_Env_DeleteRecursively\"><code>Status tensorflow::Env::DeleteRecursively(const string &amp;dirname, int64 *undeleted_files, int64 *undeleted_dirs)</code></h4> <p>Deletes the specified directory and all subdirectories and files underneath it. undeleted_files and undeleted_dirs stores the number of files and directories that weren't deleted (unspecified if the return status is not OK). REQUIRES: undeleted_files, undeleted_dirs to be not null. Typical return codes.</p> <p>OK - dirname exists and we were able to delete everything underneath.</p> <p>NOT_FOUND - dirname doesn't exist</p> <p>PERMISSION_DENIED - dirname or some descendant is not writable</p> <p>UNIMPLEMENTED - Some underlying functions (like Delete) are not implemented</p> <h4 id=\"Status_tensorflow_Env_CreateDir\"><code>Status tensorflow::Env::CreateDir(const string &amp;dirname)</code></h4> <p>Creates the specified directory.</p> <h4 id=\"Status_tensorflow_Env_DeleteDir\"><code>Status tensorflow::Env::DeleteDir(const string &amp;dirname)</code></h4> <p>Deletes the specified directory.</p> <h4 id=\"Status_tensorflow_Env_Stat\"><code>Status tensorflow::Env::Stat(const string &amp;fname, FileStatistics *stat)</code></h4> <p>Obtains statistics for the given path.</p> <h4 id=\"Status_tensorflow_Env_IsDirectory\"><code>Status tensorflow::Env::IsDirectory(const string &amp;fname)</code></h4> <p>Returns whether the given path is a directory or not. Typical return codes (not guaranteed exhaustive):</p> <p>OK - The path exists and is a directory.</p> <p>FAILED_PRECONDITION - The path exists and is not a directory.</p> <p>NOT_FOUND - The path entry does not exist.</p> <p>PERMISSION_DENIED - Insufficient permissions.</p> <p>UNIMPLEMENTED - The file factory doesn't support directories.</p> <h4 id=\"Status_tensorflow_Env_GetFileSize\"><code>Status tensorflow::Env::GetFileSize(const string &amp;fname, uint64 *file_size)</code></h4> <p>Stores the size of <code>fname</code> in <code>*file_size</code>.</p> <h4 id=\"Status_tensorflow_Env_RenameFile\"><code>Status tensorflow::Env::RenameFile(const string &amp;src, const string &amp;target)</code></h4> <p>Renames file src to target. If target already exists, it will be replaced.</p> <h4 id=\"virtual_uint64_tensorflow_Env_NowMicros\"><code>virtual uint64 tensorflow::Env::NowMicros()=0</code></h4> <p>Returns the number of micro-seconds since some fixed point in time. Only useful for computing deltas of time.</p> <h4 id=\"virtual_uint64_tensorflow_Env_NowSeconds\"><code>virtual uint64 tensorflow::Env::NowSeconds()</code></h4> <p>Returns the number of seconds since some fixed point in time. Only useful for computing deltas of time.</p> <h4 id=\"virtual_void_tensorflow_Env_SleepForMicroseconds\"><code>virtual void tensorflow::Env::SleepForMicroseconds(int64 micros)=0</code></h4> <p>Sleeps/delays the thread for the prescribed number of micro-seconds.</p> <h4 id=\"virtual_Thread_tensorflow_Env_StartThread\"><code>virtual Thread* tensorflow::Env::StartThread(const ThreadOptions &amp;thread_options, const string &amp;name, std::function&lt; void()&gt; fn) TF_MUST_USE_RESULT=0</code></h4> <p>Returns a new thread that is running fn() and is identified (for debugging/performance-analysis) by \"name\".</p> <p>Caller takes ownership of the result and must delete it eventually (the deletion will block until fn() stops running).</p> <h4 id=\"virtual_void_tensorflow_Env_SchedClosure\"><code>virtual void tensorflow::Env::SchedClosure(std::function&lt; void()&gt; closure)=0</code></h4> <h4 id=\"virtual_void_tensorflow_Env_SchedClosureAfter\"><code>virtual void tensorflow::Env::SchedClosureAfter(int64 micros, std::function&lt; void()&gt; closure)=0</code></h4> <h4 id=\"virtual_Status_tensorflow_Env_LoadLibrary\"><code>virtual Status tensorflow::Env::LoadLibrary(const char *library_filename, void **handle)=0</code></h4> <h4 id=\"virtual_Status_tensorflow_Env_GetSymbolFromLibrary\"><code>virtual Status tensorflow::Env::GetSymbolFromLibrary(void *handle, const char *symbol_name, void **symbol)=0</code></h4> <h4 id=\"static_Env_tensorflow_Env_Default\"><code>static Env* tensorflow::Env::Default()</code></h4> <p>Returns a default environment suitable for the current operating system.</p> <p>Sophisticated users may wish to provide their own Env implementation instead of relying on this default environment.</p> <p>The result of Default() belongs to this library and must never be deleted.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassEnv.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassEnv.html</a>\n  </p>\n</div>\n","structsessionoptions":"<h1 id=\"struct-tensorflowsessionoptions\"><code>struct tensorflow::SessionOptions</code></h1> <p>Configuration information for a Session .</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"Env_tensorflow_SessionOptions_env\"><code>Env* tensorflow::SessionOptions::env</code></h4> <p>The environment to use.</p> <h4 id=\"string_tensorflow_SessionOptions_target\"><code>string tensorflow::SessionOptions::target</code></h4> <p>The TensorFlow runtime to connect to.</p> <p>If 'target' is empty or unspecified, the local TensorFlow runtime implementation will be used. Otherwise, the TensorFlow engine defined by 'target' will be used to perform all computations.</p> <p>\"target\" can be either a single entry or a comma separated list of entries. Each entry is a resolvable address of the following format: local ip:port host:port ... other system-specific formats to identify tasks and jobs ...</p> <p>NOTE: at the moment 'local' maps to an in-process service-based runtime.</p> <p>Upon creation, a single session affines itself to one of the remote processes, with possible load balancing choices when the \"target\" resolves to a list of possible processes.</p> <p>If the session disconnects from the remote process during its lifetime, session calls may fail immediately.</p> <h4 id=\"ConfigProto_tensorflow_SessionOptions_config\"><code>ConfigProto tensorflow::SessionOptions::config</code></h4> <p>Configuration options.</p> <h4 id=\"tensorflow_SessionOptions_SessionOptions\"><code>tensorflow::SessionOptions::SessionOptions()</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructSessionOptions.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructSessionOptions.html</a>\n  </p>\n</div>\n","classsession":"<h1 id=\"class-tensorflowsession\"><code>class tensorflow::Session</code></h1> <p>A Session instance lets a caller drive a TensorFlow graph computation.</p> <p>When a Session is created with a given target, a new Session object is bound to the universe of resources specified by that target. Those resources are available to this session to perform computation described in the GraphDef. After extending the session with a graph, the caller uses the Run() API to perform the computation and potentially fetch outputs as Tensors.</p> <p>Example:</p> <pre class=\"lang-c++ no-auto-prettify\" data-language=\"cpp\">// ... Create or load graph into \"graph\".\n\n// This example uses the default options which connects\n// to a local runtime.\ntensorflow::SessionOptions options;\nstd::unique_ptr&lt;tensorflow::Session&gt;\nsession(tensorflow::NewSession(options));\n\n// Create the session with this graph.\ntensorflow::Status s = session-&gt;Create(graph);\nif (!s.ok()) { ... }\n\n// Run the graph and fetch the first output of the \"output\"\n// operation, and also run to but do not return anything\n// for the \"update_state\" operation.\nstd::vector&lt;tensorflow::Tensor&gt; outputs;\ns = session-&gt;Run({}, {\"output:0\"}, {\"update_state\"}, &amp;outputs);\nif (!s.ok()) { ... }\n\n// Map the output as a flattened float tensor, and do something\n// with it.\nauto output_tensor = outputs[0].flat&lt;float&gt;();\nif (output_tensor(0) &gt; 0.5) { ... }\n\n// Close the session to release the resources associated with\n// this session.\nsession-&gt;Close();\n\n</pre> <p>A Session allows concurrent calls to Run() , though a Session must be created / extended by a single thread.</p> <p>Only one thread must call Close() , and Close() must only be called after all other calls to Run() have returned.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_Session_Session\"><code>tensorflow::Session::Session()</code></h4> <h4 id=\"virtual_tensorflow_Session_Session\"><code>virtual tensorflow::Session::~Session()</code></h4> <h4 id=\"virtual_Status_tensorflow_Session_Create\"><code>virtual Status tensorflow::Session::Create(const GraphDef &amp;graph)=0</code></h4> <p>Create the graph to be used for the session.</p> <p>Returns an error if this session has already been created with a graph. To re-use the session with a different graph, the caller must Close() the session first.</p> <h4 id=\"virtual_Status_tensorflow_Session_Extend\"><code>virtual Status tensorflow::Session::Extend(const GraphDef &amp;graph)=0</code></h4> <p>Adds operations to the graph that is already registered with the Session .</p> <p>The names of new operations in \"graph\" must not exist in the graph that is already registered.</p> <h4 id=\"virtual_Status_tensorflow_Session_Run\"><code>virtual Status tensorflow::Session::Run(const std::vector&lt; std::pair&lt; string, Tensor &gt; &gt; &amp;inputs, const std::vector&lt; string &gt; &amp;output_tensor_names, const std::vector&lt; string &gt; &amp;target_node_names, std::vector&lt; Tensor &gt; *outputs)=0</code></h4> <p>Runs the graph with the provided input tensors and fills <code>outputs</code> for the endpoints specified in <code>output_tensor_names</code>. Runs to but does not return Tensors for the nodes in <code>target_node_names</code>.</p> <p>The order of tensors in <code>outputs</code> will match the order provided by <code>output_tensor_names</code>.</p> <p>If <code>Run</code> returns <code>OK()</code>, then <code>outputs-&gt;size()</code> will be equal to <code>output_tensor_names.size()</code>. If <code>Run</code> does not return <code>OK()</code>, the state of <code>outputs</code> is undefined.</p> <p>REQUIRES: The name of each Tensor of the input or output must match a \"Tensor endpoint\" in the <code>GraphDef</code> passed to <code>Create()</code>.</p> <p>REQUIRES: At least one of <code>output_tensor_names</code> and <code>target_node_names</code> must be non-empty.</p> <p>REQUIRES: outputs is not nullptr if <code>output_tensor_names</code> is non-empty.</p> <h4 id=\"virtual_Status_tensorflow_Session_Create\"><code>virtual Status tensorflow::Session::Create(const RunOptions &amp;run_options, const GraphDef &amp;graph)</code></h4> <p>Implementations which support <code>RunOptions</code>.</p> <p>NOTE: This API is still experimental and may change.</p> <h4 id=\"virtual_Status_tensorflow_Session_Extend\"><code>virtual Status tensorflow::Session::Extend(const RunOptions &amp;run_options, const GraphDef &amp;graph)</code></h4> <h4 id=\"virtual_Status_tensorflow_Session_Close\"><code>virtual Status tensorflow::Session::Close(const RunOptions &amp;run_options)</code></h4> <h4 id=\"virtual_Status_tensorflow_Session_Run\"><code>virtual Status tensorflow::Session::Run(const RunOptions &amp;run_options, const std::vector&lt; std::pair&lt; string, Tensor &gt; &gt; &amp;inputs, const std::vector&lt; string &gt; &amp;output_tensor_names, const std::vector&lt; string &gt; &amp;target_node_names, std::vector&lt; Tensor &gt; *outputs, RunMetadata *run_metadata)</code></h4> <p>Like <code>Run</code>, but allows users to pass in a <code>RunOptions</code> proto and to retrieve non-Tensor metadata output via a <code>RunMetadata</code> proto for this step. <code>run_metadata</code> may be nullptr, in which case any metadata output is discarded. NOTE: This API is still experimental and may change.</p> <h4 id=\"virtual_Status_tensorflow_Session_PRunSetup\"><code>virtual Status tensorflow::Session::PRunSetup(const std::vector&lt; string &gt; &amp;input_names, const std::vector&lt; string &gt; &amp;output_names, const std::vector&lt; string &gt; &amp;target_nodes, string *handle)</code></h4> <p>Sets up a graph for partial execution. All future feeds and fetches are specified by <code>input_names</code> and <code>output_names</code>. Returns <code>handle</code> that can be used to perform a sequence of partial feeds and fetches. NOTE: This API is still experimental and may change.</p> <h4 id=\"virtual_Status_tensorflow_Session_PRun\"><code>virtual Status tensorflow::Session::PRun(const string &amp;handle, const std::vector&lt; std::pair&lt; string, Tensor &gt; &gt; &amp;inputs, const std::vector&lt; string &gt; &amp;output_names, std::vector&lt; Tensor &gt; *outputs)</code></h4> <p>Continues the pending execution specified by <code>handle</code> with the provided input tensors and fills <code>outputs</code> for the endpoints specified in <code>output_names</code>. NOTE: This API is still experimental and may change.</p> <h4 id=\"virtual_Status_tensorflow_Session_Close\"><code>virtual Status tensorflow::Session::Close()=0</code></h4> <p>Closes this session.</p> <p>Closing a session releases the resources used by this session on the TensorFlow runtime (specified during session creation by the <code>SessionOptions::target</code> field).</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassSession.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassSession.html</a>\n  </p>\n</div>\n","classpartialtensorshapeutils":"<h1 id=\"class-tensorflowpartialtensorshapeutils\"><code>class tensorflow::PartialTensorShapeUtils</code></h1> <p>Static helper routines for <code>PartialTensorShape</code>. Includes a few common predicates on a partially known tensor shape.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"string_tensorflow_PartialTensorShapeUtils_PartialShapeListString\"><code>string tensorflow::PartialTensorShapeUtils::PartialShapeListString(const gtl::ArraySlice&lt; PartialTensorShape &gt; &amp;shapes)</code></h4> <h4 id=\"bool_tensorflow_PartialTensorShapeUtils_AreCompatible\"><code>bool tensorflow::PartialTensorShapeUtils::AreCompatible(const gtl::ArraySlice&lt; PartialTensorShape &gt; &amp;shapes0, const gtl::ArraySlice&lt; PartialTensorShape &gt; &amp;shapes1)</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassPartialTensorShapeUtils.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassPartialTensorShapeUtils.html</a>\n  </p>\n</div>\n","classtensor":"<h1 id=\"class-tensorflowtensor\"><code>class tensorflow::Tensor</code></h1> <p>Represents an n-dimensional array of values.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::Tensor()</code></h4> <p>Creates a 1-dimensional, 0-element float tensor.</p> <p>The returned Tensor is not a scalar (shape {}), but is instead an empty one-dimensional Tensor (shape {0}, NumElements() == 0). Since it has no elements, it does not need to be assigned a value and is initialized by default ( IsInitialized() is true). If this is undesirable, consider creating a one-element scalar which does require initialization:</p>  <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::Tensor(DataType type, const TensorShape &amp;shape)</code></h4> <p>Creates a Tensor of the given <code>type</code> and <code>shape</code>. If LogMemory::IsEnabled() the allocation is logged as coming from an unknown kernel and step. Calling the Tensor constructor directly from within an Op is deprecated: use the OpKernelConstruction/OpKernelContext allocate_* methods to allocate a new tensor, which record the kernel and step.</p> <p>The underlying buffer is allocated using a <code>CPUAllocator</code>.</p> <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::Tensor(Allocator *a, DataType type, const TensorShape &amp;shape)</code></h4> <p>Creates a tensor with the input <code>type</code> and <code>shape</code>, using the allocator <code>a</code> to allocate the underlying buffer. If LogMemory::IsEnabled() the allocation is logged as coming from an unknown kernel and step. Calling the Tensor constructor directly from within an Op is deprecated: use the OpKernelConstruction/OpKernelContext allocate_* methods to allocate a new tensor, which record the kernel and step.</p> <p><code>a</code> must outlive the lifetime of this Tensor .</p> <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::Tensor(Allocator *a, DataType type, const TensorShape &amp;shape, const AllocationAttributes &amp;allocation_attr)</code></h4> <p>Creates a tensor with the input <code>type</code> and <code>shape</code>, using the allocator <code>a</code> and the specified \"allocation_attr\" to allocate the underlying buffer. If the kernel and step are known allocation_attr.allocation_will_be_logged should be set to true and LogMemory::RecordTensorAllocation should be called after the tensor is constructed. Calling the Tensor constructor directly from within an Op is deprecated: use the OpKernelConstruction/OpKernelContext allocate_* methods to allocate a new tensor, which record the kernel and step.</p> <p><code>a</code> must outlive the lifetime of this Tensor .</p> <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::Tensor(DataType type)</code></h4> <p>Creates an empty Tensor of the given data type.</p> <p>Like Tensor() , returns a 1-dimensional, 0-element Tensor with IsInitialized() returning True. See the Tensor() documentation for details.</p> <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::Tensor(const Tensor &amp;other)</code></h4> <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::Tensor(Tensor &amp;&amp;other)</code></h4> <p>Copy constructor.</p> <h4 id=\"tensorflow_Tensor_Tensor\"><code>tensorflow::Tensor::~Tensor()</code></h4> <h4 id=\"DataType_tensorflow_Tensor_dtype\"><code>DataType tensorflow::Tensor::dtype() const</code></h4> <p>Returns the data type.</p> <h4 id=\"const_TensorShape_tensorflow_Tensor_shape\"><code>const TensorShape&amp; tensorflow::Tensor::shape() const</code></h4> <p>Returns the shape of the tensor.</p> <h4 id=\"int_tensorflow_Tensor_dims\"><code>int tensorflow::Tensor::dims() const</code></h4> <p>Convenience accessor for the tensor shape.</p> <p>For all shape accessors, see comments for relevant methods of <code>TensorShape</code> in <code>tensor_shape.h</code>.</p> <h4 id=\"int64_tensorflow_Tensor_dim_size\"><code>int64 tensorflow::Tensor::dim_size(int d) const</code></h4> <p>Convenience accessor for the tensor shape.</p> <h4 id=\"int64_tensorflow_Tensor_NumElements\"><code>int64 tensorflow::Tensor::NumElements() const</code></h4> <p>Convenience accessor for the tensor shape.</p> <h4 id=\"bool_tensorflow_Tensor_IsSameSize\"><code>bool tensorflow::Tensor::IsSameSize(const Tensor &amp;b) const</code></h4> <h4 id=\"bool_tensorflow_Tensor_SharesBufferWith\"><code>bool tensorflow::Tensor::SharesBufferWith(const Tensor &amp;b) const</code></h4> <h4 id=\"size_t_tensorflow_Tensor_BufferHash\"><code>size_t tensorflow::Tensor::BufferHash() const</code></h4> <h4 id=\"bool_tensorflow_Tensor_IsInitialized\"><code>bool tensorflow::Tensor::IsInitialized() const</code></h4> <p>If necessary, has this Tensor been initialized?</p> <p>Zero-element Tensors are always considered initialized, even if they have never been assigned to and do not have any memory allocated.</p> <h4 id=\"size_t_tensorflow_Tensor_TotalBytes\"><code>size_t tensorflow::Tensor::TotalBytes() const</code></h4> <p>Returns the estimated memory usage of this tensor.</p> <h4 id=\"bool_tensorflow_Tensor_IsAligned\"><code>bool tensorflow::Tensor::IsAligned() const</code></h4> <p>Returns true iff this tensor is aligned.</p> <h4 id=\"Tensor_tensorflow_Tensor_operator_\"><code>Tensor&amp; tensorflow::Tensor::operator=(const Tensor &amp;other)</code></h4> <p>Assign operator. This tensor shares other's underlying storage.</p> <h4 id=\"Tensor_tensorflow_Tensor_operator_\"><code>Tensor &amp; tensorflow::Tensor::operator=(Tensor &amp;&amp;other)</code></h4> <p>Move operator. See move constructor for details.</p> <h4 id=\"bool_tensorflow_Tensor_CopyFrom\"><code>bool tensorflow::Tensor::CopyFrom(const Tensor &amp;other, const TensorShape &amp;shape) TF_MUST_USE_RESULT</code></h4> <p>Copy the other tensor into this tensor and reshape it.</p> <p>This tensor shares other's underlying storage. Returns <code>true</code> iff <code>other.shape()</code> has the same number of elements of the given <code>shape</code>.</p> <h4 id=\"Tensor_tensorflow_Tensor_Slice\"><code>Tensor tensorflow::Tensor::Slice(int64 dim0_start, int64 dim0_limit) const</code></h4> <p>Slice this tensor along the 1st dimension.</p> <p>I.e., the returned tensor satisfies returned[i, ...] == this[dim0_start + i, ...]. The returned tensor shares the underlying tensor buffer with this tensor.</p> <p>NOTE: The returned tensor may not satisfies the same alignment requirement as this tensor depending on the shape. The caller must check the returned tensor's alignment before calling certain methods that have alignment requirement (e.g., <code>flat()</code>, <code>tensor()</code>).</p> <p>REQUIRES: <code>dims()</code> &gt;= 1 REQUIRES: <code>0 &lt;= dim0_start &lt;= dim0_limit &lt;= dim_size(0)</code></p> <h4 id=\"bool_tensorflow_Tensor_FromProto\"><code>bool tensorflow::Tensor::FromProto(const TensorProto &amp;other) TF_MUST_USE_RESULT</code></h4> <p>Parse <code>other</code> and construct the tensor.</p> <p>Returns <code>true</code> iff the parsing succeeds. If the parsing fails, the state of <code>*this</code> is unchanged.</p> <h4 id=\"bool_tensorflow_Tensor_FromProto\"><code>bool tensorflow::Tensor::FromProto(Allocator *a, const TensorProto &amp;other) TF_MUST_USE_RESULT</code></h4> <h4 id=\"void_tensorflow_Tensor_AsProtoField\"><code>void tensorflow::Tensor::AsProtoField(TensorProto *proto) const</code></h4> <p>Fills in <code>proto</code> with <code>*this</code> tensor's content.</p> <p><code>AsProtoField()</code> fills in the repeated field for <code>proto.dtype()</code>, while <code>AsProtoTensorContent()</code> encodes the content in <code>proto.tensor_content()</code> in a compact form.</p> <h4 id=\"void_tensorflow_Tensor_AsProtoTensorContent\"><code>void tensorflow::Tensor::AsProtoTensorContent(TensorProto *proto) const</code></h4> <h4 id=\"TTypes_T_Vec_tensorflow_Tensor_vec\"><code>TTypes&lt;T&gt;::Vec tensorflow::Tensor::vec()</code></h4> <p>Return the tensor data as an <code>Eigen::Tensor</code> with the type and sizes of this <code>Tensor</code>.</p> <p>Use these methods when you know the data type and the number of dimensions of the Tensor and you want an <code>Eigen::Tensor</code> automatically sized to the <code>Tensor</code> sizes. The implementation check fails if either type or sizes mismatch.</p> <p>Example:</p> <pre class=\"lang-c++ no-auto-prettify\" data-language=\"cpp\">Tensor my_mat(...built with Shape{rows: 3, cols: 5}...);\nauto mat = my_mat.matrix&lt;T&gt;();    // 2D Eigen::Tensor, 3 x 5.\nauto mat = my_mat.tensor&lt;T, 2&gt;(); // 2D Eigen::Tensor, 3 x 5.\nauto vec = my_mat.vec&lt;T&gt;();       // CHECK fails as my_mat is 2D.\nauto vec = my_mat.tensor&lt;T, 3&gt;(); // CHECK fails as my_mat is 2D.\nauto mat = my_mat.matrix&lt;int32&gt;();// CHECK fails as type mismatch.\n\n</pre> <h4 id=\"TTypes_T_Matrix_tensorflow_Tensor_matrix\"><code>TTypes&lt;T&gt;::Matrix tensorflow::Tensor::matrix()</code></h4> <h4 id=\"TTypes_T_NDIMS_Tensor_tensorflow_Tensor_tensor\"><code>TTypes&lt; T, NDIMS &gt;::Tensor tensorflow::Tensor::tensor()</code></h4> <h4 id=\"TTypes_T_NDIMS_Tensor_tensorflow_Tensor_bit_casted_tensor\"><code>TTypes&lt; T, NDIMS &gt;::Tensor tensorflow::Tensor::bit_casted_tensor()</code></h4> <p>Return the tensor data to an <code>Eigen::Tensor</code> with the same size but a bitwise cast to the specified dtype <code>T</code>.</p> <p>Using a bitcast is useful for move and copy operations. NOTE: this is the same as <code>tensor()</code> except a bitcast is allowed.</p> <h4 id=\"TTypes_T_Flat_tensorflow_Tensor_flat\"><code>TTypes&lt;T&gt;::Flat tensorflow::Tensor::flat()</code></h4> <p>Return the tensor data as an <code>Eigen::Tensor</code> of the data type and a specified shape.</p> <p>These methods allow you to access the data with the dimensions and sizes of your choice. You do not need to know the number of dimensions of the Tensor to call them. However, they <code>CHECK</code> that the type matches and the dimensions requested creates an <code>Eigen::Tensor</code> with the same number of elements as the tensor.</p> <p>Example:</p> <pre class=\"lang-c++ no-auto-prettify\" data-language=\"cpp\">Tensor my_ten(...built with Shape{planes: 4, rows: 3, cols: 5}...);\n// 1D Eigen::Tensor, size 60:\nauto flat = my_ten.flat&lt;T&gt;();\n// 2D Eigen::Tensor 12 x 5:\nauto inner = my_ten.flat_inner_dims&lt;T&gt;();\n// 2D Eigen::Tensor 4 x 15:\nauto outer = my_ten.shaped&lt;T, 2&gt;({4, 15});\n// CHECK fails, bad num elements:\nauto outer = my_ten.shaped&lt;T, 2&gt;({4, 8});\n// 3D Eigen::Tensor 6 x 5 x 2:\nauto weird = my_ten.shaped&lt;T, 3&gt;({6, 5, 2});\n// CHECK fails, type mismatch:\nauto bad   = my_ten.flat&lt;int32&gt;();\n\n</pre> <h4 id=\"TTypes_T_UnalignedFlat_tensorflow_Tensor_unaligned_flat\"><code>TTypes&lt;T&gt;::UnalignedFlat tensorflow::Tensor::unaligned_flat()</code></h4> <h4 id=\"TTypes_T_NDIMS_Tensor_tensorflow_Tensor_flat_inner_dims\"><code>TTypes&lt; T, NDIMS &gt;::Tensor tensorflow::Tensor::flat_inner_dims()</code></h4> <p>Returns the data as an Eigen::Tensor with NDIMS dimensions, collapsing all Tensor dimensions but the last NDIMS-1 into the first dimension of the result. If NDIMS &gt; dims() then leading dimensions of size 1 will be added to make the output rank NDIMS.</p> <h4 id=\"TTypes_T_NDIMS_Tensor_tensorflow_Tensor_flat_outer_dims\"><code>TTypes&lt; T, NDIMS &gt;::Tensor tensorflow::Tensor::flat_outer_dims()</code></h4> <p>Returns the data as an Eigen::Tensor with NDIMS dimensions, collapsing all Tensor dimensions but the first NDIMS-1 into the last dimension of the result. If NDIMS &gt; dims() then trailing dimensions of size 1 will be added to make the output rank NDIMS.</p> <h4 id=\"TTypes_T_NDIMS_Tensor_tensorflow_Tensor_shaped\"><code>TTypes&lt; T, NDIMS &gt;::Tensor tensorflow::Tensor::shaped(gtl::ArraySlice&lt; int64 &gt; new_sizes)</code></h4> <h4 id=\"TTypes_T_NDIMS_Tensor_tensorflow_Tensor_bit_casted_shaped\"><code>TTypes&lt; T, NDIMS &gt;::Tensor tensorflow::Tensor::bit_casted_shaped(gtl::ArraySlice&lt; int64 &gt; new_sizes)</code></h4> <p>Return the tensor data to an <code>Eigen::Tensor</code> with the new shape specified in <code>new_sizes</code> and cast to a new dtype <code>T</code>.</p> <p>Using a bitcast is useful for move and copy operations. The allowed bitcast is the only difference from <code>shaped()</code>.</p> <h4 id=\"TTypes_T_NDIMS_UnalignedTensor_tensorflow_Tensor_unaligned_shaped\"><code>TTypes&lt; T, NDIMS &gt;::UnalignedTensor tensorflow::Tensor::unaligned_shaped(gtl::ArraySlice&lt; int64 &gt; new_sizes)</code></h4> <h4 id=\"TTypes_T_Scalar_tensorflow_Tensor_scalar\"><code>TTypes&lt; T &gt;::Scalar tensorflow::Tensor::scalar()</code></h4> <p>Return the Tensor data as a <code>TensorMap</code> of fixed size 1: <code>TensorMap&lt;TensorFixedSize&lt;T, 1&gt;&gt;</code>.</p> <p>Using <code>scalar()</code> allows the compiler to perform optimizations as the size of the tensor is known at compile time.</p> <h4 id=\"TTypes_T_ConstVec_tensorflow_Tensor_vec\"><code>TTypes&lt;T&gt;::ConstVec tensorflow::Tensor::vec() const</code></h4> <p>Const versions of all the methods above.</p> <h4 id=\"TTypes_T_ConstMatrix_tensorflow_Tensor_matrix\"><code>TTypes&lt;T&gt;::ConstMatrix tensorflow::Tensor::matrix() const</code></h4> <h4 id=\"TTypes_T_NDIMS_ConstTensor_tensorflow_Tensor_tensor\"><code>TTypes&lt; T, NDIMS &gt;::ConstTensor tensorflow::Tensor::tensor() const</code></h4> <h4 id=\"TTypes_T_NDIMS_ConstTensor_tensorflow_Tensor_bit_casted_tensor\"><code>TTypes&lt; T, NDIMS &gt;::ConstTensor tensorflow::Tensor::bit_casted_tensor() const</code></h4> <p>Return the tensor data to an <code>Eigen::Tensor</code> with the same size but a bitwise cast to the specified dtype <code>T</code>.</p> <p>Using a bitcast is useful for move and copy operations. NOTE: this is the same as <code>tensor()</code> except a bitcast is allowed.</p> <h4 id=\"TTypes_T_ConstFlat_tensorflow_Tensor_flat\"><code>TTypes&lt;T&gt;::ConstFlat tensorflow::Tensor::flat() const</code></h4> <h4 id=\"TTypes_T_UnalignedConstFlat_tensorflow_Tensor_unaligned_flat\"><code>TTypes&lt;T&gt;::UnalignedConstFlat tensorflow::Tensor::unaligned_flat() const</code></h4> <h4 id=\"TTypes_T_NDIMS_ConstTensor_tensorflow_Tensor_shaped\"><code>TTypes&lt; T, NDIMS &gt;::ConstTensor tensorflow::Tensor::shaped(gtl::ArraySlice&lt; int64 &gt; new_sizes) const</code></h4> <h4 id=\"TTypes_T_NDIMS_ConstTensor_tensorflow_Tensor_bit_casted_shaped\"><code>TTypes&lt; T, NDIMS &gt;::ConstTensor tensorflow::Tensor::bit_casted_shaped(gtl::ArraySlice&lt; int64 &gt; new_sizes) const</code></h4> <p>Return the tensor data to an <code>Eigen::Tensor</code> with the new shape specified in <code>new_sizes</code> and cast to a new dtype <code>T</code>.</p> <p>Using a bitcast is useful for move and copy operations. The allowed bitcast is the only difference from <code>shaped()</code>.</p> <h4 id=\"TTypes_T_NDIMS_UnalignedConstTensor_tensorflow_Tensor_unaligned_shaped\"><code>TTypes&lt; T, NDIMS &gt;::UnalignedConstTensor tensorflow::Tensor::unaligned_shaped(gtl::ArraySlice&lt; int64 &gt; new_sizes) const</code></h4> <h4 id=\"TTypes_T_ConstScalar_tensorflow_Tensor_scalar\"><code>TTypes&lt; T &gt;::ConstScalar tensorflow::Tensor::scalar() const</code></h4> <h4 id=\"TTypes_T_NDIMS_ConstTensor_tensorflow_Tensor_flat_inner_dims\"><code>TTypes&lt; T, NDIMS &gt;::ConstTensor tensorflow::Tensor::flat_inner_dims() const</code></h4> <h4 id=\"TTypes_T_NDIMS_ConstTensor_tensorflow_Tensor_flat_outer_dims\"><code>TTypes&lt; T, NDIMS &gt;::ConstTensor tensorflow::Tensor::flat_outer_dims() const</code></h4> <h4 id=\"string_tensorflow_Tensor_SummarizeValue\"><code>string tensorflow::Tensor::SummarizeValue(int64 max_entries) const</code></h4> <p>Render the first <code>max_entries</code> values in <code>*this</code> into a string.</p> <h4 id=\"string_tensorflow_Tensor_DebugString\"><code>string tensorflow::Tensor::DebugString() const</code></h4> <p>A human-readable summary of the tensor suitable for debugging.</p> <h4 id=\"void_tensorflow_Tensor_FillDescription\"><code>void tensorflow::Tensor::FillDescription(TensorDescription *description) const</code></h4> <p>Fill in the <code>TensorDescription</code> proto with metadata about the tensor that is useful for monitoring and debugging.</p> <h4 id=\"StringPiece_tensorflow_Tensor_tensor_data\"><code>StringPiece tensorflow::Tensor::tensor_data() const</code></h4> <p>Returns a <code>StringPiece</code> mapping the current tensor's buffer.</p> <p>The returned <code>StringPiece</code> may point to memory location on devices that the CPU cannot address directly.</p> <p>NOTE: The underlying tensor buffer is refcounted, so the lifetime of the contents mapped by the <code>StringPiece</code> matches the lifetime of the buffer; callers should arrange to make sure the buffer does not get destroyed while the <code>StringPiece</code> is still used.</p> <p>REQUIRES: <code>DataTypeCanUseMemcpy(dtype())</code>.</p> <h4 id=\"void_tensorflow_Tensor_UnsafeCopyFromInternal\"><code>void tensorflow::Tensor::UnsafeCopyFromInternal(const Tensor &amp;, const TensorShape &amp;)</code></h4> <p>Copy the other tensor into this tensor and reshape it and reinterpret the buffer's datatype.</p> <p>This tensor shares other's underlying storage.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassTensor.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassTensor.html</a>\n  </p>\n</div>\n","classwritablefile":"<h1 id=\"class-tensorflowwritablefile\"><code>class tensorflow::WritableFile</code></h1> <p>A file abstraction for sequential writing.</p> <p>The implementation must provide buffering since callers may append small fragments at a time to the file.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_WritableFile_WritableFile\"><code>tensorflow::WritableFile::WritableFile()</code></h4> <h4 id=\"tensorflow_WritableFile_WritableFile\"><code>tensorflow::WritableFile::~WritableFile()</code></h4> <h4 id=\"virtual_Status_tensorflow_WritableFile_Append\"><code>virtual Status tensorflow::WritableFile::Append(const StringPiece &amp;data)=0</code></h4> <h4 id=\"virtual_Status_tensorflow_WritableFile_Close\"><code>virtual Status tensorflow::WritableFile::Close()=0</code></h4> <h4 id=\"virtual_Status_tensorflow_WritableFile_Flush\"><code>virtual Status tensorflow::WritableFile::Flush()=0</code></h4> <h4 id=\"virtual_Status_tensorflow_WritableFile_Sync\"><code>virtual Status tensorflow::WritableFile::Sync()=0</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassWritableFile.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassWritableFile.html</a>\n  </p>\n</div>\n","classrandomaccessfile":"<h1 id=\"class-tensorflowrandomaccessfile\"><code>class tensorflow::RandomAccessFile</code></h1> <p>A file abstraction for randomly reading the contents of a file.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_RandomAccessFile_RandomAccessFile\"><code>tensorflow::RandomAccessFile::RandomAccessFile()</code></h4> <h4 id=\"tensorflow_RandomAccessFile_RandomAccessFile\"><code>tensorflow::RandomAccessFile::~RandomAccessFile()</code></h4> <h4 id=\"virtual_Status_tensorflow_RandomAccessFile_Read\"><code>virtual Status tensorflow::RandomAccessFile::Read(uint64 offset, size_t n, StringPiece *result, char *scratch) const =0</code></h4> <p>Reads up to <code>n</code> bytes from the file starting at <code>offset</code>.</p> <p><code>scratch[0..n-1]</code> may be written by this routine. Sets <code>*result</code> to the data that was read (including if fewer than <code>n</code> bytes were successfully read). May set <code>*result</code> to point at data in <code>scratch[0..n-1]</code>, so <code>scratch[0..n-1]</code> must be live when <code>*result</code> is used.</p> <p>On OK returned status: <code>n</code> bytes have been stored in <code>*result</code>. On non-OK returned status: <code>[0..n]</code> bytes have been stored in <code>*result</code>.</p> <p>Returns <code>OUT_OF_RANGE</code> if fewer than n bytes were stored in <code>*result</code> because of EOF.</p> <p>Safe for concurrent use by multiple threads.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassRandomAccessFile.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassRandomAccessFile.html</a>\n  </p>\n</div>\n","classtensorshapeutils":"<h1 id=\"class-tensorflowtensorshapeutils\"><code>class tensorflow::TensorShapeUtils</code></h1> <p>Static helper routines for <code>TensorShape</code>. Includes a few common predicates on a tensor shape.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"static_bool_tensorflow_TensorShapeUtils_IsScalar\"><code>static bool tensorflow::TensorShapeUtils::IsScalar(const TensorShape &amp;shape)</code></h4> <h4 id=\"static_bool_tensorflow_TensorShapeUtils_IsVector\"><code>static bool tensorflow::TensorShapeUtils::IsVector(const TensorShape &amp;shape)</code></h4> <h4 id=\"static_bool_tensorflow_TensorShapeUtils_IsVectorOrHigher\"><code>static bool tensorflow::TensorShapeUtils::IsVectorOrHigher(const TensorShape &amp;shape)</code></h4> <h4 id=\"static_bool_tensorflow_TensorShapeUtils_IsMatrix\"><code>static bool tensorflow::TensorShapeUtils::IsMatrix(const TensorShape &amp;shape)</code></h4> <h4 id=\"static_bool_tensorflow_TensorShapeUtils_IsMatrixOrHigher\"><code>static bool tensorflow::TensorShapeUtils::IsMatrixOrHigher(const TensorShape &amp;shape)</code></h4> <h4 id=\"static_Status_tensorflow_TensorShapeUtils_MakeShape\"><code>static Status tensorflow::TensorShapeUtils::MakeShape(const int32 *dims, int64 n, TensorShape *out)</code></h4> <p>Returns a <code>TensorShape</code> whose dimensions are <code>dims[0]</code>, <code>dims[1]</code>, ..., <code>dims[n-1]</code>.</p> <h4 id=\"static_Status_tensorflow_TensorShapeUtils_MakeShape\"><code>static Status tensorflow::TensorShapeUtils::MakeShape(const int64 *dims, int64 n, TensorShape *out)</code></h4> <h4 id=\"static_Status_tensorflow_TensorShapeUtils_MakeShape\"><code>static Status tensorflow::TensorShapeUtils::MakeShape(gtl::ArraySlice&lt; int32 &gt; shape, TensorShape *out)</code></h4> <h4 id=\"static_Status_tensorflow_TensorShapeUtils_MakeShape\"><code>static Status tensorflow::TensorShapeUtils::MakeShape(gtl::ArraySlice&lt; int64 &gt; shape, TensorShape *out)</code></h4> <h4 id=\"string_tensorflow_TensorShapeUtils_ShapeListString\"><code>string tensorflow::TensorShapeUtils::ShapeListString(const gtl::ArraySlice&lt; TensorShape &gt; &amp;shapes)</code></h4> <h4 id=\"bool_tensorflow_TensorShapeUtils_StartsWith\"><code>bool tensorflow::TensorShapeUtils::StartsWith(const TensorShape &amp;shape0, const TensorShape &amp;shape1)</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassTensorShapeUtils.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassTensorShapeUtils.html</a>\n  </p>\n</div>\n","structtensorshapedim":"<h1 id=\"struct-tensorflowtensorshapedim\"><code>struct tensorflow::TensorShapeDim</code></h1>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"int64_tensorflow_TensorShapeDim_size\"><code>int64 tensorflow::TensorShapeDim::size</code></h4> <h4 id=\"tensorflow_TensorShapeDim_TensorShapeDim\"><code>tensorflow::TensorShapeDim::TensorShapeDim(int64 s)</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructTensorShapeDim.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructTensorShapeDim.html</a>\n  </p>\n</div>\n","structthreadoptions":"<h1 id=\"struct-tensorflowthreadoptions\"><code>struct tensorflow::ThreadOptions</code></h1> <p>Options to configure a Thread .</p> <p>Note that the options are all hints, and the underlying implementation may choose to ignore it.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"size_t_tensorflow_ThreadOptions_stack_size\"><code>size_t tensorflow::ThreadOptions::stack_size</code></h4> <p>Thread stack size to use (in bytes).</p> <h4 id=\"size_t_tensorflow_ThreadOptions_guard_size\"><code>size_t tensorflow::ThreadOptions::guard_size</code></h4> <p>Guard area size to use near thread stacks to use (in bytes)</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructThreadOptions.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructThreadOptions.html</a>\n  </p>\n</div>\n","classtensorshape":"<h1 id=\"class-tensorflowtensorshape\"><code>class tensorflow::TensorShape</code></h1>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"uint8_tensorflow_TensorShape_buf_16_\"><code>uint8 tensorflow::TensorShape::buf[16][16]</code></h4> <h4 id=\"Rep64_tensorflow_TensorShape_unused_aligner\"><code>Rep64* tensorflow::TensorShape::unused_aligner</code></h4> <h4 id=\"tensorflow_TensorShape_TensorShape\"><code>tensorflow::TensorShape::TensorShape(gtl::ArraySlice&lt; int64 &gt; dim_sizes)</code></h4> <p>Construct a <code>TensorShape</code> from the provided sizes. REQUIRES: <code>dim_sizes[i] &gt;= 0</code></p> <h4 id=\"tensorflow_TensorShape_TensorShape\"><code>tensorflow::TensorShape::TensorShape(std::initializer_list&lt; int64 &gt; dim_sizes)</code></h4> <h4 id=\"tensorflow_TensorShape_TensorShape\"><code>tensorflow::TensorShape::TensorShape(const TensorShapeProto &amp;proto)</code></h4> <p>REQUIRES: <code>IsValid(proto)</code></p> <h4 id=\"tensorflow_TensorShape_TensorShape\"><code>tensorflow::TensorShape::TensorShape()</code></h4> <p>Create a tensor shape with no dimensions and one element, which you can then call <code>AddDim()</code> on.</p> <h4 id=\"tensorflow_TensorShape_TensorShape\"><code>tensorflow::TensorShape::~TensorShape()</code></h4> <h4 id=\"tensorflow_TensorShape_TensorShape\"><code>tensorflow::TensorShape::TensorShape(const TensorShape &amp;b)</code></h4> <p>Copy the specified shape.</p> <h4 id=\"void_tensorflow_TensorShape_operator_\"><code>void tensorflow::TensorShape::operator=(const TensorShape &amp;b)</code></h4> <h4 id=\"tensorflow_TensorShape_TensorShape\"><code>tensorflow::TensorShape::TensorShape(TensorShape &amp;&amp;b)</code></h4> <p>Move the specified shape. After moving, is safe for destruction and.</p> <h4 id=\"void_tensorflow_TensorShape_operator_\"><code>void tensorflow::TensorShape::operator=(TensorShape &amp;&amp;b)</code></h4> <h4 id=\"void_tensorflow_TensorShape_Clear\"><code>void tensorflow::TensorShape::Clear()</code></h4> <p>Clear a tensor shape.</p> <h4 id=\"void_tensorflow_TensorShape_AddDim\"><code>void tensorflow::TensorShape::AddDim(int64 size)</code></h4> <p>Add a dimension to the end (\"inner-most\"). REQUIRES: <code>size &gt;= 0</code></p> <h4 id=\"void_tensorflow_TensorShape_AppendShape\"><code>void tensorflow::TensorShape::AppendShape(const TensorShape &amp;shape)</code></h4> <p>Appends all the dimensions from <code>shape</code>.</p> <h4 id=\"void_tensorflow_TensorShape_InsertDim\"><code>void tensorflow::TensorShape::InsertDim(int d, int64 size)</code></h4> <p>Insert a dimension somewhere in the <code>TensorShape</code>. REQUIRES: <code>0 &lt;= d &lt;= dims()</code> REQUIRES: <code>size &gt;= 0</code></p> <h4 id=\"void_tensorflow_TensorShape_set_dim\"><code>void tensorflow::TensorShape::set_dim(int d, int64 size)</code></h4> <p>Modifies the size of the dimension <code>d</code> to be <code>size</code> REQUIRES: <code>0 &lt;= d &lt; dims()</code> REQUIRES: <code>size &gt;= 0</code></p> <h4 id=\"void_tensorflow_TensorShape_RemoveDim\"><code>void tensorflow::TensorShape::RemoveDim(int d)</code></h4> <p>Removes dimension <code>d</code> from the <code>TensorShape</code>. REQUIRES: <code>0 &lt;= d &lt; dims()</code></p> <h4 id=\"int_tensorflow_TensorShape_dims\"><code>int tensorflow::TensorShape::dims() const</code></h4> <p>Return the number of dimensions in the tensor.</p> <h4 id=\"int64_tensorflow_TensorShape_dim_size\"><code>int64 tensorflow::TensorShape::dim_size(int d) const</code></h4> <p>Returns the number of elements in dimension <code>d</code>. REQUIRES: <code>0 &lt;= d &lt; dims()</code></p> <h4 id=\"gtl_InlinedVector_int64_4_tensorflow_TensorShape_dim_sizes\"><code>gtl::InlinedVector&lt; int64, 4 &gt; tensorflow::TensorShape::dim_sizes() const</code></h4> <p>Returns sizes of all dimensions.</p> <h4 id=\"int64_tensorflow_TensorShape_num_elements\"><code>int64 tensorflow::TensorShape::num_elements() const</code></h4> <p>Returns the number of elements in the tensor.</p> <p>We use <code>int64</code> and not <code>size_t</code> to be compatible with <code>Eigen::Tensor</code> which uses <code>ptrdiff_t</code>.</p> <h4 id=\"bool_tensorflow_TensorShape_IsSameSize\"><code>bool tensorflow::TensorShape::IsSameSize(const TensorShape &amp;b) const</code></h4> <p>Returns true if <code>*this</code> and <code>b</code> have the same sizes. Ignores dimension names.</p> <h4 id=\"bool_tensorflow_TensorShape_operator_\"><code>bool tensorflow::TensorShape::operator==(const TensorShape &amp;b) const</code></h4> <h4 id=\"bool_tensorflow_TensorShape_operator_\"><code>bool tensorflow::TensorShape::operator!=(const TensorShape &amp;b) const</code></h4> <h4 id=\"void_tensorflow_TensorShape_AsProto\"><code>void tensorflow::TensorShape::AsProto(TensorShapeProto *proto) const</code></h4> <p>Fill <code>*proto</code> from <code>*this</code>.</p> <h4 id=\"Eigen_DSizes_Eigen_DenseIndex_NDIMS_tensorflow_TensorShape_AsEigenDSizes\"><code>Eigen::DSizes&lt; Eigen::DenseIndex, NDIMS &gt; tensorflow::TensorShape::AsEigenDSizes() const</code></h4> <p>Fill <code>*dsizes</code> from <code>*this</code>.</p> <h4 id=\"Eigen_DSizes_Eigen_DenseIndex_NDIMS_tensorflow_TensorShape_AsEigenDSizesWithPadding\"><code>Eigen::DSizes&lt; Eigen::DenseIndex, NDIMS &gt; tensorflow::TensorShape::AsEigenDSizesWithPadding() const</code></h4> <p>Same as <code>AsEigenDSizes()</code> but allows for <code>NDIMS &gt; dims()</code> in which case we pad the rest of the sizes with 1.</p> <h4 id=\"TensorShapeIter_tensorflow_TensorShape_begin\"><code>TensorShapeIter tensorflow::TensorShape::begin() const</code></h4> <p>For iterating through the dimensions.</p> <h4 id=\"TensorShapeIter_tensorflow_TensorShape_end\"><code>TensorShapeIter tensorflow::TensorShape::end() const</code></h4> <h4 id=\"string_tensorflow_TensorShape_DebugString\"><code>string tensorflow::TensorShape::DebugString() const</code></h4> <p>For error messages.</p> <h4 id=\"void_tensorflow_TensorShape_DumpRep\"><code>void tensorflow::TensorShape::DumpRep() const</code></h4> <h4 id=\"bool_tensorflow_TensorShape_IsValid\"><code>bool tensorflow::TensorShape::IsValid(const TensorShapeProto &amp;proto)</code></h4> <p>Returns <code>true</code> iff <code>proto</code> is a valid tensor shape.</p> <h4 id=\"Status_tensorflow_TensorShape_IsValidShape\"><code>Status tensorflow::TensorShape::IsValidShape(const TensorShapeProto &amp;proto)</code></h4> <p>Returns <code>OK</code> iff <code>proto</code> is a valid tensor shape, and a descriptive error status otherwise.</p> <h4 id=\"static_constexpr_int_tensorflow_TensorShape_MaxDimensions\"><code>static constexpr int tensorflow::TensorShape::MaxDimensions()</code></h4> <h4 id=\"string_tensorflow_TensorShape_DebugString\"><code>string tensorflow::TensorShape::DebugString(const TensorShapeProto &amp;proto)</code></h4> <p>Same as <code>TensorShape(proto). DebugString()</code> but doesn't crash for invalid protos.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassTensorShape.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassTensorShape.html</a>\n  </p>\n</div>\n","structstate":"<h1 id=\"struct-tensorflowstatusstate\"><code>struct tensorflow::Status::State</code></h1>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_error_Code_tensorflow_Status_State_code\"><code>tensorflow::error::Code tensorflow::Status::State::code</code></h4> <h4 id=\"string_tensorflow_Status_State_msg\"><code>string tensorflow::Status::State::msg</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructState.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructState.html</a>\n  </p>\n</div>\n","classthread":"<h1 id=\"class-tensorflowthread\"><code>class tensorflow::Thread</code></h1>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_Thread_Thread\"><code>tensorflow::Thread::Thread()</code></h4> <h4 id=\"tensorflow_Thread_Thread\"><code>tensorflow::Thread::~Thread()</code></h4> <p>Blocks until the thread of control stops running.</p><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassThread.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassThread.html</a>\n  </p>\n</div>\n","classstatus":"<h1 id=\"class-tensorflowstatus\"><code>class tensorflow::Status</code></h1>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_Status_Status\"><code>tensorflow::Status::Status()</code></h4> <p>Create a success status.</p> <h4 id=\"tensorflow_Status_Status\"><code>tensorflow::Status::~Status()</code></h4> <h4 id=\"tensorflow_Status_Status\"><code>tensorflow::Status::Status(tensorflow::error::Code code, tensorflow::StringPiece msg)</code></h4> <p>Create a status with the specified error code and msg as a human-readable string containing more detailed information.</p> <h4 id=\"tensorflow_Status_Status\"><code>tensorflow::Status::Status(const Status &amp;s)</code></h4> <p>Copy the specified status.</p> <h4 id=\"void_tensorflow_Status_operator_\"><code>void tensorflow::Status::operator=(const Status &amp;s)</code></h4> <h4 id=\"bool_tensorflow_Status_ok\"><code>bool tensorflow::Status::ok() const</code></h4> <p>Returns true iff the status indicates success.</p> <h4 id=\"tensorflow_error_Code_tensorflow_Status_code\"><code>tensorflow::error::Code tensorflow::Status::code() const</code></h4> <h4 id=\"const_string_tensorflow_Status_error_message\"><code>const string&amp; tensorflow::Status::error_message() const</code></h4> <h4 id=\"bool_tensorflow_Status_operator_\"><code>bool tensorflow::Status::operator==(const Status &amp;x) const</code></h4> <h4 id=\"bool_tensorflow_Status_operator_\"><code>bool tensorflow::Status::operator!=(const Status &amp;x) const</code></h4> <h4 id=\"void_tensorflow_Status_Update\"><code>void tensorflow::Status::Update(const Status &amp;new_status)</code></h4> <p>If <code>ok()</code>, stores <code>new_status</code> into <code>*this</code>. If <code>!ok()</code>, preserves the current status, but may augment with additional information about <code>new_status</code>.</p> <p>Convenient way of keeping track of the first error encountered. Instead of: <code>if (overall_status.ok()) overall_status = new_status</code> Use: <code>overall_status.Update(new_status);</code></p> <h4 id=\"string_tensorflow_Status_ToString\"><code>string tensorflow::Status::ToString() const</code></h4> <p>Return a string representation of this status suitable for printing. Returns the string <code>\"OK\"</code> for success.</p> <h4 id=\"return_tensorflow_Status_OK\"><code>return tensorflow::Status::OK()</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassStatus.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassStatus.html</a>\n  </p>\n</div>\n","classpartialtensorshape":"<h1 id=\"class-tensorflowpartialtensorshape\"><code>class tensorflow::PartialTensorShape</code></h1> <p>Manages the partially known dimensions of a Tensor and their sizes.</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_PartialTensorShape_PartialTensorShape\"><code>tensorflow::PartialTensorShape::PartialTensorShape()</code></h4> <p>Construct an unknown <code>PartialTensorShape</code>.</p> <h4 id=\"tensorflow_PartialTensorShape_PartialTensorShape\"><code>tensorflow::PartialTensorShape::PartialTensorShape(gtl::ArraySlice&lt; int64 &gt; dim_sizes)</code></h4> <p>Construct a <code>PartialTensorShape</code> from the provided sizes. REQUIRES: <code>dim_sizes[i] &gt;= 0</code></p> <h4 id=\"tensorflow_PartialTensorShape_PartialTensorShape\"><code>tensorflow::PartialTensorShape::PartialTensorShape(std::initializer_list&lt; int64 &gt; dim_sizes)</code></h4> <h4 id=\"tensorflow_PartialTensorShape_PartialTensorShape\"><code>tensorflow::PartialTensorShape::PartialTensorShape(const TensorShapeProto &amp;proto)</code></h4> <p>REQUIRES: <code>IsValid(proto)</code></p> <h4 id=\"PartialTensorShape_tensorflow_PartialTensorShape_Concatenate\"><code>PartialTensorShape tensorflow::PartialTensorShape::Concatenate(int64 size) const</code></h4> <p>Add a dimension to the end (\"inner-most\"), returns a new PartialTensorShape . REQUIRES: <code>size &gt;= -1</code>, where -1 means unknown</p> <h4 id=\"PartialTensorShape_tensorflow_PartialTensorShape_Concatenate\"><code>PartialTensorShape tensorflow::PartialTensorShape::Concatenate(const PartialTensorShape &amp;shape) const</code></h4> <p>Appends all the dimensions from <code>shape</code>. Returns a new PartialTensorShape .</p> <h4 id=\"Status_tensorflow_PartialTensorShape_MergeWith\"><code>Status tensorflow::PartialTensorShape::MergeWith(const PartialTensorShape &amp;shape, PartialTensorShape *result) const</code></h4> <p>Merges all the dimensions from <code>shape</code>. Returns <code>InvalidArgument</code> error if either <code>shape</code> has a different rank or if any of the dimensions are incompatible.</p> <h4 id=\"int_tensorflow_PartialTensorShape_dims\"><code>int tensorflow::PartialTensorShape::dims() const</code></h4> <p>Return the number of dimensions in the tensor. If the number of dimensions is unknown, return -1.</p> <h4 id=\"bool_tensorflow_PartialTensorShape_IsFullyDefined\"><code>bool tensorflow::PartialTensorShape::IsFullyDefined() const</code></h4> <p>Return true iff the rank and all of the dimensions are well defined.</p> <h4 id=\"bool_tensorflow_PartialTensorShape_IsCompatibleWith\"><code>bool tensorflow::PartialTensorShape::IsCompatibleWith(const PartialTensorShape &amp;shape) const</code></h4> <p>Return true iff the ranks match, and if the dimensions all either match or one is unknown.</p> <h4 id=\"bool_tensorflow_PartialTensorShape_IsCompatibleWith\"><code>bool tensorflow::PartialTensorShape::IsCompatibleWith(const TensorShape &amp;shape) const</code></h4> <p>Return true iff the dimensions of <code>shape</code> are compatible with <code>*this</code>.</p> <h4 id=\"int64_tensorflow_PartialTensorShape_dim_size\"><code>int64 tensorflow::PartialTensorShape::dim_size(int d) const</code></h4> <p>Returns the number of elements in dimension <code>d</code>. REQUIRES: <code>0 &lt;= d &lt; dims()</code></p> <h4 id=\"gtl_ArraySlice_int64_tensorflow_PartialTensorShape_dim_sizes\"><code>gtl::ArraySlice&lt;int64&gt; tensorflow::PartialTensorShape::dim_sizes() const</code></h4> <p>Returns sizes of all dimensions.</p> <h4 id=\"void_tensorflow_PartialTensorShape_AsProto\"><code>void tensorflow::PartialTensorShape::AsProto(TensorShapeProto *proto) const</code></h4> <p>Fill <code>*proto</code> from <code>*this</code>.</p> <h4 id=\"bool_tensorflow_PartialTensorShape_AsTensorShape\"><code>bool tensorflow::PartialTensorShape::AsTensorShape(TensorShape *tensor_shape) const</code></h4> <h4 id=\"string_tensorflow_PartialTensorShape_DebugString\"><code>string tensorflow::PartialTensorShape::DebugString() const</code></h4> <p>For error messages.</p> <h4 id=\"bool_tensorflow_PartialTensorShape_IsValid\"><code>bool tensorflow::PartialTensorShape::IsValid(const TensorShapeProto &amp;proto)</code></h4> <p>Returns <code>true</code> iff <code>proto</code> is a valid partial tensor shape.</p> <h4 id=\"Status_tensorflow_PartialTensorShape_IsValidShape\"><code>Status tensorflow::PartialTensorShape::IsValidShape(const TensorShapeProto &amp;proto)</code></h4> <p>Returns <code>OK</code> iff <code>proto</code> is a valid tensor shape, and a descriptive error status otherwise.</p> <h4 id=\"string_tensorflow_PartialTensorShape_DebugString\"><code>string tensorflow::PartialTensorShape::DebugString(const TensorShapeProto &amp;proto)</code></h4> <h4 id=\"static_Status_tensorflow_PartialTensorShape_MakePartialShape\"><code>static Status tensorflow::PartialTensorShape::MakePartialShape(const int32 *dims, int n, PartialTensorShape *out)</code></h4> <p>Returns a <code>PartialTensorShape</code> whose dimensions are <code>dims[0]</code>, <code>dims[1]</code>, ..., <code>dims[n-1]</code>. Values of -1 are considered \"unknown\".</p> <h4 id=\"static_Status_tensorflow_PartialTensorShape_MakePartialShape\"><code>static Status tensorflow::PartialTensorShape::MakePartialShape(const int64 *dims, int n, PartialTensorShape *out)</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassPartialTensorShape.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassPartialTensorShape.html</a>\n  </p>\n</div>\n","classenvwrapper":"<h1 id=\"class-tensorflowenvwrapper\"><code>class tensorflow::EnvWrapper</code></h1> <p>An implementation of Env that forwards all calls to another Env .</p> <p>May be useful to clients who wish to override just part of the functionality of another Env .</p>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"tensorflow_EnvWrapper_EnvWrapper\"><code>tensorflow::EnvWrapper::EnvWrapper(Env *t)</code></h4> <p>Initializes an EnvWrapper that delegates all calls to *t.</p> <h4 id=\"tensorflow_EnvWrapper_EnvWrapper\"><code>tensorflow::EnvWrapper::~EnvWrapper()</code></h4> <h4 id=\"Env_tensorflow_EnvWrapper_target\"><code>Env* tensorflow::EnvWrapper::target() const</code></h4> <p>Returns the target to which this Env forwards all calls.</p> <h4 id=\"Status_tensorflow_EnvWrapper_GetFileSystemForFile\"><code>Status tensorflow::EnvWrapper::GetFileSystemForFile(const string &amp;fname, FileSystem **result) override</code></h4> <p>Returns the FileSystem object to handle operations on the file specified by 'fname'. The FileSystem object is used as the implementation for the file system related (non-virtual) functions that follow. Returned FileSystem object is still owned by the Env object and will.</p> <h4 id=\"Status_tensorflow_EnvWrapper_GetRegisteredFileSystemSchemes\"><code>Status tensorflow::EnvWrapper::GetRegisteredFileSystemSchemes(std::vector&lt; string &gt; *schemes) override</code></h4> <p>Returns the file system schemes registered for this Env .</p> <h4 id=\"Status_tensorflow_EnvWrapper_RegisterFileSystem\"><code>Status tensorflow::EnvWrapper::RegisterFileSystem(const string &amp;scheme, FileSystemRegistry::Factory factory) override</code></h4> <h4 id=\"uint64_tensorflow_EnvWrapper_NowMicros\"><code>uint64 tensorflow::EnvWrapper::NowMicros() override</code></h4> <p>Returns the number of micro-seconds since some fixed point in time. Only useful for computing deltas of time.</p> <h4 id=\"void_tensorflow_EnvWrapper_SleepForMicroseconds\"><code>void tensorflow::EnvWrapper::SleepForMicroseconds(int64 micros) override</code></h4> <p>Sleeps/delays the thread for the prescribed number of micro-seconds.</p> <h4 id=\"Thread_tensorflow_EnvWrapper_StartThread\"><code>Thread* tensorflow::EnvWrapper::StartThread(const ThreadOptions &amp;thread_options, const string &amp;name, std::function&lt; void()&gt; fn) override</code></h4> <p>Returns a new thread that is running fn() and is identified (for debugging/performance-analysis) by \"name\".</p> <p>Caller takes ownership of the result and must delete it eventually (the deletion will block until fn() stops running).</p> <h4 id=\"void_tensorflow_EnvWrapper_SchedClosure\"><code>void tensorflow::EnvWrapper::SchedClosure(std::function&lt; void()&gt; closure) override</code></h4> <h4 id=\"void_tensorflow_EnvWrapper_SchedClosureAfter\"><code>void tensorflow::EnvWrapper::SchedClosureAfter(int64 micros, std::function&lt; void()&gt; closure) override</code></h4> <h4 id=\"Status_tensorflow_EnvWrapper_LoadLibrary\"><code>Status tensorflow::EnvWrapper::LoadLibrary(const char *library_filename, void **handle) override</code></h4> <h4 id=\"Status_tensorflow_EnvWrapper_GetSymbolFromLibrary\"><code>Status tensorflow::EnvWrapper::GetSymbolFromLibrary(void *handle, const char *symbol_name, void **symbol) override</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassEnvWrapper.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/ClassEnvWrapper.html</a>\n  </p>\n</div>\n","structtf_buffer":"<h1 id=\"struct-tf-buffer\"><code>struct TF_Buffer</code></h1>  <h3 id=\"member-details\">Member Details</h3> <h4 id=\"const_void_TF_Buffer_data\"><code>const void* TF_Buffer::data</code></h4> <h4 id=\"size_t_TF_Buffer_length\"><code>size_t TF_Buffer::length</code></h4> <h4 id=\"void_TF_Buffer_data_deallocator_void_data_size_t_length_\"><code>void(* TF_Buffer::data_deallocator)(void *data, size_t length))(void *data, size_t length)</code></h4><div class=\"_attribution\">\n  <p class=\"_attribution-p\">\n    &copy; 2015 The TensorFlow Authors. All rights reserved.<br>Licensed under the Apache 2.0 License.<br>\n    <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructTF_Buffer.html\" class=\"_attribution-link\">https://www.tensorflow.org/versions/r0.10/api_docs/cc/StructTF_Buffer.html</a>\n  </p>\n</div>\n"}